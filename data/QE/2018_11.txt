Understanding the smart park placement scheme under smart city through artificial intelligence With the development of science and technology, China's urban construction has also entered a high-speed and transformation, and the city is developing towards wisdom, which has given birth to the concept of smart park. The so-called smart park refers to the formation of urban decision-making mechanisms driven by technology such as artificial intelligence, big data, cloud computing, etc., and rationalizes, efficiently, and integrates data and resources according to data and reality to achieve optimal operational efficiency. At the moment of the rapid development of artificial intelligence in China, the concept of smart park is not a new concept. We can understand the true face of the smart park through some practical cases, and discover the surprise side of the artificial intelligence city. The development of artificial intelligence technology in China has become more and more perfect, and many technologies have been successfully launched in many application fields, and even many successful examples have emerged. The Smart Park is a new concept born on the basis of a smart city. The so-called smart city is driven by data. All the decision-making mechanisms of the whole city are based on data. Through the analysis and comprehensive deployment of data, the public resources of the entire city are planned and mobilized. The purpose of this is to continuously improve the efficiency of the operation of the whole city and promote the optimal use of resources. The smart park is actually extended from this concept, targeting a small space, an office space, and a smart space solution set by the living space. In this program, we will be exposed to more artificial intelligence technologies, such as driverless, online classrooms, and remote diagnosis and treatment. These artificial intelligence products covering public and public measures will be further developed. Realize the contribution of smart cities. For the smart park, while the scope is subdivided, the artificial intelligence project will be more detailed for the launching field. For example, for the smart park of the nature of the office area, more face recognition gates will be placed, conference signs, speed gates, etc. Artificial intelligence products to meet the daily operational needs of smart campuses. For smart parks in residential areas, there may be more involvement in face recognition technology, such as stranger alarm systems, gates, etc., to ensure the safety of the park life. All of these will further change the future life scene of smart cities or smart parks, and will further affect the development of China's artificial intelligence industry. According to relevant professionals, based on this, the establishment of smart cities and smart parks will be infinitely creative through the assistance of artificial intelligence. At the same time, through the adaptability of technology, there will be more innovation and efficiency. The products and technologies have been settled, and the feasibility of the artificial intelligence smart park has been further proved in practice.Xi Jinping: Promoting the Healthy Development of China's New Generation of Artificial Intelligence Xinhua News Agency, Beijing, October 31st The Political Bureau of the CPC Central Committee held the ninth collective study on the status quo and trend of artificial intelligence development on the afternoon of October 31. Xi Jinping, general secretary of the CPC Central Committee, emphasized that artificial intelligence is an important driving force for a new round of scientific and technological revolution and industrial transformation. Accelerating the development of a new generation of artificial intelligence is related to whether China can seize a new round of scientific and technological revolution and industrial transformation opportunities. Strategic issues. It is necessary to profoundly understand the great significance of accelerating the development of a new generation of artificial intelligence, strengthen leadership, plan well, clarify tasks, lay a solid foundation, promote its deep integration with economic and social development, and promote the healthy development of China's new generation of artificial intelligence. Gao Wen, a professor at Peking University and an academician of the Chinese Academy of Engineering, explained the issue and discussed his opinions and suggestions. The comrades of the Political Bureau of the CPC Central Committee listened carefully to the explanations and discussed the relevant issues. Xi Jinping delivered a speech while presiding over the study. He emphasized that artificial intelligence is a strategic technology that leads this round of scientific and technological revolution and industrial transformation, and has a "head geese" effect with strong spillovers. Driven by new theoretical and new technologies such as mobile Internet, big data, supercomputing, sensor network, and brain science, artificial intelligence accelerates development, showing deep learning, cross-border integration, human-machine collaboration, group openness, and autonomous control. The new features are having a major and far-reaching impact on economic development, social progress, and the international political and economic landscape. Accelerating the development of a new generation of artificial intelligence is an important strategic strategy for us to win the initiative of global science and technology competition, and is an important strategic resource to promote China's science and technology leapfrog development, industrial optimization and upgrading, and overall productivity jump. Xi Jinping pointed out that artificial intelligence has multi-disciplinary and highly complex features. We must strengthen research and judgment, coordinate planning, collaborative innovation, and steadily advance. We will focus on enhancing originality and focus on key core technologies to consolidate the foundation of a new generation of artificial intelligence. It is necessary to strengthen basic theoretical research, support scientists to brave the "no man's land" at the forefront of artificial intelligence technology, and strive to achieve transformative and subversive breakthroughs in the direction of artificial intelligence development and theory, methods, tools, systems, etc., to ensure that China is in artificial intelligence. The theoretical research in this important field is ahead, and the key core technologies occupy the commanding heights. It is necessary to focus on key core technologies, focus on problems, comprehensively enhance the innovation capability of artificial intelligence technology, accelerate the establishment of a new generation of artificial intelligence key common technology system, and grasp the layout on the short board to ensure that the key core technologies of artificial intelligence are firmly in their hands. . It is necessary to strengthen the development of science and technology application, closely focus on the needs of economic and social development, give full play to China's massive data and large-scale market application scale advantages, adhere to the demand-oriented, market-reduced technological development path, actively cultivate artificial intelligence innovation products and services, and promote artificial intelligence. The industrialization of technology has formed a good development situation in which science and technology innovation and industrial application promote each other. It is necessary to strengthen the construction of the talent team, with greater determination and more effective measures to build a variety of high-level talent training platforms, strengthen the training of reserve talents, and provide more adequate talent support for science and technology and industrial development. Xi Jinping emphasized that China's economy has shifted from a high-speed growth stage to a high-quality development stage. It is in the process of transforming its development mode, optimizing its economic structure, and transforming its growth momentum. It is in urgent need of a new generation of artificial intelligence and other major innovations. We must deeply grasp the characteristics of the development of a new generation of artificial intelligence, strengthen the integration of artificial intelligence and industrial development, and provide new kinetic energy for high-quality development. It is necessary to focus on building a modern economic system, taking supply-side structural reform as the main line, grasping the opportunity of digital, network, and intelligent integration development, and exerting the role of artificial intelligence in quality change, efficiency change, and power change to improve total factor productivity. It is necessary to cultivate artificial intelligence enterprises and industries with major tie-tie actions, and build an intelligent economy that is driven by data, human-machine synergy, cross-border integration, and sharing. It is necessary to give play to the technological advantages of artificial intelligence in industrial upgrading, product development, service innovation, etc., to promote the deep integration of artificial intelligence in the same, secondary and tertiary industries, to promote the transformation of various industries with artificial intelligence technology, leading in the middle and high-end consumption, innovation, and low in green. Carbon, shared economy, modern supply chain, human capital services and other fields will foster new growth points and create new kinetic energy. It is necessary to promote the construction of intelligent information infrastructure, upgrade the level of traditional infrastructure intelligence, and form an infrastructure system that meets the needs of intelligent economy and intelligent society. Xi Jinping pointed out that it is necessary to strengthen the combination of artificial intelligence and guarantee and improve people's livelihood, and proceed from the need to protect and improve people's livelihood and create a better life for the people, and promote the deep application of artificial intelligence in people's daily work, study and life, and create more intelligent. Work style and lifestyle. It is necessary to grasp the prominent contradictions and difficulties in the field of people's livelihood, strengthen the in-depth application of artificial intelligence in the fields of education, health care, sports, housing, transportation, disability pension, and domestic service, and innovate the intelligent service system. It is necessary to strengthen the combination of artificial intelligence and social governance, develop artificial intelligence systems suitable for government services and decision-making, strengthen the integration of government information resources and accurate prediction of public needs, promote the construction of smart cities, and promote the deep application of artificial intelligence in the field of public security. The use of artificial intelligence in the ecological field, using artificial intelligence to improve the level of public services and social governance. It is necessary to strengthen the potential risk analysis and prevention of the development of artificial intelligence, safeguard the interests of the people and the national security, and ensure that artificial intelligence is safe, reliable and controllable. It is necessary to integrate multi-disciplinary forces, strengthen research on legal, ethical and social issues related to artificial intelligence, and establish and improve laws, regulations, institutional systems, and ethics that ensure the healthy development of artificial intelligence. Leading cadres at all levels must study hard at the forefront of science and technology, grasp the laws and characteristics of artificial intelligence development, strengthen overall coordination, increase policy support, and form work synergies.Defying Technology Face++ is the first to propose DocUNet recoverable and distorted document images CVPR 2018 (Conference on Computer Vision and Pattern Recognition) will be held in the United States from June 18th to 22nd. Salt Lake City is held. As a diamond sponsor of the conference, the Vision Technology Institute will also attend the event under the leadership of Dr. Sun Jian. ?? Paper link: https://www3.cs.stonybrook.edu/~cvl/content/papers/2018/Ma_CVPR18.pdf Introduction Due to the rapid increase in the number of mobile cameras, taking pictures has become a digital record of physical documents. A common way to follow up, such as text recognition. However, text recognition is difficult to achieve due to the often distorted or deformed physical documents and poor lighting conditions. In response to this problem, Vision Technology Face++ first proposed a learning-based stacked U-Net called DocUNet that smoothes and restores distorted document images. DocUNet fills a technical gap in the field of deep learning. Due to the effectiveness and efficiency of flattened document images, DocUNet can greatly reduce the difficulty of text recognition, optimize the development of OCR technology, and promote text recognition and retrieval capabilities in real-world, network and other scenarios. From the underlying technology dimension to office automation, wisdom Retail, unmanned supermarkets and even autonomous driving innovations have paved the way for peace. Digitizing design ideas is an important way to save existing printed documents and can be accessed anytime, anywhere. The traditional method uses a flatbed scanner to digitize documents, but it is not easy to carry and is costly. Recently, with the increasing number of mobile cameras, shooting physical documents has become the most convenient way to scan documents. Once photographed, the image can be further processed by text detection and recognition techniques to enable content analysis and information extraction. A common problem common with document images is that the scanning conditions of the document pages are not ideal: they may be bent, folded, crumpled, or placed on a very complex background. Imagine a wrinkle receipt taken from the wallet. All of these factors can cause serious problems in the automated analysis process of document images, as shown in Figure 1. There is therefore a need to digitize flattened images in distorted documents. Figure 1: The flattening of the document image and its use. (a) Showcase some of the work of this paper. Above is the input image, below is the output image. (b) The network in this paper significantly improves the performance of the current optimal text detection system: the following restored document image can detect more words (green) than the above distorted image. The flattening of document images is not a new problem, and there are many solutions. Some vision systems rely on well-designed and calibrated hardware, such as stereo cameras, or structured light projectors to measure 3D distortion of documents; they perform well, but additional hardware limits their application; other work draws on this lesson. The multi-view image reconstructs the 3D shape of the distorted document image. Some people are working to restore a document image by analyzing a single image with various low-level artifacts (such as shading, text lines, etc.). This article presents a new learning-based approach to recovering images of any curved and folded document. Different from the previous method, this paper proposes the first end-to-end learning method, which can directly predict document distortion. Previous methods only used learning to extract features, and the final image restoration was still based on traditional optimization techniques; this method relied on convolutional neural networks (CNNs) to restore images end-to-end. Compared to the optimization method, the test performance of the feedforward network is very eye-catching. In addition, this data-driven approach can be better generalized to other document types (text, numbers, handwriting, etc.) if appropriate training data is available. This method translates this problem into finding a suitable 2D map to recover the distorted image document. It predicts a mapping field that moves the pixels in the distorted source image S(u, v) ? to the (x, y)? in the resulting image D. Therefore, this paper finds that this task has some commonality with semantic segmentation; for the latter, the network assigns a class of tags to each pixel. Similarly, the network in this paper assigns a 2D vector to each pixel. This inspired the author to use the well-known U-Net in the semantic segmentation domain to solve the regression problem in this paper and define a new loss function to drive the network to return the coordinates (x, y) in D for each pixel in S. Obtaining massive amounts of data with labels is the first challenge facing deep supervisory learning. To train the network, the author needs to distort a large number of document images and corresponding deformed images with different degrees as input to achieve perfect restoration. Unfortunately, such data sets do not exist. Obtaining a realistic deformed label image is very difficult, so the final selection of synthetic data in this article. By randomly distorting the flattened document image, this paper synthesizes 100K images to use the perturbed image as input, and the network used to distort the image is the inverse shape intended for restoration. There is also no public benchmark available for evaluating document flattening. Previous methods either evaluated on a small number of images, or the data set contained only a few twist types. The author created a baseline of 130 images to fill this gap, with huge differences in document type, degree of distortion and type, and shooting conditions. Data Sets This method is based on CNN and requires a large amount of training data. In this task, document deformation can be characterized as 3D mesh, surface normal, 2D flow, etc. It is very difficult to accurately capture it in any form in the real world, such as a range camera or a calibration stereo vision system. Additional hardware, while estimating the accuracy of the deformation, usually depends on the hardware cost. In addition, it is unrealistic to manually distort/deform document files to cover all real-world situations. This article considers training with synthetic data, which is common in recent deep learning and allows for complete control over changes to the data set. An intuitive idea is to render a distorted document directly in a 3D rendered document, but this is impractical for the following reasons. First, it is very difficult and slow to generate a physically correct 3D mesh through physical simulation. Second, rendering through path tracking is also very time consuming. Rendering a 100K image will take more than two months. -- 2D warped image synthesis This paper directly synthesizes 2D training images. Although the underlying physical modeling has been overlooked, manipulating a 2D mesh is fairly straightforward and the image generation is fast. Since the purpose of this paper is to map the distorted paper to the restoration paper, the data synthesis is a reverse process, that is, the restoration image is subjected to various types of distortion. When creating a warp pattern, this article follows the following empirical principles: i) A real piece of paper is partially rigid and does not stretch or compress. The distortion at one point will bring about a spatial change. Ii) There are two types of distortion: folding and bending, which produce creases and curls, respectively. The actual situation is usually a combination of these two types of distortion. This article first collects a large number of flat digital documents, including papers, books, and magazine pages, and then distorts them, as shown in Figure 2. Figure 2: 2D synthetic warped document image. Perturbed mesh generation: Given image I, this paper places a m x n mesh M on it to provide control points for the distortion. Select a random vertex p as the initial deformation point on M. The direction and intensity of the deformation are marked as v and are also randomly generated. Finally, based on i), v propagates to other vertices by weight w. The vertices on the warped grid are calculated as p_i + wv, ?i. Disturbed image generation: The perturbed mesh provides a sparse deformation domain. This paper interpolates it in a linear fashion to construct a dense warp map from the pixel level, and then applies the warp map to the original image to generate a perturbed image. In this way, the author synthesized 100K images on a single CPU. Each image contains up to 19 synthetic deformations (30% is curved and 70% is folded). The bending needs to ensure that the Gaussian curvature should be 0 at any position, and the folding is arbitrary. The sample is shown in Figure 5. Figure 5: Sample image in the composite data. DocUNet--The network architecture is similar to semantic segmentation. This article designed the network to enhance pixel-by-pixel supervision. Because of its simplicity and effectiveness in semantic segmentation tasks, this paper chooses U-Net as the basic model, which is basically a full convolutional network, including a series of downsampling layers and subsequent upsampling layers, feature mapping. Connect between the upper and lower sampling layers. However, the output of a single U-Net is not satisfactory and should be optimized so that another U-Net is stacked as a refiner on the output of the first U-Net. As shown in Figure 3. Figure 3: Network architecture. The network is made up of two U-Net stacks. The network splits and outputs a forward map y_1 from the output of the first U-Net. The same loss applied to y_2 is also applied to y_1. Next y_1 connects to the output feature map of the first U-Net and acts as the input for the second U-Net. Y_2 can be used directly to generate a restored image. This article has a layer responsible for converting the deconvolution feature to the final output (x, y). The first U-Net forks into two after the last deconvolution layer. The first U-Net deconvolution feature is connected to the intermediate prediction ?y_1 ? as the input to the second U-Net. The second U-Net finally gives an optimized prediction y_2 that the author uses as the final output of the network. This paper applies the same loss function to y_1 and y_2 during training. However, when testing, only y_2 is used as the output of the network. Unlike semantic segmentation, which is essentially a pixel classification problem, the calculation of the network output (for mapping F) is a regression process. The output of speech segmentation usually has C channels, where C is the number of semantic categories. The network only outputs 2 channels for (x, y) coordinates. The loss function loss function consists of two parts: 1. The element-wise loss between the output map y and its corresponding groundtruth map y^star. 2. The relative position of the map of the different points of the output y_1 - y_2 and their corresponding groundtruth map relative position y_1^star - y_2^star relative shift (variable invarient loss). The absolute error is expressed as: ?? The relative error is expressed as: ?? Assume that d_i = y_i - y_i^star, Eq. 5? can be expressed as: ?? This paper also finds that L1 (Eq. 7) is better than L2 (Eq. 6), so the loss function can be rewritten as: ??F The element corresponding to the background pixel of S is a constant -1, so the partial loss in ?Eq. 7 comes from the background. In fact, it is not necessary for the network to accurately return these elements to -1. Any negative value should be sufficient. So in this paper, hinge loss is used for background pixels: ?? and Eq. 7 is only used for foreground pixels. The experiment first introduces the benchmark for evaluating the distortion of a document on a single image; then evaluates the learning-based approach presented in this paper and compares it with the results of previous non-learning methods. - Reference image: The image in the reference is an image of a physical paper document taken by the mobile phone. Collected 65 papers of various contents/forms, each of which was photographed in two, with a total of 130 images. The baseline contains the original image and the document centered cropped images?, and the experiment uses the latter because the focus of this article is to flatten the paper rather than locate the document in the image.The creation of the benchmark is based on the following considerations: i) Document type: The selected document types are different, with receipts, letters, documents, magazines, papers, books, etc.; ii) Distortion: The original flat paper document is physically distorted by different people. ; iii) Environment: The image was taken by two people using two different mobile phones under different indoor and outdoor lighting conditions. Groundtruth: Scans a selected paper document before it is folded by a flatbed scanner. Adjust the size and overall color of the acquired image to match the original flat document as much as possible. Figure 6 is a few examples of the benchmark. Figure 6: Benchmark sample. The results of the benchmark evaluation show that the method is superior to the previous Tian et al. [27]. Specifically, the results of this method are 0.41 and 14.08 for MS-SSIM? and LD?, respectively, compared with 0.13 and 33.69 for [27]. This is because [27] is designed primarily for text line documents and relies heavily on the quality of text line tracking, so it can't handle more complex documents, such as mixed text lines and numbers, or areas where text line tracking fails, as shown in Figure 10 is shown. Figure 10: Comparison of Tian et al. [27]. In terms of computational efficiency, [27] it takes 3 to 4 minutes to process 1 image on 1 CPU with Matlab. In contrast, the network on this GTX 1080 Ti GPUTM runs at 28 fps, although this comparison is a bit unfair. The bottleneck is to generate a restored image from the map. The Matlab implementation not optimized in this article takes about 3 to 4 seconds on the CPU. Overall, the method is fast [27] an order of magnitude, as shown in the following table: ?? More comparison results are shown in Figure 8 and Figure 9: Figure 8: Comparison You et al. [36]. Although [36] uses 5 to 10 images, the method is still quite competitive. Figure 9: Comparison Das et al. [6]. The method of [6] is specifically designed for folding documents twice. In this case, the method in this paper also performs well. The example image in the image above is from [6]. Conclusion This article presents the first end-to-end neural network for flattening and restoring distorted document images. The authors propose a stacked U-Net with intermediate supervision and end-to-end training to directly predict the mapping that can remove image distortion. The author also created synthetic training data and a benchmark containing real images taken under various conditions. Experimental results confirm the effectiveness and efficiency of the method. In future work, the author will apply GAN to generalize this network to the actual image and hope to add a brightness model to remove highlights or shadows on the restored image. On the other hand, the author also optimizes the code that generates the restored image from the map and implements the real-time deployment of the entire process on the mobile side.CVPR 2018 | Defiance Technology Object Detection Chronicle - Large mini-batch detector MegDet CVPR 2018 (Conference on Computer Vision and Pattern Recognition, IEEE International Computer Vision and Pattern Recognition Conference) will be held on June 18 It was held in Salt Lake City, USA on the 22nd. As a diamond sponsor of the conference, the Vision Technology Research Institute will also attend the event under the leadership of Dr. Sun Jian. ?? Paper link: https://arxiv.org/abs/1711.07240 Leading depth learning era, one of the cornerstones of computer vision, object detection technology has achieved a leap-type development, new models and new methods continue to emerge. This article provides a new type of detection MegDet for the training of accelerated deep neural networks from the perspective of mini-batch. By expanding mini-batch to 256, it can make full use of 128 GPUs and greatly shorten the training time. Technically, the warmup learning rate strategy and Cross-GPU batch normalization (CGBN) together ensure successful training of the large mini-batch detector MegDet, with shorter time (from 33 hours to 4 hours) and higher precision . This means that MegDet optimizes object detection technology from two core dimensions of accuracy and speed, paving the way for the landing and other computer vision applications of this technology, and even in the areas of security, new retail and driverless. After the design idea R-CNN?, a series of new models such as Fast/Faster R-CNN, Mask R-CNN, and RetinaNet emerge one after another. These CNN?-based methods have made great progress in the field of object detection. In just two years, the COCO AP was 19.7 ( Fast R-CNN) rose to 39.1 (RetinaNet). Behind the above improvements is a better base network, better detection architecture, better loss design and a constantly improving pooling approach. A recent trend in the CNN image classification model is to significantly reduce training time through large mini-batch. For example, with a mini-batch of 8192 or 16000, the ResNet-50 can be trained in 1 hour or 31 minutes with little precision. In contrast, the mini-batch of the CNN image detection model is generally small, such as 2-16, while the mini-batch size of the general classification model is usually 256. In response to this problem, this paper presents a technical solution that makes large mini-batch equally suitable for detecting models. What is wrong with the mini-batch? To put it simply, there are three points: First, training is extremely time consuming; secondly, batch normalization (BN) cannot be accurately counted through small mini-batch training; finally, the number of positive and negative instances in small mini-batch is more unbalanced. Figure 2: An example image with a positive or negative proposal. (a-b) The ratio of the two instances is unbalanced; (c-d) The ratio of the two instances is balanced and medium. What are the challenges if you simply increase mini-batch? As with image classification issues, the main difficulty is that large mini-batch often requires a high learning rate to maintain accuracy. However, in object detection, high learning rates are likely to cause the model to fail to converge; if a lower learning rate is used, the results obtained are usually poorer. In order to solve the above problems, this paper proposes a solution called MegDet: First, the author proposes a new interpretation of linear scaling, and gradually improves the learning rate by using the ¡°warmup¡± learning rate strategy in the early stage; then, to solve the accuracy and convergence Problem, the author introduces Cross-GPU Batch Normalization (CGBN) to better count BN. CGBN not only increases the accuracy of the point, but also makes the training more stable, so that you can safely enjoy the powerful computing blessing in the industry, which makes sense. Figure 1: The accuracy of the verification set of the same FPN object detector trained on the COCO data set when the mini-batch size is 16 (8 GPUs) and 256 (128 GPUs) respectively. The large mini-batch detector is more accurate and the training speed is nearly an order of magnitude faster. MegDet can perform COCO training in less than 4 hours with 128 GPUs, even with higher precision; in contrast, the mini-batch requires 33 hours of training and less precision. This means that the innovation cycle can be reduced by almost an order of magnitude and even better. Based on MegDet, contempt won the first place in the COCO 2017 Object Detection Challenge. As a large mini-batch detector, MegDet can complete the training in a shorter time and achieve the accuracy increase. This section describes the principle of the method. Due to several problems with small mini-batch, simply increasing the mini-batch must handle the trade-off between precision and convergence, and the author introduced a learning rate strategy (warmup) for large mini-batch. Although this optimizes convergence to some extent, it is still lacking for larger mini-batch such as 128 or 256. The author then introduced CGBN, which is the key to large mini-batch training. CGBN batch normalization is an important technique for training deep convolutional neural networks. This paper attempts to apply it to object detection. It is worth mentioning that the input image of the classification network is usually 224 ¡Á 224 or 299 ¡Á 299, and a 12G NVIDIA TITAN Xp GPU is enough to process more than 32 images. Thus, BN can be calculated separately on each device. But for object detection, the detector needs to process objects of different sizes, so you need to enter a higher resolution image and perform batch normalization on multiple GPUs to gather enough statistics from more samples. Performing batch normalization across GPUs requires calculating aggregated mean/variance statistics for all devices. Most existing deep learning frameworks use the BN implementation in cuDNN?, but only provide advanced APIs and cannot modify internal statistics. Therefore, a primary mathematical expression is required to perform the BN and summarize the statistics through the AllReduce? operation. These fine-grained expressions typically add significant overhead to the runtime, while AllReduce operations are missing in most frameworks. The CGBN implementation is shown in Figure 3: Figure 3: CGBN implementation. An ellipse represents synchronization between devices, and a rounded box represents parallel computing of multiple devices. Experiment The data set used in this experiment was COCO Detection, which was divided into training set, validation set and test set, covering 80 categories and over 250,000 images. Backbone is a pre-trained ResNet-50 on ImageNet; the detection framework is the Feature Pyramid Network (FPN). The number of training set images exceeds 118,000, the validation set is 5000 images, the SGD optimizer momentum is 0.9, the weight decay is 0.0001, and the basic learning rate of mini-batch 16 is 0.02. The main results of the experiment are shown in Table 3: Figure 4: The accuracy of the verification set for 16-batch and 256-batch, using a long-term training strategy. Both detectors have the same BN size. The vertical dashed line indicates the moment when the learning rate decays. Third, as shown in the last part of Table 3, this paper investigates long-term training strategies. Longer training times will result in a slight increase in accuracy. Finally, as shown in Figure 4, 256-batch performs poorly in the early stages of epochs, but in the final stage it overtakes 16-batch (after the second learning rate decay). This situation is quite different from image classification, where the precision curve and the convergence score are very close in the mini-batch settings of different sizes. Conclusion This paper presents a large mini-batch detector MegDet that achieves higher accuracy in less time. This work is significant and has greatly shortened the research cycle. With MegDet, Vision Technology has won the COCO 2017 Test Challenge, some of which are as follows: Figure 5: An example of MegDet on the COCO dataset. Table 4: Results of (enhanced) MegDet on COCO test-dev. There are four main technical contributions in this paper: - Based on the assumption of maintaining equal loss variance, this paper proposes a new interpretation of linear scaling rules in the context of object detection. - This article is the first to train BN in the object detection framework; experiments have shown that CGBN not only helps the accuracy of the rise, but also makes the training easier to converge, especially for large mini-batch.CVPR 2018 | A new approach to Vision Technology - Detecting scene texts through corner positioning and region segmentation CVPR 2018 (Conference on Computer Vision and Pattern Recognition, IEEE International Computer Vision and Pattern Recognition Conference) will be 6 Held in Salt Lake City, USA from the 18th to the 22nd. As a diamond sponsor of the conference, the Vision Technology Institute will also attend the event under the leadership of Dr. Sun Jian. ?? Paper link: https://arxiv.org/abs/1802.08948 lead in the detection matrix of the eye of the machine, the natural scene text is a kind of important objects that cannot be avoided, and there are exterior scenes, videos, web pages, subtitles, screenshots, etc. A variety of expressions. Devotion Technology Face++ has pioneered a new type of text detector by taking advantage of the respective advantages of object detection and semantic segmentation, and innovatively integrated it to a new level. The impact of this iterative upgrade of the underlying detection technology is universal, meaning that most of the practical applications related to text recognition can be optimized and improved to different degrees, and promote text detection technology in live broadcast, e-commerce, forums and other UGC. Content platform websites, or video websites such as barrage, comments, group chats, nicknames, and social apps; further enhance the search and retrieval capabilities of texts in products and images, and promote the development of smart retail, unmanned supermarkets and other industries. Popularization, and even promote the advancement of autonomous driving technology. It can be seen that the new text detection technology launched by Vision Technology not only helps customers to get out of the dilemma of massive data, but also develops personalized strategies, efficiently filters multiple types of junk text and sensitive words, eliminates text hidden dangers, and thus creates intelligence, security, and The civilized social environment can also promote the development of new retail, unmanned supermarkets and autonomous driving. Design Ideas Recently, as practical application requirements continue to grow, it has become increasingly popular to extract textual information from real-life scene images. Scene text detection - a natural image text positioning technology - plays an indispensable role in various text reading systems. Due to both internal and external factors, scene text detection challenges are numerous. External factors refer to external environments such as noise, blur, and occlusion. They are also the main source of trouble for general object detection. Internal factors come from the properties of the scene text. Compared with general object detection, scene text detection is more complicated because: 1) the text in the natural scene can be in any direction, so the bounding box to be detected is usually a rotating rectangle or quadrilateral; 2) the length of the scene text bounding box The width ratio varies greatly, and usually there is an extreme aspect ratio; 3) the scene text has various granularities, such as characters, words or lines of text, and the algorithm can hardly determine the text instance when positioning the bounding box. Figure 1: Upstream and downstream from left to right are predicted top left, top right, bottom right, bottom left corner and position sensitive maps. In the past few years, a lot of research on scene text detection has been carried out. Combined with the promotion of general object detection and semantic segmentation, the recent results of scene text detection have been remarkable, and two types of mainstream detectors have evolved. The first type is based on the general object detectors SSD, YOLO, DenseBox, which can directly predict the candidate bounding box; the second type is based on semantic segmentation, which can generate a segmentation graph, and the final text box is given by post-processing. This paper combines the ideas of the above two methods and innovates. It is mainly based on the following two findings: 1) We can pass the corner points of the rectangle (top left, top right, bottom right, bottom left, as shown in Figure 1). ) to determine a rectangle, regardless of its size, aspect ratio or direction; 2) text region segmentation map can provide effective text location information, position-sensitive text region segmentation map (Figure 1) can provide Valid text instance information. Therefore, this article first directly detects the corners of the text rather than the regression text box. In addition, this paper predicts position-sensitive segmentation maps rather than text/non-text maps. Finally, this paper generates candidate bounding boxes by sampling and combining the detected corner points, and eliminates the unreasonable bounding box according to the segmentation information. The pipeline of the proposed method is shown in Figure 2. Figure 2: Overview of the method in this article. Given an image, the network outputs corner points and segmentation maps by means of corner detection and position-sensitive segmentation; then candidate frames are generated by sampling and combining corner points; finally, these candidate frames are scored by segmentation and are suppressed by NMS The remaining candidate box. The main highlights of this method are: 1) Since the scene text is detected by sampling and combining corner points, the method can process text in any direction; 2) the method can naturally avoid the detection of corner points instead of text bounding boxes. The problem of large change in aspect ratio; 3) By position-sensitive segmentation, the method can segment text instances well, regardless of whether it is a character, word or text line; 4) In this method, the boundary of the candidate frame is angled Point to decide. This method produces a more accurate bounding box than the anchor or text region based text bounding box, especially for long text. The effectiveness of this method is validated in horizontal text, multi-directional text, multi-directional long text, and public data sets of multilingual texts, which proves its advantages in accuracy and speed. In particular, the F-Measures of this method are 84.3%, 81.5%, and 72.4% on ICDAR2015, MSRA-TD500, and MLT?, respectively, which is significantly better than the previous best method. In addition, the method has a competitive advantage in terms of efficiency, and can process more than 10.4 images per second with an input picture size of 512x512. Network Architecture The method in this paper is a full-convolution network, which can implement feature extraction, corner detection and location-sensitive text region segmentation. The network architecture is shown in Figure 3. Given an image, the network gives candidate corner points and segmentation maps. Figure 3: The network consists of three parts: Backbone, Corner Detector, and Position Sensitive Segmentation Detector. Backbone uses DSSD. The corner detector is built on top of multiple feature layers (pink modules). The position sensitive segmentation detector shares a pink module with the corner detector. -- Feature extraction The backbone of the model is adapted from the pre-trained VGG16 network and is designed based on the following considerations: 1) the size of the scene text varies greatly, so the backbone must be sufficient to deal with the problem; 2) the background in the natural scene is very complex Therefore, features preferably contain more context. In view of the good performance of the FPN/DSSD structure on the above issues, this paper extracts features through the FPN/DSSD backbone. -- Corner Detection This article uses a square box to represent a corner point and uses the default box to revert to the corner point. The center point of the frame is the corner point position, and the side length of the frame is the shortest side of the text box to which the corner point belongs. Corner point detection is more complicated than SSD/DSSD. Each default box outputs a corresponding candidate box with different classification scores and offsets. Because there can be multiple corner points in the same position, the output corresponding to the default box in this paper is the classification score and offset of the four candidate boxes of the four types of corner points. In this paper, the prediction module is used to predict the scores and offsets of two branches in a convolution manner. For the m ¡Á n? feature map with k default boxes in each cell, the ¡°point¡± branch and the ¡°offset¡± branch respectively output 2 scores for each type of corner point of each default box. 4 offsets. Here, 2 in the "point value" branch indicates whether there is a corner point in the position. In general, the output channels of the "fraction" branch and the "offset" branch are k ¡Á q ¡Á 2 and k ¡Á q ¡Á 4, where q represents the corner type. q The default is equal to 4. The training phase follows the matching strategy of default box and groundtruth in SSD. To detect scene text of different sizes, this article uses different sizes of default boxes on multiple layer features. - Position Sensitive Segmentation The previous segmentation based text detection method characterizes the probability that each pixel belongs to a text region by generating a segmentation map. However, due to the overlap of text areas and improper prediction of text pixels, the text areas in the score map are often not separated from each other. In order to obtain a text bounding box from the segmentation map, complex post-processing is required. Inspired by InstanceFCN?, this article uses position-sensitive segmentation to generate text segmentation maps. Relative position information is introduced compared to the previous text segmentation method. Specifically, the text bounding box R is divided into multiple bins by a g x g rule grid. For each bin, a split graph can be used to determine if the pixel of the graph belongs to the bin. As shown in Figure 4, this paper can effectively process similar or overlapping text areas with position-sensitive segmentation. In this paper, we construct a position-sensitive segmentation in a unified network, and use the features F3, F4, F7, F8, F9, etc. to predict g x g text region segmentation map. The default g is 2. Figure 4: Location-sensitive zone segmentation provides instance information that effectively filters out false alarms. (a) input image; (b) predicted text proposal and split graph. (c) Rating. The red boxes are text proposals corresponding to words (valid), similar words, and mutually overwritten words (invalid). The score for the text box proposal is calculated by the rotated position-sensitive ROI average pooling layer (Algorithm 1). Training and Reasoning For inputting training samples, this paper first converts each text box (arbitrary quadrilateral) in groundtruth into a rectangle that covers the text box and has the smallest area, and determines the relative positions of the four corner points. The relative position of the transformed rectangle should follow the following principles: 1) The x-axis of the upper left and lower left corners must be smaller than the x-axis of the upper right and lower right corners respectively; 2) the y-axis of the upper left and upper right corners must be smaller than the lower left and lower right corners respectively. The y axis of the point. Based on the relative position of the corner points, this paper can generate corner points and position-sensitive segmented groundtruth, as shown in Figure 5. Figure 5: Generate tags for corner detection and position sensitive segmentation. (a) Redefine the corner points and use squares (white, red, green, blue boxes), and set the side length to the short edge of the text bounding box R (yellow box). (b) The groundtruth of R in (a) corresponding to the position-sensitive segmentation. In the inferential phase, a lot of corner points are generated containing the predicted position, the length of the short side, and the confidence information. High score corners (default greater than 0.5) are reserved. After NMS, 4 corner points are composed based on relative position information. A large number of candidate bounding boxes are generated after sampling and grouping corners. This paper uses location-sensitive region segmentation to score candidate text boxes. The process is shown in Figure 6. Figure 6: Overview of the scoring process. The yellow frame in (a) is the candidate box. (b) is a predicted segmentation map. This paper generates an instance segment (c) of the candidate box by collecting the segmentation map. The score is calculated by averaging the instance segmentation area. To handle the rotated text bounding box, this paper proposes a rotated position-sensitive ROI average pooling layer. Specifically, for a rotating bounding box, this paper first divides the box into g x g bins. For each bin, calculates the mean of all the pixels in the corresponding pre-frame bin area, and finally averages the mean of all bins. The specific process is shown in Algorithm 1. ?? Algorithm 1: Rotational position sensitive ROI average pooling layer. The low-scoring candidate box will be filtered out. The default threshold for this article is 0.6. Experimental results To verify the effectiveness of the proposed method, the author conducted experiments on five data sets: ICDAR2015, ICDAR2013, MSRA-TD500, MLT, COCO-Text, which detected multi-directional text, horizontal text, multi-directional long text, and more. Language text and generalization ability. -- Multi-directional text This paper tested the performance of the model in arbitrary direction text detection on ICDAR2015 data and compared it with other current best practices. All results are shown in Table 2. This method greatly exceeds the previous method. When tested on a single scale, the method's F-measure? is 80.7%, which is better than all other methods; when tested on multiple scales, the method's F-measure? is 84.3%, which is better than the current best method. 3.3%. Table 2: ICDAR2015 results. ? indicates multi-scale, ? indicates that the model's underlying network is not VGG16. -- Horizontal text This paper tested the performance of the model on horizontal text detection on ICDAR2013 data. The results are shown in Table 3. When tested on a single scale, the method's F-measure? is 85.8%, slightly below the highest value. In addition, the method can process 10.4 images per second, faster than most methods. When tested on multiple scales, the method's F-measure? is 88.0%, which is also a competitive advantage. Table 3: ICDAR2013 results. ? indicates multi-scale, ? indicates that the model's underlying network is not VGG16. Note that the first three lines are done under the ¡°ICDAR2013¡± ??evaluation protocol. -- Multi-directional long text This paper tested the performance of the model on multi-directional long text detection on MSRA-TD500 data. The results are shown in Table 4, and its performance is much better than all previous methods. The method achieved the best performance (87.6%, 76.2%, and 81.5%?) on recall, accuracy, and F-measure, and was significantly better than the previous best (81.5% vs. 77.0%?). This shows that this method is better at detecting long text in any direction than other methods. Table 4: MSRA-TD500 results. ? The underlying network representing the model is not VGG16. -- Multilingual text This paper tested the performance of the model on multilingual text detection on MLT data. As shown in Table 5, this method surpasses other methods by at least 3.1%. Table 5: MLT results. ? indicates multi-scale. -- Generalization ability To evaluate the generalization ability of the model, this paper uses the model trained on the ICDAR2015 data set to test on the COCO-Text data set. The results are shown in Table 6. Without training, this method has an F-measure of 42.5% on the COCO-Text dataset, which is superior to other methods. Table 6: COCO-Text results. ? indicates multi-scale. Conclusion This paper proposes a scene text detector that can locate text by corner detection and position sensitive segmentation. The author evaluates the detector on several specialized multi-directional texts, horizontal texts, multi-directional long texts, and multilingual texts. The superior performance of the detector demonstrates the effectiveness and robustness of the proposed method. The contribution of this method has the following four aspects: 1) A new scene text detector combining object detection and segmentation is proposed, which can realize end-to-end training and evaluation; 2) Based on location-sensitive ROI pooling, a kind of proposed Position-sensitive rotating ROI average pooling layer, can handle proposals in any direction; 3) This method can simultaneously deal with many difficulties that plagued the previous multi-directional text detection methods, such as rotation, aspect ratio change, very close text instances, etc. ; 4) This method also achieves better or more competitive results in terms of accuracy and efficiency. In the future, the author will build an end-to-end OCR system based on this method.News broadcast 8 minutes! General Secretary Xi emphasized that AI has the effect of ¡°head geese¡± and must be brave in no-man's land! Last year, the state issued the "New Generation Artificial Intelligence Development Plan", which raised artificial intelligence to the national strategy for the first time. As the core driving force of the new round of industrial transformation, artificial intelligence has continuously released the enormous energy of previous scientific and technological revolutions and industrial reform savings. Yesterday (October 31), the news broadcast reported a collective study of national leaders with a video of nearly 8 minutes, focusing on the status quo and trends of artificial intelligence development. At the meeting, Gao Wen, a professor at Peking University and an academician of the Chinese Academy of Engineering, gave a lecture and discussed opinions and suggestions. This article is divided into three parts: 1. The main content of this collective study. 2. Academician Gao Wen had previous opinions and opinions on Chinese artificial intelligence. 3. Policies to promote the development of artificial intelligence introduced at various levels of the country. AI has a "head geese" effect, supporting scientists to brave "no man's land" According to Xinhua News Agency, this collective study was held this afternoon, mainly on the ninth collective study on the status quo and trend of artificial intelligence development. Artificial intelligence is a strategic technology that leads this round of scientific and technological revolution and industrial transformation. It has the effect of a ¡°head geese¡± with strong spillovers. Driven by new theoretical and new technologies such as mobile Internet, big data, supercomputing, sensor network, and brain science, the artificial intelligence as the ¡°head geese¡± accelerates development, showing deep learning, cross-border integration, human-machine collaboration, and group intelligence. New features such as openness and self-management are having a major and far-reaching impact on economic development, social progress, and the international political and economic landscape. Therefore, as an important driving force of the new round of scientific and technological revolution and industrial transformation, accelerating the development of a new generation of artificial intelligence is a strategic issue that can grasp the new round of scientific and technological revolution and industrial transformation opportunities. Under the strategy, it is necessary to focus on enhancing originality and focus on key core technologies to consolidate the foundation of the development of a new generation of artificial intelligence. The following points need to be strengthened: strengthen basic theoretical research, support scientists to brave the "no man's land" at the forefront of artificial intelligence technology, and strive to achieve revolutionary and disruptive breakthroughs in the direction of artificial intelligence development and theory, methods, tools, systems, etc. To ensure that China's theoretical research in the important field of artificial intelligence is ahead, and key core technologies occupy the commanding heights. Focusing on key core technologies, it is problem-oriented, comprehensively enhances the ability of artificial intelligence technology innovation, accelerates the establishment of a new generation of artificial intelligence key common technology system, and grasps the layout on the short board to ensure that the key core technologies of artificial intelligence are firmly in their hands. Strengthen the application of science and technology, closely focus on the needs of economic and social development, give full play to China's massive data and the advantages of large-scale market applications, adhere to the demand-oriented, market-strengthening technological development path, actively cultivate artificial intelligence innovative products and services, and promote artificial intelligence technology. Industrialization forms a good development situation in which science and technology innovation and industrial application promote each other. Strengthen the construction of the talent team, build a multi-level high-level talent training platform with greater determination and more effective measures, strengthen the training of reserve talents, and provide more adequate talent support for science and technology and industrial development. Academician Gao Wen once pointed out that the five new clues of AI hope that the new algorithm of machine learning will progress. The Gao Wen academician who participated in the collective study of the leaders of the country is a professor at Peking University, a doctoral tutor, IEEE Fellow, academician of the Chinese Academy of Engineering, Tokyo, Japan. University Ph.D. Director of Peking University Digital Media Research Institute, Director of National Engineering Laboratory of Digital Video Codec Technology, Director of Digital Media Center of Peking University Information Engineering College. According to the China Science and Technology Network, Academician Gao Wen once emphasized the five new clues of current artificial intelligence in the twenty-sixth media fusion technology seminar (ICTC2018) in 2018: The first one: deep learning on big data + The comprehensive evolutionary technology of self-exercise is two: network-based group intelligence has sprouted three: human-computer integration technology-oriented hybrid intelligence: four cross-media reasoning has emerged: five-handed system rapid development of artificial intelligence development to the present Three ups and downs are themselves a spiral development, and the future will take turns in computer science, electronics, automation and so on. Academician Gao Wen pointed out that China's next generation of artificial intelligence has more layouts in the new algorithm of machine learning, and hopes that there will be more progress in the new algorithm of machine learning. The Prime Minister carefully looked at the highest level of chips. The top leaders of the AI ??books on the Chairman¡¯s shelf attached great importance to the development of AI and also studied many times. Not long ago, the Prime Minister visited the Belgian Microelectronics Research Center (IMEC) to learn more about the time-consuming, energy-efficient and application of high-precision nanochips in the field of people's livelihood. The IMEC Center continuously shortens the distance between circuits and circuits on the chip through precision lithography technology, and improves communication efficiency and operation speed. At present, it has produced 3 nanometer chips, which is the highest level in the world. According to the People¡¯s Daily, the Prime Minister ¡°received the glasses and looked at the chip of a vinyl record for a long time and asked four or five questions.¡± This photo made many netizens ¡°tie¡±. According to the People¡¯s Daily News, on the 26th of this month, the sixth session of the Standing Committee of the 13th National People¡¯s Congress was closed at the Great Hall of the People in Beijing. After the closing meeting, the Standing Committee of the 13th National People¡¯s Congress held a lecture on the seventh lecture. Tan Tieniu, an academician of the Chinese Academy of Sciences, gave a lecture entitled "Innovative Development and Social Impact of Artificial Intelligence." Tan Tie Niu has introduced the development status of artificial intelligence in detail on many occasions. He once pointed out that the ¡°smart +X¡± application paradigm is becoming more and more mature, and AI rapidly penetrates and integrates into all walks of life to reshape the whole society. This is the fourth of artificial intelligence. The most important manifestation of the sub-technical revolution. In this year's New Year speech, the careful TV audience found that the National President's bookshelf not only contained classic socialist works, but also artificial intelligence books, including the famous machine learning expert Pedro Domingos's "Ultimate Algorithm" and Brett Kingde. "Intelligent Wave". Domingos believes that the answer to all learning problems in AI technology is an ultimate "master" algorithm that provides feedback to the AI ??system and allows the system to evolve. Bill Gates recommended this book as a must-read AI book. Domingos said that China has an advantage in the AI ??competition because it has a large amount of data, and it is the data that drives machine learning. In the book Smart Wave, the authors present a large number of cases and rich pictures to show us a smart future, how robots will replace human work, and whether artificial intelligence will classify us as low energy. Artificial intelligence has risen to national strategy, and the country has introduced a number of AI-related policies. In recent years, China has continuously introduced artificial intelligence-related policies to promote the development of artificial intelligence technology and industry. Last year's "two sessions," artificial intelligence first appeared in the "Government Work Report." Premier Li Keqiang mentioned in the "Government Work Report": "On the one hand, we must accelerate the cultivation of new materials, artificial intelligence, integrated circuits, bio-pharmaceuticals, fifth-generation mobile communications and other emerging industries, on the other hand, we must apply big data, cloud computing, Technologies such as the Internet of Things have accelerated the transformation and upgrading of traditional industries, and the development of intelligent manufacturing has been the main direction.¡± In July last year, the state officially issued the ¡°New Generation Artificial Intelligence Development Plan¡±, which raised artificial intelligence to the national strategy for the first time. The "Plan" pointed out that artificial intelligence, as the core driving force of the new round of industrial transformation, will further release the enormous energy of previous scientific and technological revolutions and industrial transformation savings, and create new powerful engines to reconstruct production, distribution, exchange, consumption and other economics. All aspects of the activity form new intelligent demands from macro to micro, and promote new technologies, new products, new industries, new formats, new models, trigger major changes in economic structure, profoundly change human production lifestyles and thinking patterns, and achieve The overall jump in social productivity. Last year, a number of personal intelligence related policies were issued at the national level. In this year's "two sessions" government work report, the Prime Minister once again pointed out that the new generation of artificial intelligence research and development applications should be strengthened, and "Internet +" should be promoted in many fields such as medical care, pension, education, culture and sports. Develop smart industries and expand smart life. Nowadays, artificial intelligence as a national strategy is being used as an infrastructure, gradually integrating with the industry, accelerating the optimization and upgrading of the economic structure, and having a profound impact on people's production and lifestyle.CVPR 2018 | Vision Technology Face++ proposes a discriminant feature network for semantic segmentation DFN Global Computer Vision and Pattern Recognition (CVPR 2018) will be held on June 18th. Held in Salt Lake City, USA on the 22nd. As a diamond sponsor of the conference, the Vision Technology Institute will also attend the event under the leadership of Dr. Sun Jian. Thesis link: https://arxiv.org/abs/1804.09337 Lead In a large number of computer vision applications, semantic segmentation is an indispensable underlying technology. Desperate Face++ recently published a paper CVPR 2018, "Learning a Discriminative Feature Network for Semantic Segmentation?", which proposes a discriminant feature network DFN, which effectively solves two basic problems of semantic segmentation, significantly improves its accuracy and can help machines. Eyes better understand complex images and scenes, and analyze static or dynamic human bodies and other objects to help promote the popularization of AI-driven industries such as autonomous driving, mobile phone imaging, medical imaging, unmanned retail, and logistics security. And development. Design Ideas The Discriminative Feature Network (DFN) proposed in this paper contains two sub-networks, Smooth Network and Border Network, which effectively solve the intra-class inconsistency and classes faced by most existing semantic segmentation methods. There is no difference in inter-class indistinction. Specifically, in order to deal with intra-class inconsistencies, the authors specifically designed the Smooth Attitude Block (CAB) and global average pooled Smooth Network to select more discriminative features; the Border Network relied on more Layer semantic boundary supervision distinguishes features on both sides of the boundary. Along with the recent development of convolutional neural networks represented by the Fully Convolutional Network (FCN), many work has achieved remarkable results. However, the characteristics of the above-mentioned network learning often have problems that are not discriminative and difficult to distinguish. The following are: 1) Image blocks with the same label but different appearances, which are called intra-class inconsistencies, as shown in the first line of Figure 1; Two adjacent image blocks have different labels but similar appearance, which is called no difference between classes, as shown in the second line of Figure 1. Figure 1: A tricky example of semantic segmentation. The second column is the output of the FCN model; the third column is the output of the method in this article. In the first line, the lower left corner of the cow in the picture is identified as a horse, which is an in-class inconsistency problem. In the second line, the blue and black chassis on the mainframe are similar to the display, so it is difficult to distinguish, which is a problem of no difference between classes. To address these two challenges, this article rethinks semantic segmentation from a more macro perspective as a task of assigning consistent semantic tags to a class of objects rather than to each single pixel. This requires looking at the pixels of each category as a whole, and at the same time taking into account intra-class consistency and inter-class variation. This means that the task needs to discriminate features, so this paper proposes a new discriminant feature network (DFN) to learn feature representation. The DFN has two components: the Smooth Network and the Border Network. Smooth Network is used to solve in-class inconsistencies and needs to learn a robust feature representation. For this reason, two key factors are considered in this paper. On the one hand, multi-scale and global context features are needed to encode local and global information. For example, due to the lack of sufficient context information, the small white image blocks in Figure 1(a) often fail to predict the correct category; on the other hand, with the introduction of multi-scale contexts, for objects of a certain scale, the features have Different degrees of discriminative power, some of which may predict false labels. Therefore, it is necessary to select an efficient discriminant feature. It is for these two reasons that the Smooth Network is presented as a U-shaped structure to capture context information of different scales and to capture the global context through global average pooling. In addition, the paper also proposes the Channel Attention Module (CAB), which uses high-level features to guide the selection of low-level features step by step. The Border Network is responsible for distinguishing adjacent image blocks that look similar but have different labels. Most existing methods treat semantic segmentation as a densely identified problem and cannot clearly model the relationships between classes. Taking Figure 1(d) as an example, if more and more global contexts are integrated into the classification process, the computer host adjacent to the display is easily misidentified as a display due to its similar appearance. Therefore, it is important to explicitly use semantic boundaries to guide the learning of features, which can enhance the changes on both sides of the feature. During training, the author integrated the semantic boundary loss into the Border Network to learn discriminant features and increase the differences between classes. Network Architecture The DFN network architecture begins with a detailed description of its two components, the Smooth Network and the Border Network. Next, it explains how the two implement intra-class consistency and inter-class differences. Finally, the DFN complete encoder-decoder network architecture is described. . Figure 2: Overview of the discriminant feature network. (a) Network architecture. (b) Optimize the components of the Regression Block (RRB). (c) Components of the Channel Attention Module (CAB). The red and blue lines characterize the upsampling and downsampling operators, respectively. The green line is only the information transfer path and does not change the size of the feature map. -- Most existing methods of Smooth Network cannot guarantee the correct prediction of the category of each image block, especially when the image block belongs to a large area and a complex scene; the main reason for this in-class inconsistency problem is the lack of context. This author proposes a global context with a global average pooling. However, the global context only has high context information and does not help to restore spatial information. Authors need multi-scale receptive fields and contexts to optimize spatial information, just like most existing methods. However, because different scales of receptive fields have different discriminative powers, resulting in inconsistent results, it is necessary to select more discriminative features to predict a uniform semantic label of a particular category. Specifically, this paper uses ResNet as the basic recognition model; according to the feature map size, the model can be divided into five phases. It has been observed that the recognition capabilities at different stages are different and the consistency performance is different. In the low-level stage, the network encodes more refined spatial information, but its semantic consistency is poor due to lack of spatial context guidance and receptive field. In the advanced stage, semantic consistency is better due to larger receptive field. , but the predicted spatial information is rough. Overall, the low-level stage has more accurate spatial predictions, while the advanced stage has more precise semantic predictions. Based on this observation, this paper proposes Smooth Network to integrate the advantages of both, and use the consistency of the advanced stage to guide the low-level stage to obtain the optimal prediction. Figure 3: Channel Attention Module Diagram. In (a), the yellow module characterizes the low-level phase and the red module characterizes the features of the advanced phase. The author combines the features of the adjacent stages to calculate the weight vector, thereby updating the weight of the low-level feature map. Darker modules characterize high weight values. (b) is the true attention value vector for the Phase 4 channel attention module. The deeper the blue, the greater the weight of the representation weight. The popular semantic splitting architecture has two main styles, one is Backbone, such as PSPNet and Deeplab v3; the other is Encoder-Decoder, such as RefineNet and Global Convolutional Network. However, the above architecture is not complete. For this reason, this paper first embeds a global average pooling layer to extend the U-shaped architecture to a V-shaped architecture, and introduces the strongest consistency constraint for the network as a guide. In addition, this paper proposes the channel attention module. Optimize consistency as shown in Figure 2(c). This design combines the features of adjacent stages to calculate the channel attention vector (Fig. 3(b)). The features of the advanced stage give a strong consistency guide, while the features of the low stage give different discriminant information of the features, so that the channel attention vector can select the discriminant features. Channel Attention Module: The CAB is designed to change the feature weights at each stage to optimize consistency, as shown in Figure 3. In the FCN architecture, the convolution operator outputs a score map giving the probability of each category on each pixel. Its practical significance is to imply that the weights of different channels are equal. However, as described above, the feature discriminating powers at different stages are different, resulting in different consistency of prediction. In order to achieve consistent prediction within the class, the discriminant features should be extracted and the non-discriminant features should be suppressed, so that the discriminant features can be obtained step by step to achieve intra-prediction consistency. Optimized residual module: The feature map of each stage in the feature network passes through the RRB, as shown in Figure 2(b). The first component of the module is a 1 x 1 convolutional layer, which the author uses to unify the number of channels to 512. At the same time, it can integrate information from all channels. This is followed by a basic residual module that optimizes the feature map. In addition, inspired by ResNet, the module also enhances the recognition capabilities of each stage. --Border Network In the semantic segmentation task, predictions often confuse different categories with similar appearance, especially when they are spatially similar, so it is necessary to increase the difference of features. For this reason, this paper uses semantic boundaries to guide feature learning, and applies explicit supervision to extract precise semantic boundaries, so that the network learns the characteristics of strong differences between classes, and then proposes the Border Network to increase the inter-class differences of features. The Border Network directly learns semantic boundaries through explicit semantic boundaries, similar to semantic boundary detection tasks. This makes the features on both sides of the semantic boundary distinguishable. The work of this paper requires semantic boundaries to have more semantic meaning. So the Border Network is designed from the bottom up. It can obtain accurate boundary information from the low-level stage and obtain semantic information from the advanced stage, thus eliminating some original boundaries that lack semantic information. Thus, the semantic information of the advanced stage can optimize the detail boundary information of the low-level stage step by step. With traditional image processing methods, such as Canny, authors can obtain network supervision signals from the semantically segmented groundtruth. The Border Network focuses on the semantic segmentation of categories on both sides of the separation boundary. To accurately extract semantic boundaries, the features on both sides need to be more distinguishable, and this is the purpose of the author. -- Network structure authors use pre-trained ResNet as the underlying network. Smooth Network adds the global average pooling layer at the top of the network for maximum consistency; then uses CAB to change the weight of the channel to further improve consistency. At the same time, the Border Network obtains precise semantic boundaries through explicit semantic boundary supervision and makes the features on both sides more distinguishable. As a result, intra-class features are more consistent, and inter-class features are more easily distinguishable. For explicit feature optimization, multiple layers of supervision are required for better performance, while the network is easier to train. Smooth Network supervises the upsampling output of each stage with softmax loss (except for the global average pooling layer), and this paper supervises the output of the Border Network with focal loss. The two sub-networks are jointly trained, and their loss controls the weight of both by a parameter. Experimental Results This paper evaluates this approach on two open source datasets, PASCAL VOC 2012 and Cityscapes. Data set introduction, implementation details analysis, etc. are omitted, this article will directly give the final evaluation results of DFN, please refer to the original paper for more. Table 5: Performance of the DFN on the PASCAL VOC 2012 test set. The method of pre-training on MS-COCO is marked with "+". Table 6: Performance of DFN on the Cityscapes test set. "-" indicates that the method did not show the results in published papers. Conclusion In conclusion, the contribution of this paper has four main aspects: - Rethinking semantic segmentation from a new macro perspective, as a way to assign consistent semantic tags to a class of objects (not just at the pixel level) ) the task. - Propose DFN to solve both intra-class consistency and inter-class differences. DFN achieved 86.2% and 80.3% of the current optimal mean IOU on the PASCAL VOC 2012 and Cityscapes data sets, respectively, confirming the effectiveness of the method. - Propose Smooth Network to improve intra-class consistency through global context and channel attention modules. - Propose a bottom-up Border Network that uses multi-layer boundary supervised signals to increase feature changes on both sides of the semantic boundary while optimizing the semantic boundaries of the prediction.Artificial intelligence presses "fast forward button" On October 31, General Secretary Xi Jinping emphasized that the artificial intelligence is an important driving force for a new round of scientific and technological revolution and industrial transformation, and accelerates the development of a new generation of artificial intelligence. It is a strategic issue concerning whether China can seize the new round of scientific and technological revolution and industrial transformation opportunities. It is necessary to profoundly understand the great significance of accelerating the development of a new generation of artificial intelligence, strengthen leadership, plan well, clarify tasks, lay a solid foundation, promote its deep integration with economic and social development, and promote the healthy development of China's new generation of artificial intelligence. In recent years, China's artificial intelligence industry has developed rapidly, and a large number of leading scientific research achievements and global leading enterprises have emerged. At the 5th World Internet Conference held in Wuzhen, Zhejiang Province, 15 ¡°World's Leading Scientific and Technological Achievements in the Internet¡± were released, and a number of domestic enterprises led by artificial intelligence research and development were selected. The "China Artificial Intelligence Development Report 2018" released by Tsinghua University shows that the development of artificial intelligence in China has entered the international leading group. However, the industry also pointed out that there are still practical problems such as relatively weak core technology fields and insufficient attention to artificial intelligence ethics and security regulations. Popularity is concerned about the fastest growth of heat. ¡°The feeling of sitting in an unmanned car is particularly cool!¡± Last weekend, 7-year-old Zhang Tianran¡¯s children and family rushed from Haixing Park in Beijing to Haidian Park. They waited for an hour and a half and finally got into the park. The "Apollon" unmanned passenger car. Zhang Tianran¡¯s mother said: ¡°It¡¯s safe to sit in an unmanned vehicle. As long as there is something in front, the car can stop immediately.¡± From November 1st, Beijing Haidian Park turned into an artificial intelligence park. Citizens can ¡°swipe face¡± on the smart track to check the movement, sing and chat with the voice assistant in the smart pavilion, practice Tai Chi through a screen equipped with augmented reality (AR) technology... The park has already served 100,000 visitors. People. In the unmanned vehicle waiting point, the reporter saw that 30 or 40 citizens were waiting in line, mostly with the elderly and children. "Apolon" is the country's first commercial-grade driverless electric vehicle. There is no steering wheel, brakes and throttle on the car, and the safety officer controls the vehicle through an electronic screen. Due to the limited capacity of unmanned vehicles, many people who have not experienced the experience are very sorry and have said that they will come again next time. "China Artificial Intelligence Development Report 2018" shows that from 2016 to 2017, artificial intelligence has soared, becoming the fastest growing science topic in the year. According to the survey, more than half of the respondents supported the full development of artificial intelligence, and only 6.23% of the respondents did not understand artificial intelligence. Artificial intelligence products are not at the stage of early adopter experience, and many products have already entered thousands of households. For example, all kinds of smart speakers, only with a light call, the room lights, air conditioning, air purifier should be turned on. ¡°The essence of smart home is to continuously iteratively update and continuously provide a smarter and more intimate user experience. In the past, smart home products cost high and maintenance costs are high. We started from developing WiFi modules to solve the wireless connection problem of smart homes and let smart The iteration of home software upgrades has become possible, reducing the cost of use, allowing smart homes to enter the two-bedroom and one-bedroom of the hotel from the past hotel villas, and has been recognized by users.¡± Industry insiders pointed out that the grounding gas vertical field is everywhere. ¡°Headaches can¡¯t sleep, Which department is attached?¡± The reporter entered the physical condition on the WeChat public account ¡°Internet Hospital of the First Affiliated Hospital of Xiamen University¡±. After consulting the age, gender and other symptoms in detail on the public number, Dr. Li Jun recommended Dr. Li Jun to the journalist's outpatient clinic. "Xiao Jia doctor" is not a real person, but an artificial intelligence assistant. The patient can easily find the corresponding department under the guidance of ¡°Xiao Jia Doctor¡± by typing or voice-speaking symptoms. Behind the ¡°Doctor Xiao Jia¡± is the AI+ medical project that uses artificial intelligence technology in the medical field. At present, this intelligent guiding technology has covered the whole family of diseases, and the accuracy of the consultation is 98%. In addition to the consultation, Tencent Yingying also uses artificial intelligence technology to analyze medical images, and can watch 10 films in a second to help doctors screen for breast cancer, esophageal cancer, diabetic retinopathy and other diseases. In recent years, artificial intelligence is no longer the "high-precision" technology in the ivory tower. The "2018 World Blueprint for Artificial Intelligence Industry Development" shows that artificial intelligence has penetrated into vertical fields such as medical, financial, commercial, educational, security, and even applications. In manufacturing and agricultural production. In the streets and lanes, artificial intelligence can act as a patrolman to monitor and report sudden safety incidents in real time; in the field, artificial intelligence becomes a technician to help monitor and analyze soil moisture, temperature, light, pH, and achieve precise fertilization; In the factory technical workshop, artificial intelligence became a quality inspector, and the non-conforming products on the assembly line were continuously selected and filtered. In Shenzhen, relying on artificial intelligence, big data and other technologies of the "urban traffic brain" to make traffic more smooth. Shenzhen Traffic Police established a real-time monitoring system for all signalized intersections in the city, and formulated precise traffic signal management and control modes; using artificial intelligence technology to identify illegal pictures, the recognition accuracy rate was over 95%, and the efficiency was increased by 10 times. In 2017, the road traffic accident rate in Shenzhen and the road traffic congestion index in the city declined, and the urban traffic civilization index increased significantly. "In the purely technical field, the United States is in a dominant position in basic theories, innovative algorithms and chips, but China has its own advantages in industrialization structure, data level, policy support, and infrastructure transformation." The world's leading November 7th, the 5th World Internet Conference released 15 "World's leading Internet technology achievements." These results have been selected from more than 400 results in more than 20 countries around the world, demonstrating the latest technology in the global Internet arena. Among them, 360 security brain-distributed intelligent network security defense system, Jingdong intelligent supply chain technology service platform, Baidu Apollo automatic driving open platform, Xiaomi's artificial intelligence open platform for smart home... many domestic enterprise-led artificial intelligence research and development results Selected. "To make breakthroughs in artificial intelligence research, on the one hand, we must have high-tech talents who have researched and can integrate the cutting-edge algorithms. On the other hand, we must be able to combine algorithms with real-world industries, which requires a large amount of data as support and business. A deep understanding of the scene and vertical industry," said Li Jiwei, Ph.D., Ph.D., Department of Computer Science, Stanford University. According to China Artificial Intelligence Development Report 2018, the number of Chinese artificial intelligence papers and high-frequency citations is the highest in the world, the number of artificial intelligence patents is the largest in the world, and the total number of artificial intelligence talents ranks second in the world. At the same time, the number of artificial intelligence enterprises in China ranks second in the world, and it has become the largest country in the world for artificial intelligence investment and financing. In 2017, the State Council issued the ¡°New Generation Artificial Intelligence Development Plan¡± and established the ¡°three-step¡± strategy for the development of artificial intelligence. Local governments have also introduced corresponding policies to promote the development of artificial intelligence. On September 17 this year, during the World Artificial Intelligence Conference, Shanghai issued the ¡°Implementation Measures for Accelerating the High-quality Development of Artificial Intelligence¡±, and proposed 22 articles on five aspects: gathering high-end talents, breaking through core technologies, and promoting demonstration applications. Specific measures to promote the development of artificial intelligence. Industry insiders pointed out that although China's artificial intelligence development has entered the international leading group, there are still problems such as weak core technology fields, shortcomings in the combination of production and research, and insufficient attention to artificial intelligence ethics and safety regulation. "Developing artificial intelligence should pay attention to prevent legal and ethical risks. The legislation of artificial intelligence should focus on network security and user rights, and promote the development and standardization of artificial intelligence, and implement the main responsibility of the platform and the legal bottom line. Artificial intelligence Legislation can be separately legislated or classified into legislation. For example, there are special laws for unmanned driving and smart home. It can also be stipulated by covering legislation and reclassified.¡± Relevant experts artificial intelligence industry background and development trend AI, full name is Artificial Intelligence, the meaning of artificial intelligence. It is a new technical science that studies and develops theories, methods, techniques, and application systems for simulating, extending, and extending human intelligence. Since the birth of artificial intelligence, the theory and technology have become more and more mature, and the application field has been expanding. It is conceivable that the technological products brought by artificial intelligence in the future will be the "container" of human wisdom. Artificial intelligence is a challenging science, and people who do this work must understand computer knowledge, psychology, and philosophy. Artificial intelligence is a very broad science that consists of different fields, such as machine learning, computer vision, etc. In general, one of the main goals of artificial intelligence research is to make machines capable of doing what is usually required by human intelligence. Complex work. The development of AI In 1950, a senior student named Marvin Minsky ("Father of Artificial Intelligence") and his classmate Dunn Edmund built the world's first neural network. computer. Also in 1950, Alan Turing, known as the "father of computers," presented a world-famous idea - the Turing test. According to Turing's vision: If a machine can talk to humans and cannot be identified as a machine, then the machine is intelligent. And just this year, Turing also boldly predicted the feasibility of truly intelligent machines. Time has jumped to the 70s, and artificial intelligence has entered a period of hardships and obstacles. For the research of artificial intelligence, the researchers have underestimated the difficulty and lack of funds. As a result, the cooperation plan with the US Defense Advanced Research Projects Agency failed, and the pressure of public opinion began to slowly press on the artificial intelligence side, resulting in many research funding. It has been transferred to other projects, which also makes everyone worry about the future of artificial intelligence. The artificial intelligence industry is facing decline, but technology will not stop developing due to external factors. Until the early 1980s, the artificial intelligence industry began to rise. Today, in the development process of artificial intelligence nearly 70 years, scientific and technical personnel continue to break through the obstacles. Let us see the brilliant achievements of artificial intelligence today, 2016 Google AlphaGO defeated South Korea Li Shizhen. This is also a landmark symbol of artificial intelligence over humanity. The current situation of the artificial intelligence industry The current development of the artificial intelligence industry is mainly due to the introduction of deep learning algorithms, and the realization of large-scale calculations based on the amount of data and computing power is a technical breakthrough. Belonging to super artificial intelligence, there is still room for further breakthroughs in basic theoretical research on the origin of consciousness and the mechanism of human brain. At present, the five giants such as Apple, Google, Microsoft, Amazon, and Facebook have all invested more and more resources to seize the artificial intelligence market, and even transform themselves into artificial intelligence-driven companies. The domestic Internet leader "BAT" also regards artificial intelligence as a key strategy, and actively lays out the field of artificial intelligence by virtue of its own advantages. Today's artificial intelligence industry in China has a wide range of development areas, with the largest number of startups in the field of computer vision, followed by the field of service robots, and the third in the field of speech and natural language processing, smart medical, machine learning, smart driving, etc. It is also one of the more popular areas. Computer vision technology is one of the important core technologies of artificial intelligence. It can be applied to security, finance, hardware, marketing, driving, medical and other fields. At present, China's computer vision technology has reached the global leading level, and extensive commercial channels and technologies. The foundation is the main reason for its becoming the hottest area. The artificial intelligence industry chain can be divided into infrastructure layer, application technology layer and industry application layer. Base layer: mainly basic data providers, semiconductor chip suppliers, sensor suppliers and cloud service providers; technology layer: mainly voice recognition, natural language processing, computer vision, deep learning technology provider; application layer: mainly Artificial intelligence-related technologies are integrated into their own products and services, and then cut into specific scenarios. At present, the fields of autonomous driving, medical care, security, finance, marketing, etc. are generally more optimistic about the direction of the industry. Future Trends of Artificial Intelligence Artificial intelligence is a simulation of the information process of human consciousness and thinking. Artificial intelligence is not human intelligence, but it can be like human thinking, and it may exceed human intelligence. A robot is a form of artificial intelligence, an automatic machine that mimics certain activities of a person. Generally, actions such as walking and operating production tools can be realized, and it is possible to replace people's work in an environment that people cannot adapt. Modern robots are equipped with electronic computers. Through programming procedures, they can have a certain degree of artificial intelligence, such as recognizing languages ??and images, and making appropriate responses. Past technological advances have primarily focused on improving the ability to perform assigned tasks. Today's artificial intelligence gives machines the ability to react and adapt to optimize output. Through the combination of technologies such as the Internet of Things and robots, artificial intelligence can construct an integrated world of information physics. Today's artificial intelligence is gaining momentum, and it is expected to be widely used in many industries and scenarios around the world. In particular, we will see a lot of human work being replaced by machines. Of course, technical feasibility is only one factor that affects the speed and extent of automation. There are other factors to consider, including R&D and application costs, labor market supply and demand, economic benefits, and acceptance by social and government regulators. Looking ahead, artificial intelligence can be a powerful tool for addressing some of the core challenges of society. In the medical field, artificial intelligence will greatly enhance our ability to analyze the human genome and develop personalized treatment options for patients, and even greatly accelerate the process of curing cancer, Alzheimer's disease and other diseases. In the field of environmental protection, artificial intelligence can analyze climate characteristics and reduce energy consumption on a large scale, helping humans to better monitor and respond to climate change issues. Artificial intelligence can even function outside the Earth, and he can help humans explore Mars and outer space.CVPR 2018 | Born to Mobile AI - The Latest Achievements in Face++ ShuffleNet Comprehensive Interpretation Convolutional Neural Networks (CNN) play a vital role in visual artificial intelligence systems. Recently, the Face++ Institute published "ShuffleNet: an extremely efficient mobile convolutional neural network" article. The author proposed a more efficient convolution model structure for mobile low-power devices. Significantly reduce the computational complexity of the model while still maintaining a high recognition accuracy, and significantly exceeds the same method in multiple performance indicators. This article will explain the results in detail. The paper download address: https://arxiv.org/abs/1707.01083 Design Thought Convolutional neural network is the core component of modern visual artificial intelligence system. In recent years, research on convolution models has emerged in an endless stream, resulting in high-performance network structures such as VGG, ResNet, Xception, and ResNeXt, surpassing human levels in multiple visual tasks. However, these successful models are often accompanied by huge computational complexity (billions of floating point operations, and even more). This limits the ability of such models to be used only for high-performance server clusters, and for many mobile applications (usually allowing up to millions to tens of millions of floating-point operations). One way to solve this problem is to design a more lightweight model structure. The vast majority of computational complexity of modern convolutional neural networks is concentrated on convolution operations, so efficient convolutional layer design is the key to reducing network complexity. Among them, sparse connection is an effective way to improve the efficiency of convolution. Many excellent convolution models have followed this idea. For example, Google's "Xception" network [1] introduced the concept of "deep separable convolution", which splits ordinary convolution operations into depthwise convolution and pointwise convolution. The Department has effectively reduced the amount of calculations and parameters; Facebook's "ResNeXt" network [2] first uses point-by-point convolution to reduce the number of channels of input features, and then uses less computational packet convolution (group convolution) The structure replaces the original convolution operation, which also reduces the overall computational complexity. The ShuffleNet network architecture also follows the design philosophy of sparse connections. By analyzing the Xception and ResNeXt models, the author finds that the computational complexity of these two structures is reduced by the convolution kernel. However, the computational complexity of the point-by-point convolution is quite considerable. A new bottleneck. For example, the point-by-point convolution of the ResNeXt model occupies 93.4% of the computational complexity. It can be seen that in order to further increase the speed of the model, it is necessary to seek a more efficient structure to replace point-by-point convolution. Inspired by ResNeXt, the authors propose to use group pointwise convolution instead of the original structure. By limiting the input of the convolution operation to each group, the amount of computation of the model has dropped significantly. However, this also brings obvious problems: in multi-layer point-by-point convolution stacking, the information flow of the model is divided into groups, and there is no information exchange between groups (as shown in Figure 1(a)). . This will affect the presentation ability and recognition accuracy of the model. Figure 1 Point-by-point convolution and channel reordering operations Therefore, while using packet point-by-point convolution, it is necessary to introduce a mechanism for information exchange between groups. That is to say, for the second layer of convolution, each convolution kernel needs to receive the characteristics of each group as input at the same time, as shown in Figure 1(b). The authors point out that this mechanism can be easily implemented by introducing "channel shuffle" (see Figure 1(c)); and because the channel rearrangement operation is tunable, it can be embedded in the network structure. Learning to the end. The network structure is based on packet point-by-point convolution and channel reordering operations. The authors propose a new ShuffleNet structural unit, as shown in Figure 2. This structure inherits the design philosophy of ResNet [3], and based on this, a series of improvements have been made to improve the efficiency of the model: First, replace the original 3x3 convolution with channel-by-channel convolution. Reduce the complexity of the extraction space feature of the convolution operation, as shown in Figure 2 (a); then, the first two 1x1 point-by-point volume integration in the original structure, and add channel reordering operation between the two layers, further Reduce the amount of cross-channel computation of convolution operations. The final structural unit is shown in Figure 2(b). Similarly, another structural unit (Fig. 2(c)) is proposed in this paper, which is specifically used for downsampling of feature maps. With the ShuffleNet building block, the author built a complete ShuffeNet network model. It is mainly composed of 16 ShuffleNet structural units, which are divided into three phases of the network. The space size of the feature map is halved and the number of channels is doubled. The total calculation for the entire model is approximately 140 MFLOPs. By simply scaling the number of channels in each layer, you can get other models of arbitrary complexity. In addition, it can be found that the more the number of packets in the convolution operation, the lower the calculation amount of the model; this means that when the total calculation amount is constant, the larger number of packets can allow more channels, which the author believes will It helps the network to encode more information and enhance the recognition ability of the model. Figure 2 ShuffleNet Structural Unit Experiment Results The authors illustrate the need for each component of the ShuffleNet building block and its superiority to other network building blocks through a series of control experiments on the ImageNet 2016 classification data set. The author then demonstrates the generalization capabilities of the model through the results of the MS COCO target detection. Finally, the authors give the acceleration of ShuffleNet's actual operation on the ARM computing platform. Packetized point-by-point convolution authors for the ShuffleNet model with computational complexity of 140 MFLOPs, 40 MFLOPs, and 13 MFLOPs, while controlling the complexity of the model, comparing the number of grouped point-by-point convolutions at 1 to 8 for performance Impact. As can be seen from Table 1, the network with packets (g>1) always has a lower error rate than the network without packets (g=1). The authors observe that for smaller networks (such as ShuffleNet 0.25x), larger packets will give better results, and that wider channels are especially important for small networks. Inspired by this, the author removed the two structural units of the third phase of the network, and the network performance was further improved after the amount of computation saved was used to increase the network width. Table 1 Effect of group number on classification error rate The purpose of channel rearrangement channel rearrangement is to enable inter-group information to communicate with each other. In the experiment, the network with channel rearrangement is always better than the network without channel rearrangement, and the error rate is reduced by 0.9%~4.0%. Especially when the number of groups is large (such as g=8), the former is far superior to the latter. Using the same overall network layout as the other structural unit authors, the ShuffleNet structural unit was replaced with the structural elements in VGG-like, ResNet, Xception-like, and ResNeXt while maintaining computational complexity, using exactly the same training method. The results in Table 2 show that ShuffleNet is always superior to other networks at different computational complexity. Table 2 Comparison of classification error rates with other network structures (percentile) vs. MobileNets and other network structures Recently, Howard et al. proposed MobileNets [4], using the channel-by-channel convolution design [1] for efficient networks on mobile devices. structure. Although ShuffleNet is designed for models smaller than 150 MFLOPs, it is still superior to MobileNet in increasing the 500~600 MFLOPs to MobileNet. At 40 MFLOPs, ShuffleNet is 6.7% lower than the MobileNet error rate. Detailed results can be obtained from Table 3. Table 3 ShuffleNet vs. MobileNet Compared to some other network structures, ShuffleNet also shows great advantages. As can be seen from Table 4, ShuffleNet 0.5x achieves AlexNet performance with only 40 MFLOPs, while AlexNet has a computational complexity of 720 MFLOPs, which is 18 times that of ShuffleNet. Table 4 Comparison of computational complexity of ShuffleNet and other network structures MS COCO object detection Under the framework of Faster-RCNN[5], compared with 1.0 MobileNet-224 network complexity ShuffleNet 2x, the mAP on the 600 resolution map reaches 24.5 %, while MobileNet is 19.8%, indicating that the network is well generalized in detection tasks. Actual running speed The author finally tested the actual running speed of the network on an ARM platform. In the author's implementation, 40 MFLOPs' ShuffleNet compares to the similar precision of AlexNet, which is about 13x faster. The 224 x 224 input takes only 15.2 milliseconds to complete a reasoning, and it takes only 260.1 milliseconds at 1280 x 720 input. Applications Many important computer vision tasks that require semantic information, such as target detection, object recognition, etc., require a good "base model" as a feature extractor. As mobile devices become more important today, the more visual algorithm models that run on them, the higher the accuracy requirements will be. Regardless of target detection and recognition, face detection and recognition, or image stylization editing, beauty, or live user behavior analysis, the support of the basic model is indispensable. A good foundation model can make a model that cannot run efficiently on a mobile phone because the original computing power demand is too large to run efficiently, making many impossible possibilities possible. In addition, other commonly used model compression techniques, such as sparseization and network quantification, can also be applied to ShuffleNet to improve storage efficiency and speed, further reducing the threshold for visual algorithms and applications.CVPR 2018 | Vision Technology Face++ proposes RepLoss to optimize dense occlusion problems CVPR 2018 (Conference on Computer Vision and Pattern Recognition, IEEE International Computer Vision and Pattern Recognition Conference) will be held from June 18th to 22nd Held in Salt Lake City, USA. As a diamond sponsor of the conference, the Vision Technology Institute will also attend the event under the leadership of Dr. Sun Jian. Link to the paper: https://arxiv.org/abs/1711.07752 Lead crowd detection is a key link that cannot be bypassed by the development of computer vision technology. The problem of crowd occlusion is one of the most challenging problems. Desperate Technology Face++ proposes a new crowd detection and location model Repulsion Loss (RepLoss) from the bottom of the technology, which solves this problem to a considerable extent. The application scope of the underlying technological innovation is extremely wide, which means that most of the product applications related to crowd detection can be improved to different degrees, fundamentally promoting security monitoring, automatic driving, unmanned retail, and the development and development of smart cities. . In addition, the detection target of the population positioning technology RepLoss is not limited to humans, but can also be generalized to general object detection. The underlying innovation driving force has a wide range, which helps the eyes of the machine to create a person, thing, word and car. The detection matrix will further see and understand the world. RepLoss design thinking to detect pedestrians in the crowd is still a challenging problem, because in real-life scenes, pedestrians often gather in groups and occlude each other. In general, object occlusion problems can be divided into two types: intra-class occlusion and inter-class occlusion. Inter-class occlusion arises from similar objects that are piled up, also known as crowd occlusion. In pedestrian detection, dense occlusion is the largest of all occlusion problems, seriously affecting the performance of pedestrian detectors. The main impact of dense occlusion is the significant increase in the difficulty of pedestrian positioning. For example, when the target pedestrian T is blocked by pedestrian B, the detector may not be able to locate because of the similar appearance characteristics of the two. Therefore, the bounding box of T should be framed to be bound to B, resulting in inaccurate positioning. To make matters worse, since the non-maximum suppression (NMS) needs to further process the main detection results, the bounding box removed from T may be suppressed by the prediction frame of B, which may cause T miss detection. That is, crowd occlusion makes the detector sensitive to NMS thresholds: higher thresholds lead to more false positives, and lower thresholds cause more missed detection. This will invalidate most instance partitioning frameworks because they also require accurate detection results. Therefore, how to accurately locate each pedestrian in the crowd is one of the most critical issues for detectors. Figure 1: RepLoss icon. In the current optimal detection framework, bounding box regression techniques are often used to locate objects, where the regressions are trained to narrow the gap between the proposal and the groundtruth box (measured by some distance metrics such as Smooth_L1 or IoU). However, existing methods only require the proposal to be close to its intended target, regardless of the surrounding objects. As shown in Figure 1, in the standard bounding box regression loss, there is no additional penalty for the prediction frame when it moves to the surrounding object. This inevitably envisions: If you want to detect a target among the people, should you consider the positioning of the surrounding objects? Inspired by the mutual attraction of magnetic poles, this paper proposes a new positioning technology called Repulsion Loss (RepLoss), through which each proposal will not only be close to its specified target T, but also away from other groundtruth objects and specified targets. Not other proposal of T. As shown in Figure 1, the red bounding box moving to B will be subject to additional penalties due to overlap with surrounding non-target objects. Therefore, RepLoss can effectively prevent the prediction bounding box from moving to adjacent overlapping objects, improving the robustness of the detector in the crowd scene. Impact of dense occlusion This section will explore how the current optimal pedestrian detector is affected by the crowd occlusion and gain a deeper understanding of the dense occlusion problem. Dense occlusion mainly causes two problems, missed detection and false detection. The following two explanations are respectively explained. The baseline detector is the Faster R-CNN optimized for pedestrian detection and uses the new pedestrian detection data set. CityPersons?. Figure 3: Error detection analysis of baseline and RepGT. Figure 3(a) is the number of missed detections on the reasonable-crowd subset for different detection scores, and the red line indicates the number of groundtruth pedestrians missed by the baseline. In real-world applications, only the prediction bounding box with high confidence is considered. The high leakage check at the left end of the curve means that it is far from the actual application. Figure 3(b) shows the proportion of false detections caused by dense occlusions to all false detections. The red line indicates that the baseline ratio is about 20%. As shown in the red and blue lines in Figure 3, the RepGT loss effectively reduces the number of missed and misdetected by dense occlusion. Figure 4: Visualization example of error detection. The red box indicates a false detection caused by dense occlusion. As shown in Figure 4, the green box is the correct prediction bounding box, while the red box is a false detection caused by dense occlusion and gives the confidence value of the detector. If the prediction frame moves slightly or significantly to an adjacent non-target groundtruth object (such as the upper right image), or frames several overlapping parts of the occlusion object (such as the lower right image), a detection error often occurs. In addition, detection errors caused by dense occlusion often have a high degree of confidence, resulting in high ranking misdetections. This suggests that in order to improve the robustness of the detector in dense scenes, there is a need for more discriminative losses in performing bounding box regression. Here's another visual example: Figure 9: Baseline vs. RepLoss. The blue box indicates a false check and the red box indicates a missed check. The first line of the upper and lower parts of the gray dotted line is the predicted result of the baseline; the second line is the predicted result after adding RepLoss. Analysis of the error detection shows that the impact of dense occlusion on the pedestrian detector is surprising, not only the main source of missed detection, but also increases the difficulty of positioning while causing more false detections. In order to solve the above problems and improve the robustness of the pedestrian detector in dense scenes, RepLoss was proposed. RepLoss Calculation Methods This section will detail how to calculate RepLoss. Inspired by the magnet properties, RepLoss consists of 3 components, denoted as: ?? where L_Attr is the attracting item, and the prediction box needs to be close to its specified target; L_RepGT and L_RepBox are exclusive items, respectively, need to predict the box away from other groundtruth objects and other Specify a forecast box with a different target. The coefficients ¦Á and ¦Â act as weights to balance the auxiliary losses. For the sake of simplicity, only two types of tests are considered below, assuming all groundtruth objects belong to the same category. Let P = (l_P, t_P, w_P, h_P)? and G = (l_G, t_G, w_G, h_G)? be the proposal bounding box and the groundtruth bounding box, respectively, and be represented by their upper left point coordinates and their height and width. . P_+ = {P}? is a collection of all positive proposals (those with a high IoU and at least one groundtruth box are considered positive samples, and vice versa); G = {G}? is a groudtruth box in a picture Collection. -- Attracting items This article uses Smooth_L1 to construct an attraction. Given a proposal P ¡Ê P_+, the groundtruth box with the maximum value IoU is taken as its specified target: G^P_Attr = arg max_G¡ÊG IoU(G,P). B^P is the prediction box that returns from proposal P. The resulting loss can be calculated as: ?--Rejection (RepGT) RepGT loss is intended to cause the proposal to be rejected by adjacent non-target groundtruth objects. Given a proposal P ¡Ê P_+, its repelling groundtruth object is defined as a groundtruth object with the largest IoU region in addition to its specified target. Inspired by IoU loss, the RepGT loss is calculated to penalize the overlap between B^P and G^P_Rep (defined by IoG). IoG(B, G) ¡Ê [0, 1]?, so that the RepGT loss can be written as: ?? Smooth_ln? is a smooth ln function in the interval (0, 1)? continuous and differentiable, ¦Ò ¡Ê [0, 1) is a smoothing parameter that adjusts the sensitivity of RepLoss to outliers. It can be seen that the more prosorous the object overlaps with the non-target groundtruth object, the greater the penalty for the RepGT loss to the bounding box regressor, thus effectively preventing the bounding box from moving to the adjacent non-target object. -- RepBox NMS is an indispensable post-processing step in most detection frameworks. To reduce the sensitivity of the detector to NMS, the authors then propose a RepBox loss, intended to exclude proposals from different specified targets. The RepBox loss can be calculated as: ? As can be seen from the above equation, in order to minimize the RepBox loss, the IoU area between the two prediction frames with different target requirements needs to be smaller. This means that RepBox loss can reduce the probability that the bounding boxes of different regression targets will merge into one after NMS, making the detector more robust in dense scenes. RepLoss Experimental Results This section will directly present the results of RepLoss' evaluations on the datasets CityPersons and Caltech-USA?, including the evaluation and analysis of RepGT losses and RepBox losses on CityPersons, respectively; RepLoss and current currents on CityPersons and Caltech-USA The superior method is relatively comparable. The experimental setup and implementation details are omitted. For more information, please refer to the original paper. Table 3: RepLoss pedestrian test results evaluated on CityPersons. The model is trained on the training set and tested on the validation set. ResNet-50? is the backbone. The best 3 results are marked as red, blue, and green. Table 4: Calech-USA test set (reasonable) results evaluated in the new note. At the 0.5 IoU threshold, the authors further advanced the current optimality to a significant 4.0 MR^?2 on a strong baseline. When the IoU threshold is increased to 0.75, the continuous rise proves the validity of RepLoss. Figure 7: Visualization comparison of the prediction box before the NMS of the baseline and RepBox. There are fewer predictions between two adjacent groundtruth in the RepBox result, and the distribution of the bounding box of the model output is more clear. Figure 10: More CityPersons dataset detection instances (slide left and right to see more). The green box is the predicted pedestrian with a score ([0, 1.0])? greater than 0.8. Conclusion RepLoss is designed for pedestrian detection, especially for the detection performance of dense scenes. The main idea is that the attraction loss of the target object is not enough to train the optimal detector. The loss of repulsive damage from surrounding objects is also crucial. In order to fully exploit the potential of rejection, this paper proposes RepGT and RepBox, and has achieved the current optimal level in the popular datasets CityPersons and Caltech-USA. In particular, the results herein are superior to the previous best results using pixel annotations of approximately 2% without pixel annotation. The comparison of detailed experimental results confirms the value of RepLoss in greatly improving the detection accuracy in occlusion scenarios, and the general object detection (PASCAL VOC)? results further demonstrate its effectiveness. The author hopes that RepLoss will be more widely used in many other object detection tasks.Artificial intelligence is led to change and the traditional industrial technology upgrade is expected to become a hurdle? The Political Bureau of the CPC Central Committee held the ninth collective study on the status quo and trend of artificial intelligence development on October 31. The meeting emphasized that artificial intelligence has a strong "head geese" effect. Promoting the development of a new generation of artificial intelligence has become the key to winning the initiative of science and technology competition. The development of this undertaking is not only related to economic, social, and international political and economic patterns, but also an important thrust for China's scientific and technological development, industrial upgrading, and productivity improvement. Artificial intelligence has become a strategic technology that leads a new round of technological revolution and industrial transformation. Artificial intelligence has been given the lead to change. The conference proposed that artificial intelligence has multi-disciplinary and highly complex features. Therefore, it is necessary to strengthen the research of basic theories and support scientists to brave the "no-man's land"; focus on key core technologies and establish problem-oriented consciousness. Grasp the shortcomings; strengthen the application of science and technology, adhere to the demand-oriented, market-driven technological development path; promote the construction of talent teams, and create a multi-form, high-level talent training platform. The integration of artificial intelligence and industry is the general trend. The meeting proposed to build a modern economic system, requiring artificial intelligence to play a fusion effect in various fields, relying on "mobile Internet, big data, supercomputing, sensor network, brain science, etc." to form resonance, improve total factor productivity; cultivate artificial intelligence enterprises And the industry's "leaders", to play its technical endowments in industrial upgrading, product development, service innovation, etc.; empower the construction of information infrastructure to improve its level of intelligence. From the government work report at the beginning of the year to the information consumption planning in the middle of the year, and then to the global artificial intelligence held in Shanghai in September, and now the collective learning of the Central Political Bureau, artificial intelligence has always been an important direction for all policy direct operations, showing national leadership. The layer attaches great importance to the influence of artificial intelligence on the Chinese economy and the overall people's livelihood. Therefore, in the future, artificial intelligence is expected to help the country achieve various plans such as comprehensive industrial upgrading, supply-side reform, and industrial added value. China's AI scale grows first. At present, governments in various countries have intensively released artificial intelligence strategies, and technology giants have also raised their codes. Following China's release of the "New Generation of Artificial Intelligence Development Plan" in July 2017, countries around the world have been following up intensively since 2018. In March, France announced the development strategy of artificial intelligence, and proposed to invest 1.5 billion euros by 2022, April. The United Kingdom released the "British Artificial Intelligence Development Plan, Capabilities and Aspirations". The EU submitted the "EU Artificial Intelligence" report and proposed three major goals. In July, the German government adopted the "Artificial Intelligence Strategic Plan" to create an artificial intelligence powerhouse, September USA. The House of Representatives issued the AI ??White Paper "The Rise of Machines: Artificial Intelligence and the Growing Impact on US Policy." According to statistics from the Prospective Industry Research Institute's "Prospective Market Analysis and Investment Strategy Planning Analysis Report", the scale of China's artificial intelligence market reached only 5 billion yuan in 2014. By 2016, the scale of China's artificial intelligence market exceeded 10 billion yuan. , reached 10.06 billion yuan. After 2017, the scale of China's artificial intelligence market exceeds 15 billion yuan. It is estimated that the scale of China's artificial intelligence market will exceed 23 billion yuan in 2018, the fastest growth rate in the world, and it is expected to surpass the United States in 2025. Is the upgrading of traditional industrial technology expected to become a hurdle? With the accelerated transition of the mobile Internet era to the new era of artificial intelligence, AI will accelerate its empowerment and bring opportunities and development potential to various traditional industries such as medical, financial, security, education, transportation, and logistics. Among the six major industries in which the development of artificial intelligence technology will face changes, the transportation industry has emerged as a very important part, and it is widely believed that it will be the first to revolutionize the AI ??technology. AI+ medical care is also the key direction for artificial intelligence technology to achieve the application of landing. The empowerment of big data and artificial intelligence in the medical industry is manifested in many aspects, such as assisting doctors in decision-making and improving the efficiency of patient visits. At present, the maturity of artificial intelligence has been significantly improved. All walks of life are actively promoting the application of ¡°AI+¡±. AI technology and applications are rapidly making breakthroughs. Traditional industrial technology upgrades are expected to become breakthroughs, such as machine vision, speech recognition, Application scenarios such as automatic driving and data mining. At the same time, AI technology has broad prospects for the integration and development of agriculture, manufacturing, and service industries, and will become a breakthrough for artificial intelligence.CVPR 2018 | Vision Technology Human Body Attitude Estimation Champion Paper - Cascading Pyramid Network CPN Global Computer Vision and Pattern Recognition (CVPR 2018) (Conference on Computer Vision and Pattern Recognition) will be held on June 18th It was held in Salt Lake City, USA on the 22nd. As a diamond sponsor of the conference, the Vision Technology Research Institute will also attend the event under the leadership of Dr. Sun Jian. ?? Paper link: https://arxiv.org/abs/1711.07319GitHub: https://github.com/chenyilun95/tf-cpn.git lead human pose estimation is one of the basic research directions in the field of computer vision, multiplayer Multi-Person Estimation is a classic problem in this direction; when the traditional algorithm encounters a bottleneck, although the re-emergence and rapid iteration of the convolutional neural network brings new tools to solve this problem, many people Attitude estimation still faces some "hard bones" that do not move. To this end, Vision Technology has proposed the Cascaded Pyramid Network (CPN) to optimize problems that are difficult to identify at key points, and the results have proved to be very effective. This technological breakthrough of CPN will promote the development of related applications in human body posture estimation, such as game animation, security (abnormal behavior detection, etc.), sports (referee assistance, etc.), and automatic driving. Design Ideas Multi-person pose estimation is aimed at identifying and locating key points of all human bodies in an image. This is a basic research topic for many visual applications such as human motion recognition and human-computer interaction. Recently, due to the rapid development of deep neural networks, multi-person pose estimation has been significantly improved. For example, Mask R-CNN first predicts the human bounding box, and then compresses the feature map to obtain key points of the human body. Despite the continuous results, the challenges have not been reduced. For example, it is difficult to achieve positioning when key points overlap, key points are invisible, and the background is crowded. There are two main reasons for this: 1) The above ¡°difficult¡± points cannot be It is simply identified according to its appearance characteristics, such as the torso point; 2) The above "difficult" points are not explicitly dealt with during training. To this end, this paper proposes a new network architecture - Cascaded Pyramid Network (CPN), which is divided into two phases: GlobalNet and RefineNet. GlobalNet learns a good feature representation based on a feature pyramid network. Moreover, pyramid characterization can provide sufficient contextual information, which is essential for inferring occlusion and invisible key points. Based on the characteristics of the pyramid, RefineNet explicitly handles the "difficult" points. This is a top-down pipeline, which first detects the people in the image through the detector, then pulls each person out and makes a single-person pose estimation, and finally integrates the results into the original image. The idea of ??CPN's two-stage architecture design is actually not complicated. It can even be said to be quite simple and intuitive. It comes from how people recognize the key points of the human body. That is, the feature pyramid network GlobalNet first recognizes the simple key points, and then (by means of online The hardkey integration of Refine key integrates the characterization from the former to identify the remaining difficult points. From easy to difficult, the layers advance, and finally overcome the problems that are difficult to identify at key points. In addition, this paper explores the effects of different factors (human body detectors and data preprocessing) on ??multi-person pose estimation. For example, it is found through experiments that the detection mean (Detection mAP) has a limited influence on the key point average accuracy (Keypoint mAP) after reaching a certain threshold (Det mAP41.1). Another example is the use of Large Batch, which can increase the CAP's mAP by 0.4-0.7 percentage points, which means that in addition to object detection, Large batch is also suitable for key point identification. These details are very valuable for studying how to further improve the accuracy and robustness of CPN. The network architecture is similar to Mask R-CNN. The CPN pipeline is also top-down: first, a set of bounding boxes is generated from the image through the human body detector; then the single-point key estimator is used to predict the detailed positioning of each person's key points. The FPN-based current optimal object detector is used as a human body detector, and Mask R-CNN ROIAlign? is used instead of FPN ROIPooling. Inspired by networks such as Stacked hourglass?, this paper proposes CPN, and its architecture is shown in Figure 1. Figure 1: Cascading Pyramid Network (CPN). L2 loss*? indicates L2 loss with key points for online difficulty mining. -- The network architecture of GlobalNetCPN is based on ResNet. The last residual blocks of different convolutional features conv2?5 are denoted as C_2, C_3, ..., C_5, respectively, and a 3 ¡Á 3? convolution filter is applied thereon to generate a thermogram of the key points. As shown in Figure 2, shallow features such as C_2 and C_3 have higher spatial resolution in positioning, but less semantic information on recognition. On the other hand, due to convolution (and pooling), deep feature layers such as C_4 and C_5 have more semantic information, but the spatial resolution is lower. Therefore, a U-shaped structure is often introduced while preserving the spatial resolution and semantic information of the feature layer. Figure 2: Output heat map for different features. The green dot indicates the groundtruth position of the key point. Recently, FPN further improved the U-shaped structure through deep monitoring information. The key point estimation in this paper applies a similar feature pyramid structure. Slightly different from FPN, during the upsampling process, the author used a 1 ¡Á 1? convolution kernel before adding pixels by pixel, and this structure is GlobalNet. As shown in Figure 2, based on ResNet backbone, GlobalNet can effectively locate simple visible key points (such as eyes), but can not accurately locate difficult hidden keys (hips). Positioning such key points as the hip usually requires more contextual information and processing than adjacent appearance features. In many cases, a single GlobalNet cannot directly identify these ¡°difficult¡± points. --RefineNetGlobalNet generates feature pyramid representations to identify "easy" points, and RefineNet? explicitly handles "difficult" key points. To improve the efficiency of information transmission and ensure information integrity, RefineNet transmits information between different layers and integrates this information through upsampling and connection like HyperNet? Unlike the optimized strategy of Stacked hourglass?, RefineNet receives feature information from all pyramid layers, rather than just passing the last upsampling feature between hourglass modules. In addition, more bottleneck modules are used to handle deeper features, and smaller spatial scales provide a good trade-off between efficiency and performance. As the training progresses, the network will tend to focus on the more "simple" points, which are less important than the "difficult" points, such as occlusion, so the network should pay attention to the balance between the two. To this end, RefineNet explicitly selects difficult key points (called online difficult key point mining / OHKM) online based on training losses and only propagates the gradient back from the selected key points. Experiments The entire CPN pipeline estimates multi-person poses in a top-down manner. First, the human body proposals are generated by the current optimal human body frame detector; for each proposal, it is assumed that only one human body is included in the cropping region, and then the final prediction is given by the pose estimation network. This section demonstrates the performance of CPN from the perspective of experimental data. The data sets selected for the CPN evaluation are MS COCO test-dev and test-challenge. Table 10 shows the final results of CPN on COCO test-dev. In the absence of additional training data, the AP value for the CPN single model is 72.1, and the AP value for the CPN multi-model fusion (with different groundtruth thermograms) is 73.0. Table 9 shows the comparison of CPN and other methods on COCO test-challenge 2017. The AP value of 72.1 is the current optimal result of the data set. Table 11 shows the performance of CPN and CPN+ (integrated model) on COCO minival?, which provides a reference for the gap between COCO minival and COCO test-dev / test-challenge. Figure 3 is an example of some CPN results. Table 9: Comparison of final results on COCO test-challenge 2017. Table 10: Comparison of the final results on the COCO test-dev. Table 11: Corresponding results on COCO minival, test-dev and test-challenge. Figure 3: Example of CPN results. Conclusion According to the top-down pipeline, this paper proposes a new cascaded pyramid network CPN to solve the "difficult" key point problem. Specifically, CPN includes a global pyramid based on the feature pyramid structure and a RefineNetTM that links all pyramid features to contextual information. In addition, online difficult key points mining was introduced in RefineNet to explicitly handle "difficult" points. The algorithm achieved the current best results on the COCO keypoint benchmark, a 19% improvement over the COCO 2016 keypoint? Challenge. ECCV 2018 | Vision Technology proposes unified perceptual analysis network UPerNet to optimize scene understanding One of the three top conferences of global computer vision ECCV 2018 (European Conference on Computer Vision) will be held in Munich, Germany on September 8-14. At that time, Dr. Sun Jian, the chief scientist of the contempt, will lead the team to the event to help communicate and land computer vision technology. Thesis title: "Unified Perceptual Parsing for Scene Understanding" paper link: https://arxiv.org/abs/1807.10221 code link: https://github.com/CSAILVision/unifiedparsing lead human understanding of the world is multi-level You can easily classify scenes, detect objects, and even identify parts, textures, and materials. In this paper, Vision Technology proposes a new task called Unified Perceptual Parsing (UPP) that requires the machine vision system to identify as many visual concepts as possible from an image. At the same time, the multitasking framework UPerNet was proposed and training strategies were developed to learn heterogeneous annotations. Defiance Technology benchmarked UPerNet on UPP and found that it can effectively segment a large number of image concepts. This trained network is further used to discover visual knowledge in natural scenes. Background The human visual system can extract a large amount of semantic information from an image at a glance. Humans can not only resolve objects in them immediately, but also identify details such as parts, textures, and materials. As shown in Figure 1, this is a living room with many different objects, such as a coffee table, a painting, and a wall. At the same time, we also saw that this is a four-legged coffee table with a table mat on the table top, and the table is wooden, and the sofa surface is knitted. It can be seen that from the visual perception of materials and textures to the semantic perception of objects and parts, our description of this visual scene is multi-layered. Figure 1: A neural network trained for UPP can analyze visual concepts of different levels of perception at a time, such as scenes, objects, parts, textures, materials, and so on. In recent years, due to the development of deep neural networks and large data sets, computer visual recognition capabilities have made significant progress, constantly approaching or even surpassing human standards. However, visual recognition tasks are different and their research is different. For example, object detection and scene recognition have reached the human level, and the accuracy of parsing and segmentation can be up to the pixel level; the perception and recognition of texture and material are also well studied. Design Ideas In the human visual system, the completion of the above tasks is one step in place, which throws a question to the computer vision model: whether a neural network can solve several different visual tasks simultaneously. This paper proposes this problem in the form of a new task, called Unified Perceptual Parsing (UPP), and gives a new learning method to solve it. UPP has several challenges. First, there is no annotated data set that covers all levels of visual information. Different data sets are created for a specific task. For example, the ADE20K data set is used for scene analysis, the DTD data set is used for texture recognition, and the OpenSurfaces data set is used for material and surface recognition. Second, annotations at different levels of perception are also mixed. For example, the annotations for the ADE20K dataset are pixel-level, while the DTD datasets are image-level. To address these challenges, this paper proposes a new framework that integrates the differences between different data sets and learns to jointly detect different visual concepts. On the one hand, this article randomly samples a data source from each iteration and updates only the relevant layers to reason the concept from the data source. Such a design would circumvent unstable behavior, such as the gradient of a particular concept annotation with noise. On the other hand, the framework relies on the hierarchical nature of a single network feature, ie for high-level semantic concepts such as scene classification, the classifier is constructed only based on feature maps with higher-level semantic information; for lower-level semantic information, such as objects And material segmentation, the classifier is built only based on feature maps of all stages or with low-level semantic information. Furthermore, this paper proposes a training method that allows the network to predict pixel-level texture labels using only image-level annotations. The contributions of this paper can be summarized as follows: 1) A new analytical task, Unified Perception Analysis (UPP), is required, which requires the system to analyze multi-level visual concepts at one time; 2) propose a new network with hierarchical structure. - UPerNet, which can learn differentiated data in different image data sets; 3) The network can implement joint reasoning and explore rich visual knowledge in images. Defining a UPPUPP task is to identify as many visual concepts as possible from a given image. From scene labels, objects, to parts, textures, and materials, the visual concept is multi-layered. This task relies on the availability of different training data. Since no existing data set can satisfy the condition, this paper integrates several image annotation sources into a new data set - Broden+. --Broden+ The new dataset is built on the Broadly Densely Labeled Dataset (Broden), a confounding dataset with different visual concepts. However, due to its original design, Broden is not suitable for the training of split networks. To this end, the paper is optimized from four aspects, and the Broden+ data set is obtained: 1- removing the similar concept of different data sets; 2- only retaining object categories that appear at least 50 images above and contain at least 50,000 pixels in the entire data set. ; 3- Manually remove the downsampling tags in the OpenSurfaces dataset; 4-map 400+ scene tags in the ADE20K dataset to 365 tags in the Places dataset. Thus, the new dataset resulting from the standardization work contains a total of 57,095 images, of which 22,210 are from ADE20K, 10,103 are from Pascal-Context and Pascal-Part, 19,142 are from OpenSurfaces, and 5,640 are from DTD, as shown in Table 1. Figure 3 is a few examples. Table 1: Statistics for each tag type in the Broden+ data set, with evaluation metrics also given. Figure 3: Broden+ data set instance. -- Indicators In general, the metrics for segmentation tasks are P.A. and mIoU. In order to solve the problem that mIoU does not count the prediction of unlabeled areas, making it more suitable for tasks such as partial segmentation, this paper uses mIoU in some specific tasks, but also counts the prediction of background area. This new indicator is called mIoU-bg. Specifically, for object and material parsing tasks with ADE20K, Pascal-Context, OpenSurfaces datasets, evaluation criteria PA and mIoU are used; for object parts, PA and mIoU-bg are used; for scene and texture classification, top is used -1 accuracy. UPerNet--The current optimal segmentation network is based primarily on the Full Convolutional Network (FCN). Due to the lack of adequate training samples, the segmentation network is typically initialized from a pre-training network for image classification tasks. In order to achieve high-resolution prediction of semantic segmentation, the dilated conv technique is proposed to mitigate the side effects of downsampling while ensuring the expansion rate of the receptive field; the network using this technology has become the standard paradigm for semantic segmentation tasks. However, for the UPP task proposed in this paper, this method has two defects: 1 - The recently proposed deep convolutional network has achieved great success in image classification and semantic segmentation tasks, but the number of layers often reaches tens or hundreds of layers; The design structure is so complicated that the downsampling rate increases rapidly in the early stage of the network due to the large receptive field and low computational complexity. 2- This network only uses the deepest feature map. It is reasonable to use advanced semantic features to segment advanced concepts (such as objects), but it is not suitable for segmenting multi-level perceptual properties, especially low-level concepts (such as textures, materials). In view of this, this paper proposes a new multi-tasking framework UPerNet. -- Architecture Figure 4: UPerNet architecture diagram. The UPerNet (Unified Perceptual Parsing Network) network architecture is shown in Figure 4, which is based on the Feature Pyramid Network (FPN). Although in theory, the depth of the deep convolution network is large enough, the actual available is much smaller. To overcome this problem, this paper uses the Pyramid Pooling Module (PPM) in PSPNet for the last layer of the backbone network before it is fed to the top-down branch of the FPN. The results show that the PPM and FPN architectures are highly consistent in terms of bringing effective global prior representation. This article uses features from multiple semantic levels. Since the image level information is more suitable for scene classification, the Scene head is directly attached to the feature map after the PPM module. The Object head and Part head are attached to the feature map that is merged with all layers from the FPN. The material head is attached to the FPN with the highest resolution feature map. Texture is attached to the Res-2 module in ResNet and optimized after the entire network has been trained for other tasks. There are three reasons behind this design: 1-Texture is the lowest level of perceptual properties, so it is purely based on obvious The feature does not require any advanced information; 2 - the correct prediction of the core features of the texture is implicitly learned while training other tasks; 3 - the receptive field of this branch needs to be small enough, so when a normal size image is input Network, which can predict different labels in different areas. Experiments This section first gives a quantitative study of UPerNet on the original semantic segmentation task and UPP task, and then uses this framework to explore the knowledge of visual common sense behind scene understanding. -- The overall structure of the results. In order to prove the effectiveness of UPerNet in semantic segmentation, this paper presents the results of labeling on the ADE20K dataset with different settings in different settings, as shown in Table 2. Table 2: Comparative analysis of this method (based on ResNet-50) and current best practices on the ADE20K dataset. Multi-task learning with mixed annotations. This paper presents training results on different sets of labels that are separated or fused. Table 3: Results of UPerNet on the Broden+ data set. Quantify the results. This paper gives the quantitative results of UPerNet. As shown in Figure 5. UPerNet unifies structural visual knowledge while efficiently predicting hierarchical output. Figure 5: Prediction of UPerNet (ResNet-50) on the verification set. -- Vision Knowledge UPP requires the model to identify as many visual concepts as possible from an image. If the model succeeds in doing this, you can discover rich visual knowledge hidden under the real world and answer questions such as "The material of this cup." What is the problem that helps the machine vision system better understand the world around you. This section demonstrates that UPerNet trained on Broden+ data sets can discover multiple levels of structural knowledge. The researchers defined several class relationships in a hierarchical manner, as shown in Table 4. Table 4: Visual knowledge of UPerNet exploration. Conclusion This article defines a recognition task called Unified Perception Parsing (UPP), which attempts to parse the multi-level visual concept of an image from scenes, objects, parts, materials, and textures. A multitasking network and training strategies for handling hashed annotations were developed and tested. This paper further uses the trained network to discover visual knowledge in the scene.The role of face recognition companies in the future urban construction The future development of Chinese cities is more reflected in the changes brought about by technological innovation. In this process, artificial intelligence plays a very important role. For face recognition companies, the future urban construction will present a more favorable pattern for their development, not only because of the needs of urban development, but also because of strong support from relevant departments such as the government. In the process of technological innovation, more artificial intelligence elements will be born, and these things will further affect the state of life throughout the city. More people believe that the future city will be an era of artificial intelligence, and face recognition companies will play a major role in this process, because without them, the pace of technological innovation and artificial intelligence will not It may start and it may not make a greater contribution to urban construction. It is reported that the country is currently open to the development needs of future urban construction, and some of the policies that are more conducive to the development of face recognition companies, with the help of policy, more and more technology-based companies will be established, and others have already matured. Face recognition companies with technology and experience, they will continue to advance under the policy of this policy, develop more projects that are conducive to urban development, and put these artificial intelligence related products into different In the application, it has a positive impact on the development of the entire city. For example, nowadays we often encounter face recognition gates in public, sign-in systems encountered in the workplace, etc. In fact, these technology products are derived from artificial intelligence companies. These solutions are built on the basis of smart cities or smart offices. Through technological innovation, these devices or hardware are given more intelligent elements, allowing them to replace traditional human resources and more efficiently complete the needs of enterprises or users. . It is understood that these projects with intelligent elements or hardware equipment products will play an important role in the development of urban construction in the future. They will constantly change the living conditions of Chinese people and become an important force leading the development of smart cities. In the future, the speed of urban development will be faster and faster, and the demand will be more and more diversified. For face recognition companies, how to grasp the policy's east wind, how to use the support programs of relevant state departments to bring more to the company More profit, and a more positive contribution to the entire city construction, will be a question worth considering, and it will be a challenge that these technology-based companies must face. ECCV 2018 | Defiance Technology Oral Paper Interpretation: IoU-Net makes the target position detection reliability. ECCV 2018 (European Conference on Computer Vision), one of the top three global computer vision conferences, will be held in Munich, Germany on September 8-14. Kicked off. At that time, Dr. Sun Jian, the chief scientist of the contempt, will lead the team to the event to help communicate and land computer vision technology. Thesis title: "Acquisition of Localization Confidence for Accurate Object Detection" paper link: https://arxiv.org/abs/1807.11590 code link: https://github.com/vacancy/PreciseRoIPooling lead modern CNN-based target detector relies on Boundary box regression and non-maximum suppression (NMS) are used to locate the target. The predicted probability of the category label can naturally reflect the classification confidence of each box, but the frame position reliability is missing. This allows the originally positioned accurate bounding box to deviate from the target during iterative regression or even be suppressed during the NMS process. To this end, Vision Technology proposes IoU-Net, which can learn to predict the IoU between each detected bounding box and the matching target as the location reliability of the box. With this positional reliability, the detector ensures that more accurate boundary frames are retained during the NMS process, improving the NMS process. In addition, using the predicted IoU as the optimization goal, an optimization-based bounding box correction method is also proposed. This underlying breakthrough of target detection technology (one of the cornerstones of computer vision) will not only optimize the development of the upper technology, but also bring beneficial effects to the technology, such as video intelligence understanding, smart real estate and retail, and smart cameras. Wait, promote the progress of digital China, urban brain, unmanned supermarkets and other industries. Background target detection is the premise of many downstream visual applications, such as instance segmentation, human skeleton drawing, face recognition, and advanced target reasoning. It combines two tasks of target classification and positioning. Most modern target detector frameworks are two-stage, where target detection is defined as a multi-task learning problem: 1) distinguish foreground object frames from the background and assign them the appropriate category labels; 2) regress a set of coefficients to maximize The intersection ratio (IoU) or other indicator between the detection frame and the target frame. Finally, the redundant bounding box (repeated detection of the same target) is removed through an NMS process. In such a detection process, classification and positioning are solved in different ways. Specifically, given a proposal, the probability of each category label can be used naturally as the "classification confidence" of the proposal, while the bounding box regression module only predicts the transform coefficients for the proposal. Fits the position of the target object. In other words, this process lacks ¡°location reliability¡±. The lack of location reliability brings two disadvantages: 1- When suppressing duplicate detection, the classification score is usually used as an indicator of the position of the detection frame due to the lack of location reliability. In Figure 1(a), the researchers show a set of cases in which the detection frame with higher classification confidence has a smaller overlap with its corresponding target object. Like Gresham's famous theory of ¡°bad money driving good money¡±, the mismatch between classification confidence and positioning accuracy may result in a more accurate boundary box being suppressed by the more inaccurate bounding box in the NMS process. 2- Lack of location reliability makes the widely used bounding box regression method lack interpretability or predictability. For example, the previous study [3] reported the non-monotonicity of iterative bounding box regression. That is to say, if the bounding box regression is applied multiple times, it may damage the positioning effect of the input bounding box (see Figure 1(b)). Figure 1: Illustration of two shortcomings caused by lack of location reliability. These examples are selected from the MS-COCO minival. (a) An example of classification confidence and positioning accuracy misalignment. The yellow frame indicates the real target frame, and the red frame and the green frame are the results of the FPN. The location reliability is calculated by the IoU-Net proposed by the researcher. Using classification confidence as a ranking indicator results in a more accurate boundary box (green frame) being incorrectly deleted in the traditional NMS process. (b) An example of non-monotonic positioning in iterative bounding box regression. Design Ideas In this paper, the researchers introduced IoU-Net, which predicts the IoU between the detected bounding boxes and their corresponding real target frames, so that the network can be like the classification module. The accuracy of positioning is mastered. This simple predictive IoU value provides researchers with a new solution to the aforementioned problems: 1-IoU is a natural standard for positioning accuracy. Researchers can use the predicted IoU to replace the classification confidence as the ranking basis in the NMS. This technique, known as IoU-guided NMS, eliminates suppression errors caused by misleading classification confidence. 2- The researcher proposes an optimization-based bounding box correction process that can be compared with the traditional regression-based bounding box correction method. During reasoning, the predicted IoU can be used as an optimization target or as an interpretable indicator of location reliability. The researchers' proposed Precise RoI Pooling layer allows researchers to solve IoU optimizations by gradient ascent. Researchers have shown that the optimization-based bounding box correction method can achieve a monotonous improvement in positioning accuracy in experiments compared to regression-based methods. This method is fully compatible and can be integrated into a variety of different CNN-based detectors. Boundary box correction diagram: Uplink is the result of the traditional method, and down is the result of the proposed method. Target Positioning This section explores two shortcomings of target positioning: mismatch between classification confidence and positioning accuracy, and non-monotonic bounding box regression. The standard FPN detector was trained on the MS-COCO trainval35k with the most baseline and tested on minival for further study. -- Classification & Positioning Accuracy Mismatch Figure 2: Relationship between the IoU of the bounding box and its corresponding target box and the classification/location reliability. For those test frames with an IoU higher than 0.5 in the target box, the Pearson correlation coefficients are (a) 0.217 and (b) 0.617. (a) Classification Confidence represents a category of bounding boxes, but cannot be interpreted as positioning accuracy. (b) To solve this problem, the researchers proposed IoU-Net to predict the location reliability of each detected bounding box, ie its IoU with the corresponding target box. Figure 3: The number of positive bounding boxes obtained after NMS, grouped according to the IoU between them and the corresponding target box. In traditional NMS (blue bar graph), a large portion of the accurately positioned boundary box is error suppressed, which is caused by a mismatch between classification confidence and positioning accuracy, while IoU-guided NMS (Yellow bar chart) preserves more accurate bounding boxes. -- Non-monotone Boundary Box Regression Figure 4: Optimization-based and regression-based BBox optimization. As shown in the figure above, (a) indicates comparison in FPN. When the regression is applied iteratively, the AP (average precision) of the test results will increase first, but will decrease rapidly in subsequent iterations. (b) indicates a comparison in Cascade R-CNN. The iterations 0, 1, 2 represent the 1, 2, and 3 regression phases in the Cascade R-CNN. After multiple rounds of regression, the AP declined slightly, while the optimization-based approach further increased AP by 0.8%. To quantitatively analyze the validity of IoU predictions, IoU-Net first proposed a method for training IoU predictors. Next, we show how to use the IoU predictor for NMS and bounding box correction. Finally, the researchers integrated the IoU predictor into existing target detectors such as FPN. -- Learning Forecast IoU Figure 5: The complete architecture of IoU-Net. In the above image, the input image is first entered into an FPN backbone network. The IoU predictor then reads the output characteristics of this FPN backbone network. The researchers replaced the RoI pooling layer with the PrRoI pooling layer. This IoU predictor has similar results to the R-CNN branch. The modules in the dashed box form a single IoU-Net. --IoU-guided NMS algorithm 1: IoU-guided NMS. In this algorithm, the classification confidence and location reliability are disentangled. The researchers used location reliability (predicted IoU) to rank all detected bounding boxes and then updated the classification confidence based on a cluster-like rule. - Boundary box correction as an optimization process algorithm 2: Optimization based bounding box correction. Precise RoI Pooling. The researchers introduced a precision RoI pooling (abbreviated as: PrRoI pooling) to help the researchers' bounding box corrections. It does not have any coordinate quantization and has a continuous gradient on the bounding box coordinates. Given the feature map F of the RoI/PrRoI before pooling (for example, from Conv4 in ResNet-50), let wi,j be the feature at a discrete position (i,j) on the feature map. Using bilinear interpolation, this discrete feature map can be considered to be continuous at any continuous coordinate (x, y): where ?? is the interpolation coefficient. Then, a bin of RoI is represented as ??, where (x_1, y_1) and (x_2, y_2) are consecutive coordinates of the upper left and lower right corners, respectively. Given bin and feature map F, the researchers performed pooling by calculating a second-order integral (such as average pooling): For easier understanding, the researchers visualized RoI pooling, RoI Align, and the researchers in Figure 6. PrRoI pooling: In the traditional RoI pooling, the continuous coordinates first need to be quantized to calculate the sum of the activations in the bin; in order to eliminate the quantization error, in the RoI Align, N=4 in the bin will be sampled. Continuous points are represented as (a_i, b_i), and pooling is performed at the points of these samples. The N in RoI Align is predefined and cannot be adjusted according to the size of the bin. In contrast, the PrRoI pooling proposed by the researchers is based on continuous feature maps to calculate second-order integrals. Figure 6: Graphical representation of RoI pooling, RoI Align, and PrRoI pooling. -- Joint training This IoU predictor can be integrated into standard FPN processes for end-to-end training and reasoning. For clarity of explanation, the researcher refers to the CNN architecture for image feature extraction as a backbone, and the module applied to each RoI is called a head. As shown in Figure 5, this IoU-Net uses ResNet-FPN as the backbone network, and its architecture is top-down, building a feature pyramid. FPN can extract the characteristics of these RoIs from different levels of this feature pyramid according to the proportion of RoI features. The original RoI pooling layer was replaced by a precision RoI pooling layer. As for the head of the network, this IoU predictor works in parallel with the R-CNN branch (including classification and bounding box regression) based on the same visual characteristics from the backbone network. Experimental researchers conducted experiments on 80 MS-COCO test data sets. Specifically, the model was trained on a union of 80,000 training images and 35,000 verified images (trainval35k), and the model was evaluated on a collection containing 5000 proof images. To validate the method, the researcher trained a separate IoU-Net (without the R-CNN module) separately from the target detector. IoU-guided NMS and optimization-based bounding box corrections are applied to the test results. --IoU-guided NMS Table 1 summarizes the performance of different NMS methods. Although Soft-NMS retains more bounding boxes (without true "suppression"), IoU-guided NMS can improve results by improving the positioning of detected bounding boxes. Therefore, on high IoU metrics (such as AP_90), IoU-guided NMS is significantly better than the benchmark approach. Table 1: Comparison of IoU-guided NMS with other NMS methods. By preserving the exact bounding box, the IoU-guided NMS performs significantly better on APs with high matching thresholds (such as AP_90). Figure 7: Recall rate curves for different NMS methods under different IoU thresholds for matching detected bounding boxes to real target frames. The investigator provided No-NMS (without suppressing the bounding box) as the upper limit of the recall rate curve. The IoU-NMS proposed by the researchers has a higher recall rate and can effectively narrow the gap with the upper limit at high IoU thresholds (such as 0.8). -- Optimization-based bounding box correction The optimization-based bounding box correction proposed by the researchers is compatible with most CNN-based target detectors, as shown in Table 2. Applying this bounding box correction method to the original IoU-Net process can further improve performance by more accurately targeting the target. Even for Cascade R-CNN with three-level bounding box regression, this improved approach can further increase AP_90 by 2.8% and overall AP by 0.8%. Table 2: Optimization-based bounding box correction can further enhance the performance of multiple CNN-based target detectors. -- Joint optimization IoU-Net can be optimized end-to-end in parallel with the target detection framework. The researchers found that adding IoU predictors to the network helped to make network learning more discriminative, which increased the overall APs of ResNet50-FPN and ResNet101-FPN by 0.6% and 0.4%, respectively. IoU-guided NMS and bounding box corrections can further improve performance. The researchers used ResNet101-FPN to get 40.6% of APs, compared to 38.5%, an increase of 2.1%. Table 4 gives the speed of reasoning, indicating that IoU-Net can achieve an improvement in detection levels within the cost of computing. Table 3: Final experimental results on MS-COCO. IoU-Net represents the ResNet-FPN embedded in the predictor. On this FPN benchmark, the researchers achieved an AP boost of approximately 2%. Table 4: The speed of inference that multiple target detectors get on a single TITAN X GPU. These models all have the same backbone network ResNet50-FPN. The input resolution is 1200x800. All hyperparameter settings are the same. Conclusion This paper proposes a new network architecture IoU-Net for accurate target location. By learning to predict and target the real target IoU, IoU-Net can detect the "fixed position reliability" of the bounding box, implementing an IoU-guided NMS process, thereby preventing the more accurate boundary frame from being suppressed. IoU-Net is intuitive and easy to integrate into a variety of different inspection models to dramatically improve positioning accuracy. The MS-COCO experimental results show the effectiveness and practical application potential of the method. From the perspective of academic research, this paper points out that there is a problem that the classification confidence and the location reliability do not match in the modern detection process. Further, the researchers redefine the bounding box correction problem to a completely new optimization problem and propose a solution that is superior to the regression-based method. Researchers hope that these new perspectives will inspire future target detection efforts.The 5th World Internet Conference enters the countdown Despise technology to meet you in Wuzhen From November 7th to 9th, the eyes of the global Internet field will once again focus on the beautiful water town of Wuzhen, paying attention to the 5th World Internet Conference. At the same time, as an important part of the World Internet Conference, the 5th "Light of the Internet" Expo, co-sponsored by the National Network Office, the Ministry of Science and Technology, the Ministry of Industry and Information Technology and the People's Government of Zhejiang Province, will also be held from November 6th to 10th. The day was held in Wuzhen. At that time, Defiance Technology will also bring a number of original artificial intelligence black technologies to the main venue of the Expo to showcase the innovation and development achievements of China's artificial intelligence technology. Exhibition time: November 6-10, 2018 (9:00-17:00, 10:00-12:00): Venue: Wuzhen Internet International Convention and Exhibition Center, No. 646, Huanhe Road, Wuzhen, Tongxiang, Zhejiang, China Location: Hall A1F-10, the first floor of Hall 3, the 5th World Internet Conference, scorned booth design. The 5th World Internet Light Expo focuses on the world's Internet development trends and cutting-edge technologies, highlighting the global scale. New products, new technologies, new applications. As a strategic technology that leads a new round of scientific and technological revolution and industrial transformation, artificial intelligence has become a hot spot for Internet companies and innovative enterprises at the Expo every year. As an industry leader in artificial intelligence, it is also a global Leading companies in the field of artificial intelligence, Vision Technology has brought its advanced AI technology and products to the Expo since 2015. This year, contempt for the latest innovations in security, mobile, automotive, retail, and logistics, and will showcase smart vision, smart home and wearable solutions with partner Amys Semiconductor (ams). On the eve of the conference, we will first bring you first-hand exhibit information. First, despise the city Tianyan 2.0 city Tianyan system, is a cloud intelligent research and judgment platform that deliberately launched on the line in 2015. Combined with big data and deep learning algorithms, it can realize the data visualization and trajectory tracking function of public security prevention and control. In 2018, contempt for the official launch of the City Tianyan 2.0 platform, the self-developed face recognition, pedestrian recognition, vehicle identification, trajectory tracking, video structuring and other leading AI vision technology, and urban security, urban transportation, urban governance The combination of actual scene requirements provides intelligent identification of key public security personnel, traffic violations, and urban mobile vendors. In the 2018 Asia-Europe Security Exhibition, Beijing Anbo and other exhibitions, contempt for the city's eyes has become the focus of the audience's visit experience. Second, end-to-end intelligent security As the industry's leading provider of end-to-end intelligent security products and solutions, contempt is the first artificial intelligence company to enter the security field. For the typical scenarios in the security business, and the actual demands of the "love, finger, and diligence" linkage, contempt is through the "algorithm, technology, hardware products, solutions, data" full value chain output, and strive to create a full business process coverage. The end-to-end solution system helps public security users build a new intelligent security closed-loop system from front-end awareness to cloud research and judgment to terminal applications. Today, defying intelligent security has been deployed in more than 100 cities across the country, and has become an important security solution provider for major international events such as the G20 Summit, Xiamen Golden Brick Summit, Hainan Boao Forum, and SCO Summit. Third, the mobile AI solution for the AI ??application wave in the mobile phone industry, contempt is also the industry's first to launch a soft-hard integrated mobile AI-aware full-stack solution, from algorithm innovation, application development, device manufacturing to solutions, Industry customers realize AI empowerment. At present, defy core-based deep learning and computer vision technology to launch a series of mobile AI products such as face payment, face recognition unlock, portrait light effect, portrait background blur, 3D Animoji, etc., to meet different mobile phone manufacturers. In the face unlocking, image enhancement, camera enhancement, intelligent image and video processing needs, in less than one year, it has achieved in-depth cooperation with domestic headphone companies such as Huawei, Xiaomi, vivo and OPPO. At this year's fair, Despise will showcase 3D face unlock payment and 3D portrait light technology for OPPO Find X, and smart vision, smart home and wearable solutions using ams modules. In addition, the newly developed car AI vision solution will also be unveiled at this year's fair. 4. In the retail industry, the smart retail solution defies the lack of data for offline retail scenes and cannot use data-driven decision-making. Based on the industry-leading computer vision algorithms and the IoT-aware terminal system, it has independently developed a set of ¡°clouds¡±. Service + Smart Side" new retail industry solution. It can multi-dimensionally sense and understand customer's identity attributes, behavioral information and various types of data triggered by shelves and commodities. Through data fusion analysis and in-depth mining, it helps merchants improve the capability boundary of store operators and optimize business strategies and supply. Chain management, in order to achieve cost reduction and efficiency in the process of store data. At present, contempt has provided an end-to-end intelligent solution for more than 2,000 chain stores including retail enterprises such as Mingchuang Premium, Fresh Life, Ginza Mall, and Wheat Shop. V. Logistics Warehousing Robot Solution In the practice of ignoring the AI+IoT-enabled urban terminal, the digitalization and intelligent transformation of the logistics industry has become one of the key businesses of contempt. Relying on the core R&D strength of powerful robots, big data, artificial intelligence, etc., the logistics warehouse robot solution can be designed to meet the business needs of customer storage sorting and intelligent handling, and provide ¡°robot + warehouse management system + data¡±. Analytical" and other comprehensive solutions. In the logistics industry, contempt has reached strategic partnerships with many well-known domestic e-commerce warehousing, logistics and manufacturing companies. By building an open intelligent warehousing robot platform, we will reduce costs, increase efficiency and create value for more partners. In addition to the show, contempt will also be released on November 8th at the Internet Light Expo brand launch event (2nd floor of Hall 6), the theme of "Software and Hard One Innovative Mobile 3D Solution Optimization" is released, we look forward to meeting you. Wuzhen!ECCV 2018 | Defiance Technology proposes a new approach: weakly supervised semantic segmentation through instance-level saliency detection and graph partitioning ECCV 2018 (European Conference on Computer Vision), one of the top three global computer vision conferences, will be held September 8-14 It opened in Munich, Germany. At that time, Dr. Sun Jian, the chief scientist of the contempt, will lead the team to the event to help communicate and land computer vision technology. Thesis title: "Associating Inter-Image Salient Instances for Weakly Supervised Semantic Segmentation" paper link: http://mftp.mmcheng.net/Papers/18ECCVGraphPartition.pdf The depth learning method is divided into supervised learning and unsupervised learning. The former is Deep learning "Taking down a city" is fruitful, while the latter is hope and future. However, the weak supervised learning between the two can not be ignored, and the potential is huge. In this paper, Defiance Technology and Tsinghua University propose a new weak supervised learning method by accumulating original technologies such as saliency detection and graph partitioning algorithms, speeding up the development of semantic segmentation, and promoting the technology in automatic driving, security, and The emergence and popularity of new retail, logistics and other industries. The biggest technical highlight of this approach is the intrinsic properties of each saliency instance utilized, and the interrelationship of different saliency instances across the entire dataset. The experimental results show the effectiveness and efficiency of the proposed method. It is through the difficulties of technical difficulties, continuous accumulation, mutual resonance, and promote the AI ??original technology matrix to form the AI+IoT system, which helps Vision Technology to continue to create maximum value for customers and society with extraordinary technology. Background Semantic segmentation is one of the most important tasks in the field of computer vision. Its purpose is to label semantic information for each pixel of an image. The powerful learning capabilities of convolutional neural networks have made great progress in this area, but the training of neural networks requires a large number of pixel-level labeled training data, such as PASCAL VOC and MS COCO. Weakly supervised semantic segmentation as a new method to reduce the need for pixel-level annotated data has recently received much attention. This method only needs tag information such as keywords, bounding boxes, scribbles, points, etc., and the data can be easily constructed. This paper studies the weak supervision framework with only keywords as annotation information. In weakly supervised semantic segmentation, one of the main challenges is to establish an effective connection between the keyword and the corresponding semantic target. Most previous methods use various low-level cue detectors to capture pixel-level information to generate a proxy ground-truth from the original image. Significant models and attention mechanisms are common methods. Since the above method only gives pixel-level saliency/attention information, it is difficult to distinguish different foreground target objects. Therefore, the ability to discriminate semantic instances is especially critical. With the rapid development of saliency detection algorithms, some significant detectors, such as MSRNet and S^4Net, can not only achieve pixel-level prediction of significant regions, but also extract significant instances. By referring to the advantages of the above-mentioned example-level significant target detector, this paper proposes to use S^4Net to perform instance extraction tasks in the early significant detection phase, which greatly simplifies the pipeline, some instance-level saliency images generated by S^4Net. Figure 1 (b) shows. Figure 1: Illustration of the method in this article. Since the foreground obtained by low-level feature detectors such as saliency detection does not contain semantic information, for multi-label training samples, assigning the correct keywords (tags) to each foreground object is an important task to be solved. When traditional methods deal with weakly supervised problems, they focus on processing each image independently. This paper not only exploits the intrinsic features of each saliency instance, but also generates a proxy ground-truth by assigning the correct semantic label to each saliency instance by means of the semantic interrelationship of all saliency instances across the entire data set. This algorithm can be modeled using graph partitioning. Design Ideas In order to take advantage of the saliency instance mask with bounding boxes, two major difficulties need to be overcome. First, an image may be labeled with multiple keywords, so the corresponding problem of the keyword and the saliency instance is solved. Second, not all instances generated by the saliency instance detector are semantically meaningful, and incorporating these noise instances can affect the accuracy of subsequent operations. Because the identification and removal of these noise examples is important in the method of this paper. Both of the above difficulties can be expressed as a label assignment problem, that is, the semantic label and the noise instance are labeled correctly. This paper considers the interrelationship between the intrinsic information and the saliency instances of a significant instance throughout the training set. It is also possible to give correct labels to salient instances by considering only the internal information of RoI, that is, the essential features of the saliency instances. However, in addition to the intrinsic properties of each RoI, there is a semantic interrelationship between each saliency instance: saliency instances of the same category usually have similar semantic features. It is important to consider label assignments. Specifically, on the one hand, this new framework contains a attention module that predicts the probability that a significant instance belongs to each tag based on intrinsic properties; on the other hand, predicts semantic features for each significant instance through an extractor, To get semantic relationships. A semantically similar saliency instance has an approximate semantic feature vector. Based on the semantic features, a similarity graph can be obtained, where the vertices represent saliency instances and the edge weights record semantic similarities between a pair of saliency instances. In this paper, the graph is divided into several subgraphs by a graph partitioning algorithm, in which each subgraph represents a specific category. The graph partitioning process is modeled as a mixed integer quadratic programming problem (MIQP) to obtain a global optimal solution. The goal is to make the vertices inside each subgraph as similar as possible. The graph partitioning process also takes into account the intrinsic properties of the salient instance. This method gives high-quality proxy-ground-truth data and can train a fully supervised semantic segmentation model. When dealing with semantic segmentation tasks on DeepLab, the proposed method has a mIoU of 65.6% on the PASCAL VOC 2012 test set, which is better than the current best practice. In addition to pixel-level semantic segmentation, this paper also uses the instance-level proxy-ground-truth data to train the instance-level segmentation model, and demonstrates for the first time the ability to perform instance-level segmentation using only the weakly supervised framework of keyword annotation. Network Architecture In this section, we first give an overview of the pipeline, then discuss the network structure and label allocation algorithms. The framework is shown in Figure 2. Most previous work that relied on pixel-level cues (such as saliency, edge, and attention maps) identified instance discrimination as a key task. However, with the development of deep learning, the significance detector can predict the significance map as well as the instance bounding box. Given a training image with only keywords, the researchers extracted saliency instances from each image with an instance-level significant segmentation network S^4Net. Each significant instance has a bounding box and a mask indicating that there is a visually visible foreground target in the image. These notable examples are category agnostic, so the extractor S^4Net does not need to be trained for this training set. Although the salient instance contains a ground-truth mask that trains the split mask, there are two main limitations to using these significant instances to train the split network. First, an image can be labeled with multiple keywords. Second, instances detected by S^4Net are not necessarily among the categories of the training set. This article considers these notable instances as noise instances, and eliminating them is an integral part of the pipeline in this article. Two limitations can be solved by solving the label assignment problem, where the researchers associate the saliency instance with the correct label based on the image keyword and mark the other instance as noise. Figure 2: Pipeline. The pipeline of this paper considers the relationship between the intrinsic properties of a single region and all significant instances. In the score map output by a classification network, there is a strong response to the correct category in the target area (pixel). Therefore, inspired by class activation mapping (CAM), this paper uses the attention module to directly identify the labels of significant instances based on their intrinsic properties. One of the weaknesses of the existing weak supervisory segmentation work is that the training sets are processed one by one, ignoring the relationship between the saliency instances throughout the training set. However, saliency instances belonging to the same category have similar semantic information and can play a role in tag assignment. This paper extracts the semantic features of each significant instance. The regions with similar semantic information have similar semantic features, and thus construct a similarity graph. Label assignment now becomes a graph partitioning problem, while taking advantage of the intrinsic properties of a single saliency instance and the overall relationship of all saliency instances. Experiments This section shows the results of this approach on the PASCAL VOC 2012 semantic segmentation benchmark and compares it with some of the current best practices. The results show that the framework goes significantly beyond all existing weak monitoring methods. This article also analyzes the importance of each component through a series of experiments. This paper further gives the preliminary results on the MS COCO instance segmentation task. Table 3 shows the new current best results on the PASCAL VOC 2012 validation set and test set. Specifically, compared to the baseline results of Mining Pixels, the method achieved 6% and 5.8% improvements on the test set and validation set, respectively. In addition, it is worth noting that this method is even better than other methods (in the form of lines and points) with additional supervision. In addition to the semantic segmentation results, this paper also shows the example segmentation results of the weakly supervised method using only keywords. Table 4 compares the results of this paper with the current optimal full-supervised method. Instance-level segmentation is achieved with only raw RGB images with keywords. Table 3: Pixel-level segmentation results for the proposed method on the PASCAL VOC 2012 validation set and test set and comparison with existing best practices. Table 4: Example segmentation results and comparisons of the methods in this paper on the COCO test set. Conclusion This paper proposes a new weakly supervised segmentation framework that aims to generate accurate proxy-ground-truth data based on the saliency instances extracted from the trained images and the assigned tags. This paper introduces the saliency instance into the weak supervised segmentation, which greatly simplifies the target discriminating process in the existing work, and makes the framework perform instance-level segmentation. In this paper, the label assignment task is modeled as a network partition problem, and this problem is solved by integer quadratic programming. To improve the accuracy of label assignments, the intrinsic information from a single saliency instance and the relationship of all targets in the entire data set are taken into account at the same time. Experiments show that this method achieves new current optimal results on the PASCAL VOC 2012 semantic segmentation benchmark, and demonstrates for the first time the results of the weakly supervised method with only keywords as annotation information in the MS COCO instance-level semantic segmentation task.Artificial intelligence: unlocking smart cities, the future has come. I. Overview of China's Artificial Intelligence City Development In an finite urban space, creating an infinitely intelligent city. China's urban construction experienced rapid development from the 1990s to the present, and gradually entered the new normal of urban transformation and development. The goal of urban construction begins with the pursuit of scale and economic benefits, and shifts to the three-dimensional value pursuit of ecology, humanities, social equity and sustainability, especially the people-oriented development goal, the city is developing towards ¡°smart¡±; with artificial intelligence technology Conditions are becoming more and more mature, urban management forms a data-driven urban decision-making mechanism, starting from the top-level design, top-down "AI" makes urban functions and industrial transformation more significant, creating technology-driven for the city. Business value ultimately leads to a diversified organic eco-city system. The development of intelligent networking led by artificial intelligence is the key to the next stage of smart city. Back in the 1990s, after IBM first proposed the concept of ¡°smart city¡±, China also launched digital city construction in 1995, which is the 1.0 version of China's smart city; With the concept of ¡°Smart Earth¡± in 2008, China¡¯s smart city construction once again entered the era of 3.0 perceived smart city; in 2013, WiFi, 3G/4G network transmission and cloud computing, big data back-end data storage, processing With the technological advancement of analysis, the era of 4.0 cognitive smart cities has been opened; in the near future, data accumulation and the rapid growth of transmission bandwidth and speed will enable smart cities to achieve overall architecture collaborative management, and the era of ¡°artificial smart cities¡± will also arrival. The government encourages the development of artificial intelligence and will vigorously assist the future urban construction. The government has intensively introduced policies to encourage the development of artificial intelligence technology in the past three years, indicating that it attaches great importance to the opportunities of this technology development, from vigorously promoting China to 2030, becoming the world's artificial intelligence innovation. The determination of the center can be seen. I hope that China can ¡°catch up¡± this time of the technological revolution, and it is no longer just a requirement of ¡°not falling behind¡±. The policy direction of Chinese cities is returning to the core of people-oriented. The development of the city revolves around the concept of ¡°high efficiency, benefiting the people and sustainable development¡±, which makes the city construction a major opportunity for transformation and upgrading. In the future, the upgrading of urban economic structure relies on technological innovation to bring economic power. China's GDP has grown exponentially in the past decade, and the overall level of innovation efficiency improvement in national central cities is not significant. Beijing, Wuhan, and Zhengzhou have significantly improved their innovation efficiency levels ten years ago, while other cities have remained unchanged or even declined. It can be seen that the current innovation investment and output of major cities have not kept pace with the economic development, indicating that the proportion of revenue brought by the improvement of science and technology in the economic structure is low, and the investment in improving innovation efficiency should be emphasized in the future (talent, capital, technology... ...), and focus on the economic benefits of innovation. Imminent: Solving the Problem of Optimizing the Efficiency of Limited Urban Space China's urban population surpassed the rural population for the first time in 2011. The future regional urbanization will be an important deployment of the national development strategy; in 2015, the national urban construction was less than ten years compared with 2008. At the time, the urban built-up area increased by 43.5%, and the road length increased by 40.4%. All of this occurred on the basis of an increase of 7.7% in urban area and 21.7% in public transport system operation vehicles. With a further dense population (15.3% increase in urban population density), ¡°big city diseases¡± ? traffic congestion, air pollution, inadequate infrastructure and other issues are becoming more and more serious, how to create higher urban efficiency in a limited space, Better urban operation and a more livable urban environment have become an urgent problem for domestic urban management. The coverage of China's surveillance cameras is insufficient, and the density is far lower than that of the United States and the United States in 2017. The official data of the ¡°China Skynet¡± has reached 20 million cameras, but for the urban area of ??nearly 200,000 square kilometers, the coverage and number of cameras are rare; In terms of the number of cameras/thousands of people, the average density of camera in China's cities is only 20%-30% of that of the United States and the United States, and the perfect monitoring system is a powerful means to ensure urban security. Therefore, the surveillance camera construction project has a long way to go; in the future, especially It is a huge potential for surveillance cameras in second-tier cities and below. The development of artificial intelligence From the 1950s to the early 1970s, people thought that as long as they could give the machine logical reasoning ability, the machine could be intelligent, and the artificial intelligence research was in the "inference period." Then, people realized that human beings can judge and make decisions. In addition to reasoning ability, they also need knowledge. Therefore, artificial intelligence research entered the ¡°knowledge period¡± in the 1970s, and a large number of expert systems were born at this time. As the research progressed, experts found that human knowledge was endless, and some of the knowledge itself was difficult to summarize and then handed over to the computer. So some scholars gave birth to the idea of ??giving knowledge learning ability to the computer itself. In the 1980s, machine learning really became an independent subject area, and related technologies emerged one after another. After entering 2010, significant progress has been made in the field of speech recognition and computer vision. In 2016, behind AlphaGo, which has attracted a lot of attention from academia, industry, media, and other sectors of society, it is also a combination of deep reinforcement learning and Monte Carlo tree search. Wit or skill is not as good as people? After massive data training, artificial intelligence can be used in a clear-cut field, only when compared to human intelligence that can continuously learn and adapt to changing things in an open environment, when the machine faces a rare scene that exceeds fixed rules. Often, at a loss, the robustness needs to be improved. Despite this, all aspects of urban development and construction have a large number of potential space for upgrading existing technologies, such as machine perception, cognition, big data processing, and motion control. Second, the application and scene of artificial intelligence in urban development 2017 is the first year of artificial intelligence application, in the future there will be more urban scenes landing AI + security: computer vision + deep learning technology is a necessary condition for intelligent video upgrades The camera and the huge monitoring network will generate massive monitoring video data in an instant, and efficiently extract effective information from massive video data, which becomes the key to intelligent video surveillance technology. Take a city with a video scale of 10,000 channels as an example. It generates 12PB of video data per month. In this kind of resources, the target personnel and vehicles are like a needle in a haystack. However, through artificial intelligence algorithms, the target in the video can be automatically captured. The picture, and extract its semantic attribute data and feature data that can be used to compare the search, the monthly data is only about 1.5 billion, and the storage capacity drops to about 300TB, which can realize the second-level retrieval and depict the target's trajectory. Conduct behavioral analysis. AI+ Transportation: Human control of vehicles will eventually approach zero. The evolution of driving in unmanned scenes is the evolution of automatic intelligent transportation: At this stage, the functions of assisted driving are relatively mature, whether it is testing or actual. The performance of the open environment is relatively stable; and the limited scenes of autonomous driving are expected to land in the next three years. The main landing is the scene where the environment is relatively simple, closed or safe for passengers. In the future, the unmanned form needs to pass a large number. Data accumulation, proofreading and testing, as well as technological breakthroughs and mass production of parts and components have brought down costs. AI+ authentication: AI authentication has significantly surpassed the human-authentication efficiency. The government-established government cloud platform has opened up the ¡°island¡± state of information and data for urban management. In many scenarios of smart government, the effective time for human verification It is a half-hour rotation, so authentication is widely used in various types of identity-identifying nodes. For example, biometric recognition technology based on facial feature information, with the breakthrough brought by deep learning, allows the machine to achieve self-learning ability according to the training data set, and finally grasp the concept of "face". AI+Retail: Entity retail intelligence is the only way to fight against e-commerce retail. Retail needs to seize the opportunity of ¡°new retail¡± transformation and upgrade, build information-based physical stores and build a three-dimensional database, so as to better serve customers. Control or reduce costs and increase the competitiveness of physical retail. Entity retail can start from all kinds of access data, monitor and capture the consumer's likes and dislikes in the store in real time, and carry out accurate analysis to realize intelligent operation and management. AI+ Entertainment and Life: Augmented Reality Technology Constantly Creates Value in Entertainment and Life Markets in Pan-Entertainment Scenes Such as Image and Video. China's smartphone users have higher acceptance of new things and are willing to use new technologies to upgrade existing products. The experience, the short burst of video and the beauty of the beauty filter confirm this view. At present, augmented reality technology is mainly applied to image and video entertainment scenes on personal mobile devices. In the future, under the upgrade iteration of hardware devices, augmented reality technology will bring greater commercial value. III. Future development of China's artificial intelligence city With the continuous upgrading and transformation of the city, the demand for artificial intelligence technology is increasing. Under the promotion of the fourth information revolution, the city-smart city-artificial intelligence city is continuously iteratively upgraded and artificial. Intelligent technology is becoming more and more important in urban construction; from informationization-networking+sensing-independent intelligence, more and more attention is paid to the upgrade experience brought by technological innovation; Ai Rui believes that in the future, human participation in management and decision-making in urban management will Less and less, and ultimately achieve the effect of urban independent intelligent management, so as to achieve efficient, safe, energy-saving, sustainable development of urban development goals. The increasingly perfect ICT architecture will accelerate urban iterative development and technology upgrades also provide ¡°smart¡± decision support for urban governance. From digital cities to artificial intelligence cities, the improvement of ICT (Information Communication Technology) promotes the iterative development of cities, with cloud computing. , big data, Internet of Things, communication as infrastructure, artificial intelligence technology provides analysis, deployment, management, and pre-judgment functions in urban development; IResearch believes that: under the ICT architecture with constantly upgrading technology and infrastructure, improve the city Operational efficiency and a better living experience will be a significant effect of technology changing life; and every aspect of the process will have great commercial value.The important application of face recognition algorithm in urban security In China's first- and second-tier cities, the layout density of surveillance cameras has reached more than half of that in developed countries, but the number of surveillance cameras in cities below two levels is far from enough to support future cities. The development of construction, while the intelligent and perfect monitoring system can play a huge positive role in urban governance and security, so the surveillance camera market is huge and has great potential. It is worth mentioning that in the process of building an upgraded surveillance camera project, the application of the face recognition algorithm is a key part of the entire intelligent process. The face recognition algorithm shoulders the function of collecting, transmitting and feedback data in the establishment of the monitoring system. First, the downlink data is recorded by the front-end device, and the mobile terminal device can complete the identification and structuring process in real time, and then transmit the video stream and the labeled data back to the background for further decoding processing, and transmit the final result back to the management for release. The instruction makes a reference. Imagine that all processes are completed manually, which will inevitably lead to a large waste of manpower and material resources. Therefore, in the process of establishing the urban security system, a more complete monitoring system is constructed based on the face recognition algorithm, which is further obtained through identification technology. The image or video information that the monitor wants to obtain will be the optimal solution to the various information and problems needed to solve urban security. In the process of concrete operation, in the urban monitoring system, a camera system can feed back a lot of information, including image and video, etc., to find the desired person or image information from the ever-changing and resource-rich video material. , you need to use the recognition algorithm. Through the face recognition algorithm, it is possible to screen out the target person or the required image information from a large amount of rich video material, which brings some help for the investigation. This can be a very good auxiliary role for urban security, especially when the police are chasing fugitives or suspects. Of course, the role of the face recognition algorithm is not only that, it can be applied to image recognition or surveillance recognition, and can also be applied to various areas of urban security, and play a more useful role. In the future urban construction, especially in the implementation of security projects, the relevant face recognition algorithms will continue to be used and expanded, becoming an important weapon for smart cities in the process of analyzing data and feeding back real-time information. Through the face recognition algorithm, more potential urban hazards will be discovered in advance, and the safety of urban residents can be further improved. With the development of technology, the future face recognition algorithm will become more and more complicated, but it will also be used in the construction of urban security system in a simpler and more intuitive form. Because only in this way, this technology can be used by human beings for the benefit of human society.CeMAT ASIA | AI is at the time! Despising the future of Ai Ruisi robots and deducting the future of smart logistics From November 6th to November 9th, Asia Pacific's most eye-catching annual logistics technology event - Asia International Logistics Technology and Transportation System Exhibition CeMAT ASIA 2018 will be held in Shanghai Held. As the industry's leading provider of intelligent logistics robot solutions, IResearch will showcase a variety of intelligent handling robot products and solutions for logistics warehousing and smart factories, and launch the industry's first intelligent robot open platform. stay tuned! Event time: November 6th - November 9th Venue: C1 Pavilion, W3 Hall, Shanghai New International Expo Center About CeMAT ASIACeMAT ASIA is the largest logistics technology equipment exhibition in China and even in Asia. It has never been disappointing for 18 years. This is the case. It is reported that the CeMAT ASIA 2018 has a scale of over 60,000 square meters. The conference includes system integration and solutions, automatic guided truck AGV, forklifts and accessories, conveyor sorting equipment, logistics robots, AUTO-ID, machine vision, Ten key thematic exhibition areas such as packaging equipment, lifting equipment and accessories, the core strengths of more than 600 logistics equipment industries from home and abroad will be gathered here. As we all know, the logistics industry is inseparable from the real economy, and it contains a rich industrial chain and huge industrial value. With the penetration of artificial intelligence, robotics and big data technology, the development of the domestic traditional logistics industry has entered an era of intelligence and flexibility. After the relevant national ministries and commissions issued the "Top Ten Industrial Revitalization Plan", China has also included the logistics industry into the "12th Five-Year Plan". The planning outline (draft) clearly stated that ¡°we must vigorously develop the on-site logistics industry and accelerate the establishment of a socialized, information-based, and specialized logistics system.¡± In this context, defying Ai Ruisi robots focused on ¡°AI+IoT¡± In the actual scenes such as smart logistics warehousing and smart factories, the practical needs of goods sorting and intelligent handling have created comprehensive solutions such as ¡°robot + warehouse management system + data analysis¡±, aiming to integrate artificial intelligence, internet of things and robotics. The way, we will continue to promote logistics, warehousing, factories and other industries to achieve intelligent, flexible technology upgrades, to achieve cost reduction and efficiency and create value for customers. In this year's CeMAT ASIA 2018, for the multi-dimensional, all-round real display of contempt for Ai Sisi's practical ability and cutting-edge innovation technology in the process of empowering urban terminals with AI+IoT, despise the Ai Ruisi exhibition area into three Most of them are used to display the intelligent robot open platform, the new intelligent handling robot series and the intelligent storage robot "goods to people" solution. Intelligent robot open platform application scenario business complex and changeable? Multi-vendor devices are not compatible? Does the production capacity of different production lines not match? System deployment implementation cycle is long? Is the scale of deployment cost high? NO!NO!NO!N questions 1 countermeasure! This is the easy use of the intelligent robot open platform developed by Vision. open! intelligent! Support Hybrid Cloud Deployment and Secondary Development CeMAT ASIA 2018 On-site We will demonstrate the intelligent workflow of the real simulation platform through real-time robot scheduling. At the same time, we will also focus on escaping Iris in this event. Intelligent, flexible and efficient series of new robots! They are the ? rack handling robot iWR800/ iWR1300 bin handling robot iSR200 pallet handling robot iPR2000 interactive experience "goods to people" solution in the storage scene picking, handling is often the most labor-intensive existence contempt for Ai Ruisi intelligent warehousing The robot ¡°goods to people¡± solution is designed to reduce the labor cost of storage and improve the efficiency of picking. In order to let everyone truly experience the intelligent operation process, CeMAT ASIA 2018 will despise the Aries robots to restore the scenes through the interaction of the lottery. Modernized sorting mode of management, multi-machine cooperation and human-computer interaction On the way to develop smart logistics industry, we hope to create targeted intelligent solutions for industry customers through core artificial intelligence and sensory intelligence technology to help customers reduce costs and increase efficiency. And create value and all the answers will be announced in the C1 exhibition area of ??W3 Hall, Shanghai New International Expo Center, CeMAT ASIA 2018, November 6-9Authentication is welcoming new technological innovations Now in many public places, we can access the places we need to enter through some fast channels. Authentication is no longer a process that needs to wait or need to be challenged. Because of the emergence of artificial intelligence technology, it has provided a more powerful support for identity verification. On the basis of AI, authentication has also ushered in a more efficient solution. Nowadays, if we need to go to some relatively large smart parks to work, we basically need to pass through the gates, and we need to sign in. The whole process requires manpower and resources. If you are in some large-scale parks, the number of people commuting every day is very high. More, this will also lead to time delays. Of course, that¡¯s only the past, because now the era of AI authentication has arrived, this more efficient authentication solution can further solve the various problems of authentication in these office parks and help them solve the problem efficiently. Authentication requirements. For example, many smart offices now have access control attendance systems, as well as check-in systems, face recognition gates, etc. These devices are actually hardware devices generated on the basis of AI authentication. They can realize the machine through data analysis of the terminal. Recognize the purpose of the face, so that each person passing through can be identified. Instead of sending a special person to station, it is only necessary to use the front-end camera to feedback the data to identify the true identity of the person passing through the level of milliseconds, and then further verify the user. Identity, to prevent strangers or some suspects from entering, to ensure the safety of the office. With AI identity verification technicians, the pass rate will be higher, and the company's resources can be optimized. More importantly, office security can also get a greater guarantee. In the process of saving manpower and material resources, Making the office scene more efficient and safer is beneficial to the long-term development of the company. In addition to the office area, there are many public areas, such as train stations, airports, etc., which have this type of AI authentication system and equipment. The popularity of these devices will further benefit more users, and it will also help the construction of smart cities. In the future, the technology of AI authentication will be further improved, the application will be more and more extensive, and the various information that will be fed back through this identity verification system will be more experienced and will be more and more fast. I believe that there will be more enterprises or users to charge, and get a more efficient solution to life and work from AI skills.Thai Deputy Prime Minister Qi Qi and Defiance Technology Explore AI Power in Thailand's Digital Economy Construction From November 6th to 7th, Thai Deputy Prime Minister Qi Qi visited Beijing, during which he met with Fu Yingbo, President of Defiance Technology. The cooperation content in Thailand's digital economy and smart city construction is discussed in depth. ¡ø Deputy Prime Minister Qi Qi and Vision Technology to discuss future cooperation direction During the talks, Fu Yingbo introduced the development of technology, talent, capital and business since the establishment of Vision Technology in 2011, and counted the ignorance of participation wisdom. Achievements in urban, smart finance, smart retail, smart warehousing, etc. He pointed out that contempt is the leading artificial intelligence enterprise in China, and the contemptuous face recognition technology has been ranked as one of the world's top ten breakthrough technologies by MIT Technology Review Magazine, ranking 11th among the world's smartest companies, July 2017. Defiance of technology as a representative of innovative enterprises to innovate Premier Li Keqiang. The new kinetic energy report and despised independent original technology won the high recognition of the Prime Minister. In 2018, Thailand proposed a large-scale economic reform plan "Thailand 4.0" strategy, focusing on creating an Eastern Economic Corridor (EEC) that promotes long-term economic development, while seeking deep integration with China under the "Belt and Road" strategy. Among them, digital economy and smart city construction are important contents. ¡ø Deficit Technology President Fu Yingbo (second from left) reported to Vice Premier Qi Qi and his wife, according to the introduction of President Ying Bo. Defiance Technology has cooperated with the Thai government and enterprises in 2017. For example, advanced artificial intelligence technology based on the "urban brain" layout of contempt technology has been introduced into Thailand's public security protection to assist the Thai security department to accurately and effectively crack down on illegal and criminal activities and maintain social security. At the same time, based on face recognition technology, Vision Technology has also reached a cooperation with the Bank of Thailand to help it complete online real-name authentication and user identity verification. In the future, contempt for the deep participation in Thailand's digital economy and smart city construction, and the cooperation project in Thailand will become a model for Sino-Thai science and technology innovation cooperation. In this regard, Vice Premier Qi Qi welcomed: "At present, Thailand is carrying out digital economic construction, and hopes that foreign investors can develop related industries in the EEC Eastern Economic Corridor. I hope that Vision Technology can find a common foothold for cooperation between the two sides and carry out a complete set in Thailand. Investment, landing on the EEC, will promote the change of the overall economic structure of Thailand. The Thai government will give strong support. At the same time, Vice Premier Qi Qi also expressed his eager expectations and invitations to despise the participation of science and technology in promoting the cultivation of artificial intelligence talents in Thailand. The two sides stated that they will deepen the docking of the consensus reached around the meeting, formulate a work plan, and promote more cooperation. ¡øThe Deputy Prime Minister of Thailand and the President of Defiance Technology Fu Yingbo In the era of industrial and technological changes, artificial intelligence has increasingly become a new engine for economic and social development. Countries around the world have invested in the transformation of digital economy and the construction of smart cities. In the tide. As the world's leading provider of industry intelligence solutions, Vision Technology has always been global, and its products and solutions have entered Thailand, Singapore, Japan, South Korea and other countries. In the future, Defiance Technology will conduct more in-depth exchanges and consultations with Thai government and enterprises to achieve a win-win situation; it will further grasp historical opportunities, adapt to local conditions, strengthen exchanges and cooperation with countries around the world, promote artificial intelligence technology to the world, and benefit from artificial intelligence technology. All mankind"Zhongguancun - The Power of Change" is about to start broadcasting and ignoring technology. You will see the future. To celebrate the 40th anniversary of the reform and opening up, it is also the 30th anniversary of the establishment of the Zhongguancun Park. The Zhongguancun, a six-episode documentary produced by the Zhongguancun Science Park Management Committee and Beijing TV Station. The Power of Change recently held an opening ceremony and announced that it will be broadcast on Beijing Satellite TV at 22 o'clock every night from November 12 to 17, 2018. The documentary "Zhongguancun - The Power of Change" was held in Beijing. It is reported that "Zhongguancun - The Power of Change" is divided into six episodes with the theme of "Zhongguancun People's Innovation and Entrepreneurship History". The story of the struggle of Zhongguancun generations of entrepreneurs is The incisions are sorted out from the perspectives of ¡°breaking the ice¡±, ¡°breaking through¡±, ¡°leading¡±, ¡°challenge¡±, ¡°integration¡± and ¡°future¡±, showing people to see things and seeing small and big, showing Zhongguancun leading national innovation in the 40 years of reform and opening up. The fruitful results of development. Among them, Visionary Technology Co-founder and CEO Yin Qi was invited to appear in the sixth episode of "Thousands of sails to compete in Haitian Broad" to see the future of technological change. From students to creators, Vision Technology ¡°Inch¡± is not an unfamiliar name in the high-tech field. In 2011, Inch seized the opportunity of the times and shared with two other Tsinghua ¡°Yao Ban¡± students Yang Mu and Tang Wenbin. The establishment of Vision Technology, with artificial intelligence technology to drive a new round of technological change. It is well known that the founder and CEO of Vision Technology, thanks to the continuous advancement of mobile Internet, big data, and cloud computing, the innovation of artificial intelligence technology and the business operation mode have been leaps and bounds. Statistics show that in 2017, the global artificial intelligence core industry exceeded the scale of 37 billion US dollars, while China's artificial intelligence core industry accounted for more than 15%. It is estimated that by 2020, the global artificial intelligence core industry will reach a scale of 130 billion US dollars. It is not difficult to see that artificial intelligence is now a hot area in the world. In 2011, when the field of artificial intelligence was still quiet, the Indians who were still in the university entered the AI ??field, and the artificial intelligence was firmly determined to be the direction of entrepreneurship and even life, all of which showed Yinqi¡¯s grasp of the opportunities of the times. ability. Previously, the MIT TR released the "2018 Global 35 Under 35 Technology Innovations" list, and India, the only one that has just passed the year, is the only entrepreneur in the field of artificial intelligence. However, India¡¯s achievements are not achieved overnight. In the early days of the venture, the main business of Defiance Technology was a game called "Crows" by means of visual technology. The game was very downloadable at the time. However, Inca knows that the artificial intelligence technology is framed in the game field, and some are too limited. For those who have dreams of pursuing, this does not meet their long-term expectations. In order to provide strong support for technological innovation, Inge went to Columbia University to study for a doctoral degree in 3D camera. It is this spirit of bravely breaking through innovation and facing difficulties that has enabled Yinqi to win awards such as the Beijing Youth May Fourth Medal and Zhongguancun Innovation and Entrepreneurship Young Hero. Today, from the initial technical staff to the current entrepreneurial role, standing at the forefront of technological change, Inge is still learning and exploring new areas such as business models and corporate finance. Exploring, deep-cultivating, landing, leading the transformation Under the leadership of Yinqi, the seven-year-old Vision Technology has always adhered to a firm technical belief, continuously optimized self-research technology to shape the core competitiveness of enterprises, and constantly explored the frontier areas of artificial intelligence innovation, refreshing The height of Chinese AI technology. As of now, Vision Technology has won 22 international AI top competitions, including the 3 world champions of the 2017 Global Computer Vision Top Competition, the MS COCO + Places Joint Challenge, and 2018 The 4 World Champions in the MS COCO + Mapillary Joint Challenge. In addition, Vision Technology also has more than 800 patents granted at home and abroad, and is far ahead in the industry. At the same time, the application of ignoring technology AI technology has been continuously promoted and achieved fruitful results. Today, Vision Technology's artificial intelligence technology is deeply applied in financial, mobile, security, community, logistics and retail business scenarios. Among them, in the field of security, the face recognition technology with advanced technology has been entrusted to the public security system of more than 100 cities across the country, helping the police to crack more than 5,000 cases and providing intelligent solutions for major public events. In the field of mobile phone applications, Vision Technology has launched a series of mobile AI products such as face payment, face recognition unlocking, portrait light effect, portrait background blur, video beautification, 3D Animoji, etc. to meet different mobile phone manufacturers to unlock faces. The demand for image enhancement, camera enhancement, smart image and video processing has reached deep cooperation with domestic first-line mobile phone manufacturers such as Huawei, Xiaomi, vivo and OPPO in less than one year. On this basis, the leading role of contempt technology has also been recognized by the government and industry. In 2014, Defiance Technology was recognized as a national high-tech enterprise; in 2015, it was recognized as a high-tech enterprise in Zhongguancun; in November 2016, it was selected as a leading technology enterprise in Guancun; in March 2017, it was rated as ¡°one-angle¡± by the Ministry of Science and Technology. Beast" enterprise, and ranked first in artificial intelligence enterprises. In May 2017, the core face recognition technology of Vision Technology was rated as one of the world's top ten breakthrough technologies by the famous American technology review magazine MIT Technology Review. At the same time, Vision Technology was the only artificial intelligence company in China. The most intelligent company"; In 2018, Vision Technology won the title of "Top Ten Double-Creation Hard-Building Demonstration Scientific and Technological Achievements"... It can be said that as the world's leading artificial intelligence technology enterprise, Vision Technology has long been a frequent visitor to various awards. Nowadays, the promotion of artificial intelligence technology innovation and landing has become a national-level strategy, and India has long-term planning and expectations for contempt technology. How will the future contempt technology be laid out? Where will the wave of change in China's science and technology field go? Please look forward to the upcoming six-episode documentary "Zhongguancun - The Power of Change", despise the technology and India to foresee the future with you!The era of artificial intelligence dividends: How does the face recognition algorithm increase the labor rate? As a new artificial intelligence technology, face recognition algorithm will be used more and more frequently in various fields in the future. In the report of the 19th National Congress of the Communist Party of China, it is clearly stated that the future should integrate artificial intelligence with social and economic development, and use the advantages of artificial intelligence to promote the rapid development of social economy. Among them, various intelligent technologies and projects based on the face recognition algorithm will replace the traditional labor force and thus generate new economic growth points. According to relevant data, the frequency of using artificial intelligence technology to replace the traditional labor force is increasing in various developed countries around the world, and the labor force has indeed improved even after the face recognition algorithm is involved in certain work links. Various developed countries, including the United Kingdom and France, etc., have already made advances in the artificial intelligence to replace the traditional labor structure, and have achieved very good results, and have a very significant increase in labor rate. Results. Returning to China, the arrival of the era of artificial intelligence dividends has brought more hope to the country. The traditional labor structure will also change under the artificial intelligence pattern and move toward a more efficient road. Among artificial intelligence technologies, various science and technology projects based on face recognition algorithms will further change the traditional labor structure. For example, in the past, some cumbersome related projects that required human resources will be replaced by artificial intelligence machines, thereby increasing the efficiency of production and releasing more labor into the task of creativity. Secondly, in some special aspects, manpower is an indispensable labor force, but artificial intelligence technology can also be used as an alternative and auxiliary to assist relevant technicians to complete higher-tech labor-intensive projects, thus releasing greater Human value. It can be seen from the above two positive aspects that the arrival of the era of artificial intelligence dividends can indeed bring more energy to change the Chinese economy, especially the traditional labor structure, and bring about the improvement of labor and the creation of economic value. To promote the obvious role. In the future, the role of artificial intelligence in promoting China's economy will be reflected in more aspects. With the deepening of face recognition algorithms, this high-tech AI technology will gradually be popularized in various fields and played. More active and efficient. In the future, China's artificial intelligence dividend era will be more vibrant, and in addition to face recognition algorithms, new artificial intelligence technologies will be born.AI promotes smart security Smart campus continues to spread in the future When the AI ??era came, the slogan established by smart cities began to become the choice of the times. For the entire economic development society. An important standard for smart cities is AI, and AI can be embodied in many aspects, such as urban security. Security is a very important concept for human life safety, and it is also an important indicator for the establishment of a modern smart city. In the establishment of a smart park, the established intelligent security system based on AI is now gradually becoming Expand to the big scene. In the establishment of the smart park, the system that uses the monitoring system as the front-end sensor has been gradually established. In the scheme implemented by the entire smart park, the security work of the park can be further controlled through the AI ??data, through the camera and the sensor and the background. Data analysis to complete a series of coordination work. These include monitoring of strangers' visits in the park, as well as the pursuit of suspects, as well as other aspects of the residents' own safety, such as firefighting. The layout of AI data and the establishment of a smart campus have a higher feasibility plan. While benefiting urban dwellers, this program is also constantly improving the efficiency of public safety, allowing smart security to spread to more areas. Of course, at the same time as the implementation of the smart security program, we must also see what kind of improvement is needed in this future plan and concept. Where is its development direction? With the continuous improvement of AI technology, what new elements will be added in the establishment of the smart park? These are all we need to think about. For example, in modern times, the public security department is not limited to the requirement of video surveillance for the aspect of smart security, especially the surveillance video. There are still more complicated requirements, such as Video tracking, you can analyze more complex suspect information, etc. These are the direction of intelligent security layout under the ever-changing AI technology, and will only move toward an increasingly refined and comprehensive era. In addition, when the smart park is established, how can we better control the relationship between households, property, and public security, how can we better coordinate the division of labor, and through the AI ??data analysis of the terminal? Efficiently deploying the relationship between the three, this issue also needs to be considered by the founders of the future smart park. Of course, we believe that the continuous leap of AI technology will continue to provide more powerful technical support for solving these problems. Under the organization of the Ministry of Wisdom and Security, the implementation of smart cities will continue to make great strides!Looking at the future development of artificial intelligence market through real-name certification For the current development of China's artificial intelligence market, many people have a very big expectation, and in the future, artificial intelligence will continue to transform and benefit humanity. Nowadays, more precise artificial intelligence projects, including real-name authentication systems, are providing efficient service solutions for more living and office situations. Humans are almost inseparable from artificial intelligence. However, some people still worry that artificial intelligence will replace the status of human beings, thus losing some of the traditional industries or behaviors to their original value. Or will the next artificial intelligence winter come? For this problem, relevant artificial intelligence experts said that now, both China and the world, the development of artificial intelligence market has a more solid foundation. In the past, the reason why the artificial intelligence industry appeared to be decadent was mainly because the technical conditions at that time were still immature, and the implementation of the value of artificial intelligence was not optimized to a reasonable layout, so problems were inevitable. But it is different now, because artificial intelligence has developed to the present, and has a stronger foundation. For example, today's real-name certification covers all areas of life and work, and we almost need to use this artificial intelligence recognition technology when we operate or handle any service. For example, in Internet education, artificial intelligence can change the mode of education, which can create a smarter place, while real-name authentication can help users complete the identification and verification process, so that they can enjoy online Internet education more efficiently. A variety of quality services, but also to ensure the interests of operating brands. In addition, in the medical and health industry, more places need to use real-name certification to verify the information of each patient and the patient to reserve data, or the doctor can grasp the patient's body information through identification and intelligent analysis. And provide them with more accurate care solutions. In addition to these industries, the positive changes in artificial intelligence to agriculture are also obvious. For example, agriculture is gradually shifting to the process of automated planting, which is inseparable from the deployment of artificial intelligence technology. As such, artificial intelligence has been fully demonstrated. It has a stronger foundation in modern times. Through thousands of practices, it has been proven to be applicable to more categories and play its due role. For example, real-name authentication has become the standard for contemporary identity verification. It is convenient, efficient and accurate. This is the artificial intelligence technology that people need. These technologies are also constantly creating profits for users or enterprises, and giving them a more efficient office or living atmosphere through technological transformation. So in general, the future of artificial intelligence will be more optimistic, and the winter will go away.Despising popular products to light up the Wuzhen World Internet Conference to showcase the light of AI innovation As an important part of the World Internet Conference, the 5th "Light of the Internet" Expo is also coming, the world's most advanced Internet technology, new applications Once again gathered in Wuzhen. China Mobile's 5G experience car, Alibaba's one-stop smart experience hall, Gaode's ¡°One Map Tour Wuzhen¡±, Defiance Technology City Sky System, Smart Retail Solution, etc., in Industrial Internet, Smart City, New technologies and new achievements in the fields of e-commerce have all appeared in Wuzhen. Compared with traditional Internet companies such as BAT, some innovative companies that have emerged in the mobile Internet era are also worthy of attention. As one of the earliest companies to enter the field of artificial intelligence in China, Vision Technology has also started its latest original AI technology and products in the fields of security, mobile phone, car, retail, logistics, etc., and partner Amers Semiconductor (ams) ) Visit the main exhibition hall of the Expo to showcase. This year, the contempt exhibition area is still the hot spot of the Internet Light Expo. The products and solutions of the city's Sky 2.0 system, end-to-end intelligent security, smart retail, mobile AI, logistics robots, etc. Industry media, professional audiences have a wide range of concerns. It is understood that this year is the fourth time to despise the Expo on the Internet. Throughout the four years, I have despised the AI ??innovations presented at the Expo, from Sky 1.0 to Sky 2.0, from face recognition to human recognition, behavior recognition, and gestures. Identifying, from security to mobile, retail, logistics, car, cloud-to-software and hard-to-end, end-to-end, despise every year with practical action to interpret never-ending innovation. In 2018, contempt also introduced their new technologies, products and solutions at the fair. Defiance of security black technology concentrated on the explosion of the eye and then eye-catching security, is one of the earliest technical applications and vertical business areas. In recent years, contempt has proposed an end-to-end intelligent security solution, targeting the typical scenarios in the security business and the actual demands of the "love, finger, and diligence" linkage, through the "algorithm, technology, hardware products, solutions, data" full value Chain output helps public security users build a new intelligent security closed-loop system from front-end perception to cloud research and judgment to terminal applications. According to the defiance of the staff, today's immersive intelligent security of the cave portrait system, video structured analysis system, as well as smart cameras, portable portraits and other hardware products, has been in more than 100 cities across the country, and is also the G20 summit, Security technical support for major international events such as Xiamen Golden Brick Summit, Hainan Boao Forum, and SCO Summit. It is reported that contempt has also provided security technical support for the certification of the World Internet Conference in 2015. It is worth mentioning that Deterrence Technology also demonstrated the upgraded City Eyes 2.0 system at this expo, and this system has become one of the most eye-catching exhibits in the main exhibition hall. Combining big data and deep learning algorithms, the city's Sky Eye 2.0 system will take the lead in AI vision technology such as face recognition, pedestrian recognition, vehicle identification, trajectory tracking and video structuring, and urban security, urban transportation and urban governance. The combination of actual scene requirements can provide intelligent identification of key personnel in public security, traffic violations, and urban mobile vendors. On-site, despising this collection of advanced AI vision technology, the Tianyan system also provides visitors with real-time face recognition, portrait comparison, video structured analysis, black technology experience, and promotes contempt for "the sky" is always crowded . ¡ø Despise the city Tianyan 2.0 system to force the mobile AI innovation to build a personal IoT IoT network "brush face instant unlock", "brush face security payment", "master AI beauty" ... these are contempt in this fair Key words on its introduction to AI technology and solutions on the mobile side. With the rise of the AI ??application wave in the mobile phone industry, contempt has also entered the mobile phone industry early and is the first to introduce a mobile and AI-aware full-stack solution, from algorithm innovation, application development, equipment manufacturing to solutions, for industry customers. Implement AI empowerment. From the current mobile phone AI application on the market, despise face-based payment, face recognition unlocking, portrait light effect, portrait background blur, 3D Animoji and other mobile AI based on core deep learning and computer vision technology? The product has been deployed in the latest models released by many mobile phone manufacturers to meet their needs for face unlocking, image enhancement, camera enhancement, smart image and video processing. At the fair, contempt also showed 3D face unlock payment and 3D portrait light technology for OPPO Find X. ¡ø User experience defies the dense key point detection technology. In addition, the newly developed car AI vision solution was also unveiled at this year's fair. According to reports, Vision Technology has developed multi-scenario intelligent products and solutions in the front-loading and after-loading markets of automobiles. The core technologies include gesture recognition, expression recognition, line-of-sight tracking, and coordination with multi-modal human-computer interaction. Face recognition, driver status detection, vehicle collision and lane departure warning in intelligent and safe driving. Car AI visual empowerment is another important layout in AI innovation in mobile. AI has opened up retail and logistics scenarios to help commercial efficiency upgrades. In the retail industry, contempt has also brought new AI solutions this year. According to reports, for the offline retail scene data is missing, can not use the pain points of data-driven decision-making, ignoring the industry-leading computer vision algorithm and the object-aware terminal system, independently developed a new cloud service + smart terminal retail Industry Solutions. Through multi-dimensional perception and understanding of customer identity attributes, behavioral information and various types of data triggered by shelves and commodities, and then fusion analysis and deep mining of data, help merchants enhance the capability boundary of store operators, optimize business strategies and supply Chain management, in order to achieve cost reduction and efficiency in the process of store data. ¡ø Defiance of application display in security, retail, logistics and other scenarios on the retail supply chain side, contempt began to explore in 2018 and gradually put into action. On the retail supply chain side, the digital and intelligent upgrade of logistics and warehousing is becoming an urgent need of the industry. Relying on the strong research and development strength of powerful robots, big data, artificial intelligence and other core technologies, the company has created a logistics warehousing robot solution to meet the business needs of customer warehousing and sorting and intelligent handling through AI+ robot products. According to the contempt, in the logistics industry, contempt has reached strategic partnerships with many well-known domestic e-commerce warehousing, logistics and manufacturing companies, and through the construction of an open intelligent robot platform, to achieve cost reduction and efficiency for more partners, Create value. Regained the heavyweight awards, the technology was recognized by the organizing committee. With the advanced AI technology visual display and good interactive experience, the booth of Defiance Technology was received by the provinces and cities, all levels of units and various media and other participating audiences during the conference. Strong attention. During the Expo, the core results of the artificial intelligence in the contemptuous science and technology exhibition area were also reported by the media. ¡ø CCTV's set of evening news on the black technology report of contempt technology is worth mentioning, in this year's World Internet Conference released "World Internet leading scientific and technological achievements" list, defiance of science and technology original mobile end deep learning convolutional neural network ShuffleNet has also been successfully selected, which is the original core technology after the selection of industrial-grade face recognition technology in 2017, defying technology to be nominated for the world's leading Internet technology. Since the first exhibition in 2015, the previous World Internet Conference has witnessed the rapid growth of Vision Technology. At today's World Internet Conference booth, it is amazing to despise the product matrix and pioneering application scenarios built around AI+IoT. Through constant algorithm upgrades, product iterations, and countless self-breakthroughs, Defiance Technology has grown from a slightly new and emerging unicorn company to the global machine vision artificial intelligence industry leader and face recognition product leader. The more you appear on the world stage, the light of civilization, the light of the future and the light of wisdom that showcases China's science and technology! Looking to the future, looking forward to contempt can bring more extraordinary AI technology innovation and create more value for the society.Demystifying the story behind ¡°buy, buy and buy¡± defying Iris Technology's empowerment supply chain On November 6-9, the annual Asia International Logistics Technology and Transportation Systems Exhibition (CeMAT ASIA) was grandly held at the Shanghai International Expo Center. Held as the industry's leading provider of intelligent robot solutions, he defied Ai Ruisi robots with a number of intelligent handling robot products and solutions for logistics warehousing, smart factories, and launched the industry's first intelligent robot open platform To demonstrate to the industry the practical capabilities and cutting-edge innovations of AI+IoT enabled terminals. Enhancing the effectiveness of human effects and devouring the launch of the new family of intelligent handling robots. In this exhibition, a series of more flexible and flexible intelligent robot products exhibited by Iris have received wide attention. These include the iWR500, a smart storage and handling robot in the ¡°goods to the delivery¡± mode, the iWR1300 with 1.3 tons of extra-large capacity and unlimited expansion of multiple systems, and the iSR200 and iPR2000, which can be autonomously obstacle-based based on laser navigation and visual navigation. Accurate recognition and positioning of people, compatible with human-machine hybrid scenes. ? Despise the Ai Ruisi intelligent handling robot series in the contempt of the Iris exhibition area, the scorned rack handling robot can take the goods to be picked up according to the order task to the picking point, and the picking staff completes the picking at the picking point. The robot then transports the rack to the next picking point or moves back to the inventory area, with an accuracy rate of over 99.99%, which can improve the picking efficiency by 2-3 times, and greatly improve the human effect and efficiency of warehouse management. At present, the number of robots that Iris has implemented has reached more than 3,000. Not only widely used in e-commerce, new retail, 3PL (third-party warehousing), 3C, medical, food, daily necessities, industrial and automotive manufacturing industries, but also refreshed the single-ware robot cluster operation industry record, in the future of Tianjin No. "Cang, contempt for Ai Sisi and Xinyi Technology to realize the intelligent warehousing scene of 500 robots working together efficiently. Their main job is to complete the order and fast and accurate order selection, and these AGV robots become Tianjin warehouse this year. The main force of a period. The staff in the warehouse introduced: ¡°Tianjin warehouse has nearly 50,000 SKUs, large daily volume, manual sorting is difficult, labor intensity is high, and operating costs are high. After the introduction of storage robots, the number of workers is greatly reduced. Labor intensity, greatly improve warehousing efficiency, and achieve cost reduction and efficiency.¡± Open, easy to use, intelligent contempt Ayres launches intelligent robot platform. It is well known that in the context of new retail and intelligent manufacturing, enterprise warehousing faces improvement efficiency. And the dual challenge of reducing costs, intelligent robot automation solutions have become the core competitiveness, on the one hand, the business business is complex and changeable, it is difficult to form a standardized solution; on the other hand, robot manufacturers only provide equipment and control software, can not be proposed for business processes Complete solution. In this regard, contempt for Ai Ruisi hopes to solve the user's series of pain points by creating an open platform that is open, easy to use and intelligent. Its advantages are to support multi-device access, standardizable library areas and components of dockable business systems, scalability, support for hybrid cloud deployment and secondary development, enabling rapid deployment and cost-effectiveness for industry users. Based on the cloud-based workflow, the Iris intelligent robot platform can be widely applied to the intelligent and digital construction of factories and warehouses. For example, in the ¡°goods to person¡± transfer mode of the warehousing scene, the scornful intelligent robot open platform can effectively solve the situation of capacity mismatch between multiple site areas: the staff of the site area W1 and W2 call the empty shelf from the buffer area B. After loading, the goods are shipped to the buffer area B; the staff in the site area W3 calls the fully loaded shelves from the buffer area B, unloads the shelves, and leaves the shelves to the buffer area B. In terms of implementation cost, defying the intelligent robot open platform occupies a big advantage: the number of robots in general warehousing or factories increases with the amount of business, and the software cost of applying robots to do intelligent work increases, and needs to be based on different businesses. Different hardware is used for corresponding software customization development, and the labor cost and implementation cycle are uncontrollable. Defiance of Ai Ruisi's open platform can simultaneously access a variety of smart devices, while highly intelligent and abstracting intelligent operations, and providing a friendly, simple interface to connect MES, WMS and other business systems, not It will have too much impact due to changes in the number of devices and services, so the marginal cost is lower and the scale effect is obvious. With the change of times, industrial upgrading has become the top priority of society and economy. Under the premise of industrial 4.0, intelligent manufacturing and intelligent logistics, the industry needs new technologies and new ideas. As a strategic technology that leads a new round of scientific and technological revolution and industrial transformation, artificial intelligence, Internet of Things, flexible manufacturing and other technologies have become an important strategic resource for China's science and technology leapfrog development, industrial optimization and upgrading, and overall productivity jump. This is especially true in the robotics industry. In the face of huge industry upgrades, IResearch robots hope to contribute to the logistics industry and the manufacturing industry through the ¡°AI+IoT¡± technology and solutions. From unmanned warehouses to "smart warehouses", from "manufacturing" to "intellectual creations", defiance is advancing technological changes along with cutting-edge industry partners.Attack on China's AI Policy Dividend Since 2015, Smart Manufacturing has opened the road to artificial intelligence development. In 2016, Internet+ accelerated. In 2017, artificial intelligence was officially included in the national strategy. In 2018, local governments paid attention to artificial intelligence. The degree has also increased, and AI related development plans have been introduced. According to incomplete statistics, since 2016, local governments such as Beijing, Jiangsu, and Guizhou have first introduced AI-related development planning policies. In 2018, Heilongjiang, Hebei, Tianjin, Fujian, Sichuan, Guangdong and other provinces and cities have also followed up the "New Generation Artificial Intelligence Development Plan" issued by the State Council last year, on the development of technology and applications, personnel training, and industrial scale. And the goal gives a general plan. For example, the ¡°Guangdong Province New Generation Artificial Intelligence Development Plan¡± officially announced by the Guangdong Provincial Government in August pointed out that by 2025, the core scale of Guangdong's artificial intelligence industry will exceed 150 billion yuan, driving the related industries to reach 1.8 trillion yuan; by 2030, the entire labor force The development of intelligent industries must enter the high-end link of the global value chain. As of October this year, more than 19 provinces and cities across the country have launched a new generation of artificial intelligence development plans. While actively responding to the national strategy, local governments are also trying to create a differentiated development direction related to the artificial intelligence industry by combining local resource advantages and development conditions. Among them, Beijing, Guangdong, Guizhou, Jiangsu, Zhejiang, Shanghai, and Anhui are the regions that are the first to implement IT informationization by policies, and they are relatively more active in the promulgation of artificial intelligence policies. In comparison, Hubei, Chongqing, Jiangxi, Heilongjiang, Liaoning, Hebei, Tianjin, Fujian, Sichuan, Hebei and other places are still actively developing development plans, and there are no specific implementation rules. In addition to the introduction of relevant policies, the AI ??Conference was held, and the AI ??competition was held to compete for the establishment of enterprises. Since this year, various governments have staged AI competitions. Under the support and promotion of government policies, major universities have set up AI-related courses, established AI research institutes, and jointly established innovative laboratories to establish artificial intelligence joint laboratories. Even in the field of children's education, artificial intelligence education such as programming classes began to set off a wave of learning in the society. In fact, the core appeal of the AI ??policy led by local governments is to strengthen business incubation and innovation, and introduce and train high-end talents to drive the transformation of the local economy. It is worth mentioning that while governments at all levels are planning AI-related policies, there are also a series of initiatives in the scientific and technological cooperation between the Hong Kong SAR and the Mainland of China. It is understood that Hong Kong's latest "Budget" mentions the development of innovative technologies such as artificial intelligence. At present, Huawei and WeChat have set up innovation laboratories and artificial intelligence joint laboratories at the Hong Kong University of Science and Technology. Alibaba has jointly established the Hong Kong Artificial Intelligence Laboratory with the Hong Kong Science and Technology Park. Sino-US AI policy wrestling: China has obvious advantages in latecomers, and concentrates on doing big things. China attaches great importance to the development of artificial intelligence, and has a more comprehensive top-level design of artificial intelligence. In March 2017, artificial intelligence was first written into the ¡°2017 State Council Government Work Report¡± and officially entered the national strategy. In July 2017, the State Council issued the ¡°New Generation Artificial Intelligence Development Plan¡± (referred to as ¡°Planning¡±), clearly defining artificial intelligence as an important national development strategy for the future, and determining the strategic goal of ¡°three-step¡±: by 2020, The overall technology and application of artificial intelligence is synchronized with the world's advanced level. The artificial intelligence industry has become a new important economic growth point. The application of artificial intelligence technology has become a new way to improve people's livelihood. By 2025, the basic theory of artificial intelligence has achieved a major breakthrough, some technologies and applications. To reach the world's leading level, artificial intelligence has become the main driving force for China's industrial upgrading and economic transformation. The construction of intelligent society has made positive progress. By 2030, the theory, technology and application of artificial intelligence have reached the world's leading level, becoming the world's leading artificial intelligence innovation center. . On October 31, 2018, the Political Bureau of the CPC Central Committee held the ninth collective study on the status quo and trends of artificial intelligence development. Xi Jinping, general secretary of the CPC Central Committee, emphasized that artificial intelligence is an important driving force for a new round of scientific and technological revolution and industrial transformation. Accelerating the development of a new generation of artificial intelligence is related to whether China can seize a new round of scientific and technological revolution and industrial transformation opportunities. Strategic issues. Under the strategy, it is necessary to focus on enhancing originality and focus on key core technologies to consolidate the foundation of the development of a new generation of artificial intelligence. According to the financial allocations of the Ministry of Industry and Information Technology of the past years, science and technology expenditures have been the second largest fiscal expenditure outside education, and have maintained a scale of investment of more than 11 billion yuan from 2011 to 2017. 2011-2017 The Ministry of Industry and Information Technology has allocated funds for science and technology over the years. At the same time, the investment of Chinese private capital in the field of artificial intelligence is also catching up. According to CBInsights' 2018 Trends in Artificial Intelligence, China's artificial intelligence start-ups accounted for 48% of the global total in 2017, more than doubled in 2016. In the international arena, the United States has long introduced a series of AI-related policies to support and regulate. In October 2016, the White House released "Preparing for the Future of Artificial Intelligence" and the National Science and Technology Committee issued the "National Artificial Intelligence Research and Development Strategic Plan", which officially raised artificial intelligence to the US national strategic level. State-funded artificial intelligence research and development delineation strategies, and developed seven long-term US strategies in the field of artificial intelligence. Counting the development strategy of artificial intelligence over the years, we can find that the United States puts more emphasis on economic development and social services, so that new technologies can be fully applied. However, since the new President Trump took office, the US government has not continued to implement the AI ??strategic plan formulated during the previous president. It is reported that the Trump administration's fiscal expenditure in basic science and research has declined. According to the Ministry of Energy's advanced scientific computing research plan, the budget for FY 2019 is expected to be US$ 811 million, down from US$ 1.2 billion in 2016. 32.4%. Earlier, Eric Schmidt, the executive director of Google's parent company Alphabet, publicly stated in November last year that although US artificial intelligence can still maintain its lead in the next five years, it will soon be overtaken by China. In May 2018, the White House Summit in the United States revealed the Trump administration's new strategy for the development of artificial intelligence. It is understood that in October this year, the Massachusetts Institute of Technology announced that it will invest 1 billion US dollars to open a new Su Shimin School of Computer Science. This investment is by far the largest investment in computer and artificial intelligence in American academic institutions. Relatively speaking, the US government has some leading actions in the artificial intelligence development policy, but in recent years, Chinese policy has gradually turned to artificial technology, big data, cloud computing, Internet of Things and other emerging technology industries.Artificial intelligence technology in the field of public safety The continuous innovation of technology has enabled artificial intelligence to play an active role in many areas of urban life, such as urban public safety. Modern artificial intelligence technology can reach the level of commercialization, and there are many types of applications in the field of public security, including image recognition, video structure technology and intelligent big data analysis. These artificial intelligence technologies are further Benefiting urban life. Take image recognition technology as an example. In understanding this concept, we can simply understand it as a process of using computer to process and analyze images in detail. Through this process, users can identify images of different targets and objects in different modes and reach The purpose of tracking and identification. With the advancement of computer deep learning technology, modern image recognition technology has made a qualitative leap on the basis of traditional technology. The new technology has a higher recognition rate, and has a better accuracy and environmental resistance. The show is precisely because of the advancement of technology, enabling image recognition technology to be applied to more technology industries. Today, face recognition or image recognition technology based on deep learning, and a comprehensive breakthrough in the manual modeling mode, has obtained more powerful technical support in breaking the limitation. Especially in the actual working environment, it is also possible to learn and identify a large amount of data. Even if the identified factors and objects change, or complex interference occurs, today's image recognition technology can control this change. Even so, An excellent precision recognition process can still be achieved. Today, including transportation, life, video and ecology, and the application of image recognition and video recognition technology, artificial intelligence technology in the daily life, especially in the application of the technology industry, and become more and more Common, the maturity of technology also gives artificial intelligence technology a large number of mature applications. In addition, coupled with the promotion of policies and the popularization of artificial intelligence technology, coupled with the huge demand for modern urban public safety construction, artificial intelligence technologies including image recognition, video surveillance analysis, and data processing have broader application prospects. . In the future, intelligent video technology based on the cloud with higher-end convergence capability will become the mainstream, and the future development direction of artificial intelligence will continue to move toward the video structuring process, and in the near future, big data analysis and Artificial intelligence technology will also present an unprecedented degree of tacit understanding.Beijing Municipal Party Committee Secretary Cai Qi visited the Vision Technology Research Institute. On November 12th, Beijing Municipal Party Committee Secretary Cai Qi visited Beijing Defiance Technology Co., Ltd., and the Beijing Municipal Committee Standing Committee and Secretary General Cui Shuqiang and Beijing Vice Mayor Yin Yong jointly investigated. During the investigation, Cai Qichao looked at the technology demonstrations such as the Sky-Eye System and the ¡°City Brain¡±. The company¡¯s co-founder and CEO Yin Qi reported to the company on the promotion of artificial intelligence technology innovation and business innovation practice. Cai Qi emphasized that the most representative of private enterprises in Beijing is Zhongguancun enterprises and private technology enterprises. Party committees and governments at all levels should conduct in-depth visits to service enterprises and send ¡°service packages¡± to provide one-on-one services for enterprises. Enterprises create a better development environment. Vision Technology is an artificial intelligence enterprise founded in Zhongguancun, Beijing. It has more than 900 patents granted by domestic and international artificial intelligence (more than 440 authorized), and the core face recognition technology developed by the company is rated as the global ten in 2017. Big breakthrough technology. In the fields of finance, mobile phone, security, logistics, retail, etc., face recognition technology, image recognition technology, intelligent video cloud products, smart sensor products, and intelligent robot products have been widely used. ¡ø Cai Qi listened to Vision Technology co-founder and CEO Yin Qi report artificial intelligence technology and business innovation Cai Qi pointed out that innovation is the life of Zhongguancun enterprises. Only originality can lead. Defiance of technology must increase key core technology research and continue to make new breakthroughs. It is necessary to strengthen the connection between technology and demand, apply artificial intelligence innovation results to the construction of smart cities, provide technical support in the fields of public management and security protection, and help improve the level of urban governance. We must make good use of the city's high-tech industry policies, do better and better, and strive to be the smartest company in the world. At the symposium, Cai Qi emphasized that all levels and departments must insist on visiting the service enterprise system, continuously optimize the business environment, and fulfill various policies. We must support enterprises to achieve more breakthrough results in original innovation, and strive to cultivate more unicorn companies and invisible champion enterprises. In response to the development needs and problems of enterprises, relevant departments should study and solve them one by one. ¡øYin Yong, deputy mayor of Beijing, delivered the ¡°service package¡±Defiance of Science and Technology to Participate in the Construction of Beijing Zhiyuan Artificial Intelligence Research Institute On November 14, at the opening ceremony of the 2018 China (Beijing) International Technology Transfer Conference, the Beijing Zhiyuan Action Plan was officially released. Beijing Academy of Artificial Intelligence Research (Beijing Academy) The Artificial Intelligence, BAAI) was unveiled. Party Secretary and Minister of the Ministry of Science and Technology Wang Zhigang, deputy secretary of the Beijing Municipal Committee and Mayor Chen Jining attended the meeting. Desperate Technology was invited as one of the co-constructed units of Beijing Zhiyuan Artificial Intelligence Research Institute. Deco-Tech Co-founder and CEO Yin Qi and the Beijing Municipal Science and Technology Commission Director Xu Qiang and Haidian District Mayor Dai Binbin jointly unveiled the institute. . ¡ø "Beijing News" reported that Beijing Zhiyuan Artificial Intelligence Research Institute was established, defiance of science and technology as one of the co-construction units, Visionary Technology Co-founder and CEO Yin Qi (fifth from right) attended the opening ceremony of Beijing Zhiyuan Artificial Intelligence Research Institute Chen Jining In his speech, the mayor pointed out that Beijing Zhiyuan Artificial Intelligence Research Institute is another important new research and development institution after Beijing's brain science and brain research center and quantum information science research institute. The institute will bring together the superior units in the field of artificial intelligence, such as Peking University, Tsinghua University, Chinese Academy of Sciences, and Vision Technology, adopting new scientific research organizations and talent introduction and training models to promote the development direction of artificial intelligence and theories, methods, tools and systems. A key breakthrough. Beijing will bring government, business and social data to this platform, build new open source artificial intelligence tools, and integrate the computing power of universities and large enterprises into various AI R&D institutions, welcoming global artificial intelligence research. People participate in the use. Xu Qiang, director of the Beijing Municipal Science and Technology Commission, announced the Beijing Zhiyuan Action Plan. Under the guidance and support of the Ministry of Science and Technology and the Beijing Municipal Government, the plan is jointly proposed by government departments, enterprises, universities, institutes, etc. It is the top-level design of Beijing's service artificial intelligence development, and is an action plan that embodies the wisdom of all parties. In accordance with the deployment of the Beijing Zhiyuan Action Plan, the Beijing Science and Technology Commission and the Haidian District Government promoted the establishment of the Beijing Zhiyuan Artificial Intelligence Research Institute. The institute relies on the superior units of artificial intelligence in Peking University, Tsinghua University, Chinese Academy of Sciences, and Vision, to build an open service platform, hold an artificial intelligence summit, coordinate the promotion of joint laboratories and personnel training, and adopt an internationally-oriented, flexible and autonomous operating mechanism. The implementation of the Institute "lightly loaded" and "run faster." As a leading technology enterprise in the field of artificial intelligence in China, Defiance is one of the earliest technology companies in China to develop artificial intelligence applications using deep learning methods. Based on the self-originating AI technology system, it despise the innovative research and development capabilities at all levels including training engines, core algorithms, basic platforms, and intelligent products. In the industrial practice, through the AI+IoT collaborative development strategy, it has despised the self-developed face recognition technology, image recognition technology, intelligent video cloud products, smart sensor products, and intelligent robot products widely used in finance, mobile phones, security, In the fields of logistics and retail, we will help the industry and society to achieve intelligent upgrades. In the future, Defiance Technology will rely on its own advantages in artificial intelligence technology research and development, platform construction, data mining, talent integration and other aspects to participate in the Beijing Zhiyuan Action Plan, and build Beijing Zhiyuan Artificial Intelligence Research with Beijing and industry chain partners. hospital. Leading innovation to open source and data integration, exploring the construction of intelligent innovation ecosystem; integrating talents, production, research and research resources to achieve major core theoretical breakthroughs in artificial intelligence; leveraging AI+IoT industry empowerment practices to accelerate artificial intelligence frontier technology Industrialization and social application. Promote Beijing to become the source of global artificial intelligence academic thinking, basic theory, top talents, enterprise innovation and development policies, support the development of artificial intelligence industry, promote the deep application of artificial intelligence, change the life of human society and change the world.Looking at the employment trend of the smart security industry from the artificial intelligence landing security industry is an industry that comes into being with the security needs of modern society. It can be said that as long as there are crimes and unstable factors in the society, the security industry will exist and develop. At present, the demand for equipment in the security market is still one of the fastest growing markets. Industry with the closest combination of smart security With the development of high-definition video, intelligent analysis, cloud computing and big data, security is moving from traditional passive defense to active judgment and early warning. The industry is also moving from a single security field. Industry application, improving production efficiency, and improving the direction of life intelligence. The rapid development of artificial intelligence technology has actively promoted the security field to move toward a more intelligent and humanized direction, mainly reflected in the following aspects: smart transportation, smart buildings, smart communities, and smart policing. Artificial intelligence technology is the future of the security industry. Artificial intelligence is the future of security. On the road to the future, there are still many obstacles and difficulties that need to be overcome and overcome, but the overall trend is optimistic. From the algorithm to the demand, the security field with unique advantages is constantly advancing the comprehensive industrialization of artificial intelligence in the security field. 1. Video structuring (identification and extraction of video data) In the security field, video surveillance is undoubtedly an indispensable part. With the acceleration of the construction of smart cities and safe cities, the information redundancy caused by the massive image and video information generated by the security system every day has also spawned the application of computer vision technology with artificial intelligence in the security field. 2, biometric technology (fingerprint recognition, face recognition, etc.) Currently, face, fingerprint, iris three recognition is a widely used biometric method. The fingerprint belongs to the contact recognition method, and the face and the iris belong to the non-contact identification mode, and the three complement each other. 3. Object Recognition System At present, the most important application of object recognition system in the security field is the license plate recognition system. The technology of license plate recognition has been used in the security industry for a long time. The technology is relatively mature, and the application of artificial intelligence improves the accuracy of license plate recognition. rate. Only the artificial intelligence brain with independent, individualized and constantly evolving and perfecting can solve the increasing demand in the security field, become the experts and assistants of the users, enhance the intelligence level of the entire security field, and promote the upgrading of the security industry. Employment trends in the security industry As one of the world's largest security markets, China will continue to lead the global security market. Compared with developed countries and regions, the current video surveillance penetration rate of security equipment in China is still at a low level, which means that China's security market still has a lot of room for growth, and the market potential is huge. In other words, for a long time to come, China will continue to play the role of the first engine of global security growth. Looking at the world, China's security manufacturers are not only spectacular in terms of volume and growth rate, but also in the forefront of the industry in terms of security technology innovation and overall solution capabilities. Especially in the current situation of deep integration of security technology and AI, China has become the center of security technology innovation. China's security leaders, including Hikvision and Dahua, have become the pioneers of global technological innovation. According to statistics, in 2017, the total output value of China's security industry reached 620 billion, and the industry growth rate was 14.8%. In addition, the "13th Five-Year Plan (2016-2020) Development Plan of China's Security Industry" pointed out: during the "13th Five-Year Plan" period The security industry will transform and upgrade to scale, automation and intelligence. By 2020, the total revenue of security enterprises will reach 800 billion yuan, with an annual growth rate of more than 10% and an industry added value of 250 billion yuan. Embracing artificial intelligence "People's Daily" reported on artificial intelligence data: It is estimated that by 2020, China's artificial intelligence (AI) industry will exceed 150 billion yuan, driving related industries to more than 1 trillion yuan, such rapid growth and development. There will inevitably be a large demand for talent. Some industry insiders believe that the ratio of supply and demand of domestic artificial intelligence talents is only 1:10, and supply and demand are seriously unbalanced. Zhou Ming, deputy director of the Education and Testing Center of the Ministry of Industry and Information Technology, also revealed to the media in 2016 that there is a gap of more than 5 million talents in artificial intelligence in China. In the past two years, this gap will become larger and larger.2018 Chongqing International Mobile Phone Show | Defiance of technology and software innovation leads the future of mobile phones On November 15th, the second Chongqing International Mobile Phone Show hosted by Chongqing Economic and Information Committee and hosted by Mobile Newspaper was held in Chongqing as the current domestic The largest mobile phone industry event with the largest scale and the most complete industrial chain, this year's exhibition gathered nearly 300 enterprises in the upstream and downstream of the mobile phone industry to present and exchange cutting-edge innovations. As the leading provider of soft and hard integrated smart terminal solutions in China, Vision Technology also participated in a number of original mobile phone AI visual innovation products, and won the "2018 China Mobile Phone Industry's Most Influential Enterprise" award, which fully demonstrated its contempt Create extraordinary power on the new AI Phone. At the Chongqing International Mobile Phone Show in 2017, Defiance has won the ¡°Top Ten Excellent Suppliers in the Mobile Phone Industry¡± for its R&D and application breakthroughs in face recognition unlocking technology. After a lapse of one year, the sharpness of the AI-enabled mobile phone has not diminished, and further promotes the future direction of AI Phone in the mobile phone industry. Especially in the upgrade process of mobile phone AI vision, in order to bring more detailed and comprehensive intelligent operation experience to users, the mobile phone products of various manufacturers began to cooperate with the upgrade of software and hardware to enhance AI vision capability. In the past year, based on the deep understanding of the mobile phone industry, in the practice of developing mobile phone AI vision applications, the business has been upgraded to create a software and hard phone that covers algorithms, applications, solutions and hardware. AI vision solution, and successfully developed a series of mobile AI products such as face recognition unlocking and payment, AI portrait light effect, AI micro-shaping, smart beauty, 3D bionic sensing technology, including Huawei, Xiaomi, vivo, More than 100 million mobile phone devices from domestic first-line mobile phone manufacturers such as oppo bring subversive AI visual upgrades such as face unlocking, image enhancement, camera enhancement and video processing. These are the technological innovations and achievements in the forefront of the industry. Only promoted contempt for growth as "the most influential enterprise in the 2018 China mobile phone industry." At the 2nd Chongqing International Mobile Show, Vision also demonstrated the face recognition unlocking, AI portrait light effect, smart beauty and 3D bionic sensing, car AI vision and other soft based on deep learning and computer vision technology. A hard-integrated smart terminal AI vision product. Mobile phone AI application innovation in the AI ??empowerment of mobile phone unlocking, despising the face recognition unlocking technology based on the original deep learning engine MegBrain and mobile-side convolutional neural network ShuffleNet, can adapt to high-end and low-end mobile phone chips and single-shot, Dual-camera, 3D camera module, efficient RGB face unlocking, zero-light infrared face unlocking, monocular/binocular structured light and ToF face unlocking. In terms of performance, the unlocking speed is less than 100 milliseconds, which can achieve high-speed fluency of bright screen and unlocking. In addition, scorn reduces the unlocking misunderstanding rate to one in a million, and it also has a payment level while ensuring convenience. safety. Despise the underlying technology of mobile phone AI vision application - the key point of face is dense in self-timer, contempt is also based on self-developed facial key point detection, facial 3D modeling, human body segmentation, 3D light effect rendering algorithm and other core technologies to create AI portrait light effect and intelligent beauty application, allowing users to enjoy the studio-level lighting effect and the star-rated beauty and beauty experience with only the mobile phone. 3D biomimetic sensing technology despise 3D bionic sensing technology based on binocular structure optical module. With the increasing demand for 3D-sensing applications, the contempt team is also working hard to create 2.5D and 3D visual perception solutions. Adapt to 2.5D dual-pass, 3D structured light, binocular structured light, ToF and other modules. At this exhibition, contempt also debuted the 3D vision overall solution based on binocular structured light, which includes contempt from optical design, platform development to IQ evaluation and Tuning, as well as 3D basic algorithms and 3D application algorithms. The process independent research and development and innovation, in the continual optimization and adjustment of the contempt team, defying the 3D bionic sensing technology based on binocular structure light in the indoor Depth precision range from 20cm to 1.2m, the measured data surpasses iPhone X; Under the outdoor light of 100,000 Lux, the depth map effect of the real face is not lost to the iPhone X. And in terms of cost control, the cost of the solution can currently achieve the lowest level of similar binocular structure light scheme, and has good productivity and deliverability. In addition to bringing the product display on the mobile phone side, the car AI vision solution will also bring the car AI vision solution developed in the field of smart terminals to the exhibition for demonstration. For the AI ??technology application upgrade in the automotive industry, the AI ??vision solution created by the scorn has adopted self-developed AI vision algorithms such as face recognition, gesture recognition, expression recognition, and line-of-sight tracking, combined with infrared camera modules to accurately identify Driver identity (face recognition unlocks the door, face recognition starts the engine), detects driving status and behavior (yawning, closing eyes, bowing, shaking your head, calling, smoking, etc.) to ensure the safety of the driving process. Not only that, but the car AI vision solution with the car intelligent system, can also support more than 20 static / dynamic gestures, common scenes such as pick up / hang up the phone, volume adjustment, control media playback, etc.; support four emotion recognition, combined with voice The assistant can make the boring and long driving journey interesting and interesting; its sight tracking technology can also be applied to the intelligent interaction between the vehicle equipment. At present, it deserves to provide multi-scenario intelligent products and solutions in the front and rear loading markets, and has already reached an in-depth cooperation with Weilai Automobile in vehicle AI vision solutions. Nowadays, the penetration of AI in the industry has entered an accelerated period, and the combination with various fields of terminal equipment has become the only way for AI to bring transformation and upgrade to the industry. In the field of mobile terminals, mobile phones as an important device for carrying human digital life and work, the combination with AI will not only bring a new round of market vitality to the industry, but also bring unprecedented convenience, efficiency and entertainment to people. Life and work experience. At present, Vision has given AI a personal IoT, providing AI vision solutions for mobile terminals such as mobile phones and automobiles as one of its important development directions. Future contempt will continue to focus on mobile intelligent terminal identification and certification. In the fields of computing photography and 3D perception, we have completed more technical innovations and landings of soft and hard integration, and let AI fully benefit everyone. Face recognition software assists in catching fugitives Artificial intelligence market ushers in development Some time ago, the incident of frequent fugitives in Zhang Xueyou's concert became a hot topic in the city. Everyone is well-rounded, the number of concerts of big stars will naturally not be small, basically the mighty, Renshan people, but why can the police repeatedly pick up the fugitives from the crowd? All weapons are in face recognition software. As the core of today's recognition technology, face recognition software plays an important role in many fields and has a major impact on China's artificial intelligence industry. Through face recognition software, the public security department can identify the characteristics of fugitives in dense crowds, and use facial recognition technology to further detect specific targets in the crowd through digital images. Face recognition has a lot of working methods, but it is inseparable from the model built on the basis of data. In the actual work process, facial recognition includes a lot of different work content, including the difference between people's appearance, gender, age, and identity. We can use this face recognition technology as a human brain neural network, or data to gradually make the network more mature, and then let it have the learning function, so that it can cope More complex identification sites. The fugitives at the Jacky Cheung concert were actually captured through this technology. The facial recognition technology gave the public security department more precise and quick arrest conditions, so that they could find the escaped faster and better. Prisoners provide a stronger foundation for maintaining public order. The current application of face recognition software has not only been applied to the arrest of prisoners, but also to the retail, marketing and financial industries, and plays a very important role. At the same time, the benefits of face recognition software-related products are also very large, which further highlights the business opportunities in the artificial intelligence market. Face recognition software brings convenience to users' daily life and also provides greater convenience for the establishment of smart cities. It is reported that China's artificial intelligence market is facing a period of vigorous development, market share is increasing, and the development process of face recognition software is constantly deepening and spreading to more different levels. With the development of face recognition technology, everyone can use artificial intelligence in the future, and enjoy the convenience that artificial intelligence technology brings to their lives and work. Face recognition technology will be further expanded in the application category, and achieved more brilliant results.The positive impact of artificial intelligence authentication on future education Education is a national plan. The combination of modernity, education and artificial intelligence provides a new development direction and a broader development platform for the development of modern education. More labor Smart technology can be applied to education, such as authentication. Now, in the creation of a smart education environment, artificial intelligence can provide more powerful technical support for the design of this large environment. In the campus environment based on the wisdom of the Internet of Things, the traditional operation links can be changed through more high-end AI technologies, and the efficiency of intelligent education can be effectively improved. Authentication is one of the most representative cases, which can be more effective in the field of campus security detection and early warning. For example, in the entire campus campus, security is very important, how to ensure the identity of each visitor, and the identity of strangers entering, this time authentication will play an important role. Through the operation of big data, the front-end monitoring system can monitor the identity information of each visitor or visiting user and authenticate it, thus providing greater security for campus security. In addition to being able to identify visitors, authentication can also play a big role in the establishment of smart classrooms. It can record the identity of each student participating in the smart classroom and complete the attendance process. The many advantages displayed by smart classrooms can further change the educational environment of students. For example, they can cooperate remotely, and they can also interact with data. They can also integrate humans and humans. Many advantages are combined to improve students' learning. effectiveness. In addition, authentication provides technical support for intelligent learning remote support, providing a more convenient identification system for online classes. In addition, you can participate in smart education evaluation, and provide a higher recognition scheme for the teacher's identity video. In addition to identity verification, the combination of artificial intelligence and education can be reflected in many different aspects, such as the monitoring of learning burden monitoring and early warning, as well as the companionship of intelligent learning robots, which can provide more for children's learning. Convenience provides a better foundation for companionship learning. Through all of the above, we can further understand the impact of artificial intelligence on the future development of education, and this impact will also move toward a more intelligent and more efficient pace.Despise Wisdom Education Solution, Full Scene, Innovation and Foundry Safety From November 17th to 19th, the 75th China Education Equipment Exhibition hosted by China Education Equipment Industry Association, Jiangxi Provincial Education Department and Nanchang Municipal People's Government, in Nanchang The Greenland International Expo Center is held. As an IoT solution provider with artificial intelligence as its core, Vision Technology brought the newly developed artificial intelligence education products and solutions to the site and made its debut at this exhibition. ¡ø Defiance of the 75th China Education Equipment Exhibition accompanied by the in-depth development of China's education information technology, artificial intelligence, Internet of Things, cloud computing and other emerging technologies have begun to broaden the field of education industry, promote educational equipment, teaching mode, teaching environment Deep innovation in other aspects. In this process, ¡°AI+ Education¡± stands out as the development trend of the future education industry. In the strategic layout of AI-enabled business IoT, Vision Technology has also begun to explore the upgrade thinking of integrating AI into the education industry, and will create an industry-leading soft and hard integrated smart education solution as a key breakthrough direction for its business. At this year's China Education Equipment Exhibition, Destiny demonstrated its smart education products and solutions covering the whole field of smart teaching, smart management and smart logistics for the first time, attracting many professional visitors to stop and experience. ¡ø Mr. Zhang Shaogang, Executive Vice President of China Education Technology Association, visited the booth and despised the wisdom education solution to despise the wisdom education solution. It is a sneak peek at the needs of the actual scene of the campus, based on self-developed face recognition and other sophisticated AI vision. Technology, efficient platform development and hardware innovation capabilities to create industry solutions, including classroom teaching evaluation system, intelligent time and attendance system, campus security system, dormitory management system, personnel verification system, access control system, conference sign-in system, etc. Integrated smart education products. Through flexible and innovative products, terminals that adapt to rich scenes, and cloud platforms with excellent performance, Vision Technology makes it possible to implement refined, secure and humanized campus management, and has given new dynamism to improve the level of education information and intelligence. In order to realize the AI ??reform teaching mode, the wisdom teaching promotes the teaching efficiency and quality, and despise the creation of a new classroom intelligent attendance system and classroom teaching evaluation system. ¡ø Despise the classroom intelligent attendance system equipped with high-definition cruise camera to despise the classroom intelligent attendance system, by defying the self-researched attendance camera, no dead-angle cruise shooting classroom and automatic zoom shooting of the face; together with the scorn classroom intelligent attendance host box MegBox -B2D's intelligent analysis ability, verifying the identity of students in class by means of face recognition verification, and achieving intelligent attendance without perception and cooperation. Compared with the traditional name attendance and credit card attendance, ignoring the classroom intelligent attendance system can greatly improve the efficiency of attendance and reduce the workload of teachers. ¡ø Despise the classroom teaching evaluation system equipped with attendance and behavior analysis camera MegEye-C3V-920. In the classroom teaching evaluation system, ignoring the self-developed face recognition, behavior recognition, expression recognition and other technologies, integrated in attendance and behavior analysis In the camera MegEye-C3V-920 and behavior analysis server, through the real-time structural analysis of classroom video data, feedback multi-dimensional classroom data such as student behavior, expression, concentration, and front-up attendance rate, assisting teaching evaluation and evaluation. Defiance of classroom teaching evaluation system can effectively solve the problem that traditional teaching has a single dimension of teaching quality assessment, teachers can not pay attention to all students, lack of comprehensive and efficient closed-loop feedback, provide classroom teaching effect feedback, help teachers improve teaching modes, methods, and improve teaching. quality. Smart management addresses the deficiencies and problems in the management of campus security protection, student status review, and examiner identification, defiance of people as the core, giving full play to the technical advantages of face recognition in security and auditing scenarios, and creating campus security System, personnel certification system, assist campus security and information management. ¡ø Despise the person's card verification and verification machine, strictly check the student status and the examination room identity and despise the campus security system, and deploy the face at the bayonet location of the key places in the campus (such as the main entrance, school entrance, dormitory door, library entrance, etc.) The capture machine can perform high-level face detection and capture on the person passing through the bayonet, realizing real-time stranger warning, blacklist comparison alarm and face retrieval, and improve campus security. Despising the human witness verification system, by defying the R&D personnel verification and verification machine, it can also check the student¡¯s student status, and realize the student¡¯s photo, photo ID, and student¡¯s own verification. Early warning; the identity verification of the candidates, combined with the ID card, the admission ticket, the registration information, the face verification method is used to verify the identity of the candidates, to effectively crack down on frauds such as taking the test, taking the test, and creating a fair and equitable credible examination room. . Smart logistics ¡ø despise M5 smart panel machine, face recognition hemisphere machine, face recognition gate, create campus wisdom logistics, do a good job in campus teaching, safety work, integrate new technology into campus life, change the school logistics service, It has also become an important part of the intelligent construction of educational information. Defiance of the smart logistics also introduced the dormitory management system, access control system, conference sign-in system and brush face payment system to create a smart campus life and work environment for teachers and students. Based on the advanced intelligent products such as M5 smart panel machine, face recognition hemisphere machine and face recognition gate, the contempt can provide face recognition technology for campus dormitory, teaching building and conference room. Quick pass and check-in experience; especially in the dormitory scenario, the contempt dormitory management system can also analyze and analyze various conditions such as bedtime, bedtime, and number of late arrivals in real time, helping the instructor to obtain comprehensive and detailed students. In bedtime information, improve the efficiency and safety of dormitory management. In addition, contempt is also promoting the application of the brush face payment system in major campuses, and combining the ¡°Campus One Card¡± system to comprehensively enhance the intelligent consumption experience upgrade of campus teachers and students. Education, which determines the future of mankind, also determines the future of mankind. Education is a cause of decisive significance to the great rejuvenation of the Chinese nation. Education is good for the country, and education is strong for the country. In the era of rapid development of science and technology, education must also integrate advanced technology to truly achieve prosperity. In the planning and layout of the education industry in the National Medium- and Long-Term Education Reform and Development Plan (2010-2020) and the Education Informatization 2.0 Action Plan, it is clearly pointed out that it is necessary to speed up the process of educational informationization and promote labor. The whole process application of intelligence in teaching and management. At present, ignoring wisdom education has helped Tsinghua University, Beijing University of Science and Technology, Zhengzhou University, and more than 100 colleges and universities in the People's University of China to upgrade the smart campus. In the future, ignoring wisdom education will continue to closely follow the country's policy guidelines, and in-depth understanding of the diverse needs of the campus, using AI innovation and one-stop service capabilities to create an omni-directional interactive campus teaching, comprehensive perception of the campus The environment, efficient and coordinated campus management, and convenient and convenient campus life are all efforts to promote the education and intelligence of Chinese education and enable more people to enjoy the quality education of science and technology.Smart Campus: Breaking the ¡°information island¡± and cultivating the intelligent community ecology Smart campus is the advanced form of university informationization. It uses cloud computing, Internet of Things, mobile internet, big data, artificial intelligence, social network, knowledge management, virtual reality. Such as various emerging information technologies, comprehensively perceive the campus physical environment, intelligently identify the learning, work scenarios and individual characteristics of the teachers and students. At the same time, establish a virtual image of campus in the cyberspace, connect the physical space of the school and the digital space organically, master the law of campus operation and feedback and control the physical space through the calculation of cyberspace, and establish an intelligent and open educational and teaching environment for teachers and students. Facilitate a comfortable living environment, change the way teachers and students interact with school resources and environment, carry out personalized and innovative services based on people, realize the wisdom of schools, and support schools to carry out wisdom education. Based on the design and implementation of the smart campus design, this study breaks the boundaries of business departments and the ¡°information islands¡± of business systems by building a unified data center, unified business process network and unified service portal throughout the school. A consistent ¡°information road network¡± within the scope, thereby improving the efficiency of various business links such as teaching, research and management. Research progress at home and abroad In the 1970s, the Massachusetts Institute of Technology first proposed the "Electronic Campus" program. In 1990, Kenneth University professor Kenneth first proposed the concept of ¡°digital campus¡± and presided over the ¡°Digital Campus Project¡± (hereinafter referred to as CCP) research project. Since the implementation of the CCP program, the US government has promulgated and implemented the National Education Technology Plan in 1996, 2000, 2005, and 2010 to realize the ¡°human, machine, road, and network¡± connection from primary school to university. It has completely changed the way, means and process of combining higher education teaching and learning in the United States, and has made the informationization of American education always at the international leading position. The United States has always followed the strategic principle of ¡°information technology for education reform and development¡± and has undergone a process of change from ¡°emphasizing the structural structure system application operation effect structure adjustment¡± to the digital campus and the smart campus. The United Kingdom, Australia, New Zealand, Japan and other countries have also developed and implemented a series of educational informationization promotion plans, such as the United Kingdom has introduced the "education highway: forward plan" "2010-2012 education development strategy", Australia launched " The roadmap for the implementation of the digital education revolution, New Zealand has developed the ¡°School Digital Learning Action Plan¡±, and Japan has implemented the ¡°School Networking Plan¡±. These action plans and strategies provide typical examples and experiences for other countries to implement the transition from digital campus to smart campus. Affected by foreign countries, China's college education informatization has also experienced the development process from electronic campus to digital campus and smart campus. Since the 1980s, China's college education informatization has experienced more than 30 years of development. From the early computerization, campus network construction, to the mid-term network information system construction and digital campus integration and integration, the recent emphasis on business processes Optimization and service integration, information technology is increasingly integrated into the education and teaching business of colleges and universities, and informationization of colleges and universities has begun to enter the stage of smart campus construction. On the other hand, with the widespread application of emerging information technologies such as cloud computing, Internet of Things, mobile internet, big data, Internet +, artificial intelligence, social networks, and virtual reality in universities, the integration of information technology and education and teaching services is coming. The deeper the informatization of colleges and universities, from the development of management information to the comprehensive informationization of education and teaching, the relationship between information technology and education and teaching evolved from combination and integration to integration and innovation, which promoted the conception, development and construction of the concept of smart campus. The goal and concept of smart campus construction From the user's point of view, the campus breaks the boundaries of traditional business systems and builds a flat, easy-to-operate, search engine-style unified open and scalable information and service platform. The platform carries all kinds of business and information of colleges and universities, realizes visual presentation of data assets, statistical analysis and decision-making, and fosters online intelligent community ecology of teaching, research, management and life in colleges and universities. The platform includes online transaction center, big data center, online community platform, information center, personal workbench, mobile portal and so on. The construction of a smart campus is a complex system project, and the following four concepts should be followed. IntelliSense. Applying IntelliSense technology to sense, capture, collect and transmit real-time data of various environments, resources and activities related to teaching, research, management and life in the physical campus, and realize the operation status of teachers and students on campus. The comprehensive perception of the trajectory of work and life, the interaction between teachers and students and the campus environment provides a perceptual support for the comprehensive dataization of the smart campus. The data is in volume. Data is the foundation of a smart campus and a core asset of a smart campus. In the smart campus, all kinds of information such as the basic state of people and things, various activities and environmental interactions should be fully dataized. Data should be connected, shared, factorized, and fully processed. Data connections should be extensive, and feedback should be generated through connections. And interaction, thus inspiring the innovation and integration of ¡°chemical reaction¡±. The process is phase. The process is the carrier for the generation, circulation and use of data. It is the method and way to realize the activities of teaching, research, management and life in the smart campus. The smart campus can be regarded as a large-scale ¡°real-time collaborative division of labor network¡± composed of teachers and students and various types of equipment as ¡°nodes¡±. The division of labor between teachers and students and various types of equipment ¡°nodes¡± through the construction of a unified business process network achieve. In the process, data is also generated, streamed, and used through a unified business process network. Service is used (teacher-student-oriented). Breaking the boundaries of the physical campus, providing a comprehensive, one-stop, online and offline comprehensive service for teachers and students to solve the practical needs of teachers and students in teaching, research, management and life, and support the development of individualized personnel in colleges and universities. Scientific research, intelligent management decisions, and intelligent life. The construction of smart campus The idea of ??building a smart campus is a complex system engineering. It must adopt systematic thinking and methods to design and implement the program, including the following aspects. overall plan. Carry out the top-level design of the smart campus architecture, build a modular, flexible and scalable technology architecture, and fully consider the technology trends and security guarantees such as cloud computing, big data, mobile, and intelligent. Grasp the two ends and implement the middle. The front-end is based on a unified service platform, which supports mobile APP and WeChat access, improving the user experience of teachers, students and administrators. The back-end is centered on the big data platform to achieve school-wide data fusion, achieve unified data standards, unified data views, unified data flow, unified data governance and unified data analysis, and truly use data as a core asset of the school. In the middle, the business process is the core. By co-organizing and standardizing business processes with various business departments, the front-end user service experience and the back-end unified data are connected to build a school-wide business process network to provide consistent teaching for teachers and students. Scientific research, management, life, social and other services, as shown in Figure 1. Take the point and face, step by step (iteration), and pay attention to actual results. The construction of a smart campus is a long-term process that cannot be accomplished overnight and can only be implemented step by step. In the process of step-by-step implementation, each step must find the key points in the current stage of school teaching, research and management, and cut the current urgent needs of the majority of teachers, students and management personnel, as a starting point, step by step, step by step, step by step .The Ministry of Industry and Information Technology jointly launched a "strong country dialogue" to explore the AI+ real economy. To study and implement the spirit of the important speech of General Secretary Xi Jinping in the ninth collective study of the Political Bureau of the CPC Central Committee, implement the "Central and State Organs Working Committee on promoting the central and state organs." The relevant requirements of the young cadres' in-depth study of Xi Jinping's Opinions on Socialism with Chinese Characteristics in the New Era, on November 20, despised the Science and Technology Department of the Ministry of Science and Technology and the Ministry of Industry and Information Technology, and the party committees and league committees directly under the Ministry of Industry and Information Technology, jointly organized the theme of " Studying the spirit of the important speech of the General Secretary and promoting the deep integration of artificial intelligence and the real economy. More than 600 comrades from the Ministry of Industry and Information Technology and relevant units participated in the event, despising Ren Zhiwei, vice president of science and technology, as a representative of artificial intelligence unicorn enterprises, and manufacturing Leading enterprises, artificial intelligence leading enterprises, investment circles and academic representatives exchanged in-depth exchanges on the development trend of artificial intelligence, the bottlenecks restricting the integration of artificial intelligence and the real economy, and cracking measures. Gao Wen, an academician of the Chinese Academy of Engineering and a professor at Peking University, who gave lectures on the ninth collective study of the Political Bureau of the CPC Central Committee, also came to the scene to make a keynote speech. He briefly conveyed the spirit of General Secretary Xi Jinping's important speech, introduced the development history and situation of the global artificial intelligence industry, combed the advantages and shortcomings of China's artificial intelligence development, and focused on how to promote the integration of artificial intelligence and the real economy, and bring into play the advantages and promotion of data. Valuable suggestions for the technological development of SMEs. Professor Gao Wen pointed out that from the perspective of international situation, artificial intelligence has been listed as a national strategy by many countries, but overall its development characteristics are driven by some cutting-edge enterprises, which play a vital role in the artificial intelligence revolution. effect. In the critical period of the great rejuvenation of the Chinese nation, how to better combine artificial intelligence technology with the real economy, so that China seizes the opportunity in this industrial revolution is crucial. At the meeting, representatives from manufacturing leading enterprises, artificial intelligence leading enterprises, artificial intelligence unicorn enterprises, investment circles and academia also integrated the spirit of the important speech of the general secretary of internship, focusing on artificial intelligence and the real economy, especially There is an in-depth dialogue with the integration of manufacturing. Ren Zhiwei, vice president of Vision Technology, believes that to promote the artificial intelligence innovation application on a large scale, it requires artificial intelligence combined with the Internet of Things to achieve data-driven and human-machine collaboration. Taking contempt technology as an example, in the process of empowering intelligent manufacturing and smart factories, contempt not only to create "eye of the machine" and "machine brain", but also to connect the hands and feet of the robot, so that the machine has the ability to perceive. To improve the operational efficiency of the production line. The development of the dialogue between the powerful countries not only provides a platform for the cadres and workers of the directly-owned organs, especially the young cadres, to combine political learning and business learning, and further promotes the mutual promotion and integration of the work and business of the party building group. In the next step, the party committees, league committees and trade unions directly under the Ministry of Industry and Information Technology will cooperate closely with the relevant departments and bureaus, and will organize representatives of the government, enterprises, academia, investment institutions and authoritative media to promote the construction of the "two strong countries". In-depth dialogue on issues to help the majority of party members and cadres in the form of exchanges and seminars to better deepen their understanding of Xi Jinping's new era of socialism with Chinese characteristics and the spirit of the 19th National Congress of the Communist Party of China, and better implement the central government's major decision-making arrangements with practical actions. Solidly promote the construction of two powerful countries.The Vision Technology Artificial Intelligence Patent won the 20th China Patent Excellence Award. On November 23, 2018, according to the results of the 20th China Patent Awards announced by the State Intellectual Property Office, it was submitted by Beijing Vision Technology Co., Ltd. The invention patent (patent number ZL201610306250.7) based on the neural network model has successfully won the 20th China Patent Excellence Award. Photo: Defiance Technology won the 20th China Patent Excellence Award Source: The State Intellectual Property Office official website shows that the ¡°China Patent Award¡± is the only government department award in China that rewards inventions for granting patent rights. The State Intellectual Property Office and the World Intellectual Property Organization jointly select and award the award, which is the highest patent award in the country. The China Patent Awards are held annually for all companies in China and have been held for 20 times since 1989. The selection criteria include multiple dimensions such as patent quality, technological advancement, application and protection measures and effectiveness, social benefits and development prospects. The selection process includes selection of recommendations, preliminary examination acceptance, professional review, review committee review and other aspects. The competition is fierce. . Defiance of being able to be awarded the China Patent Award is the recognition of the contempt of intellectual property by the selection unit, and it is also an affirmation of the scornful technological innovation capability. Defiance of Yongli AI Tide The key to holding independent intellectual property rights Since its inception, technological beliefs and constant innovation have been contempt for the creed that technology has remained unchanged. So far, contempt has captured 24 world technology evaluations. It has repeatedly beaten giants such as Google, Facebook, and Microsoft in the international AI top competition related to computer vision. In the COCO and Mapillary competitions of ECCV 2018, ¿õThe view is even more than four crowns, refreshing the new height of China's AI technology. At the same time, its independent research and development of computer vision technology and intelligent hardware, intelligent cloud services and other products have reached the world's leading level. It has the world's largest face recognition open platform Face++ and third-party face authentication platform FaceID, and has launched a number of vertical areas including face recognition payment, face recognition unlock, full frame smart capture machine A groundbreaking AI product. Among them, the core face recognition technology of Sci-Tech Self-study has been rated as one of the world's top ten breakthrough technologies in 2017 by the famous American technology review magazine MIT Science and Technology Review, and the Vision Technology has also entered the list of the world's 50 most intelligent companies. ". After seven years of accumulation, Defiance Technology has formed a more scientific and complete layout in terms of intellectual property rights such as patents. At present, Vision Technology has submitted more than 1,000 patent applications related to artificial intelligence in China, the United States, India, Europe and other countries and regions, becoming one of the enterprises with the most independent intellectual property rights in the artificial intelligence industry. At the same time, the patent layout covers various technical levels such as training engine, core algorithm, basic platform and intelligent products, and uses core algorithms as a link to form five major industries, including financial security, smart city, mobile phone intelligence, commercial object, and industrial robot. Patent package. With continuous self-developed technology and solid intellectual property work, since 2015, Vision Technology has been selected as the key demonstration enterprise of Zhongguancun Intellectual Property by Zhongguancun Intellectual Property Promotion Bureau, Beijing Municipal Intellectual Property Office and China National Intellectual Property Office. Beijing Patent Demonstration Unit and National Intellectual Property Advantage Enterprise have won many honorary titles such as ¡°Intellectual Intelligence Leading Enterprise in Artificial Intelligence¡± and ¡°Top Ten IPR Influential Organizations¡± in the industry. Among the Chinese unicorn enterprises selected by the Torch Center of the Ministry of Science and Technology, Defiance Technology has also been rated as the head unicorn enterprise in the field of artificial intelligence in China for two consecutive years. At the same time, in April 2018, Visionary Technology Co-founder and CEO Yin Qi was also selected as the most influential person in the field of intellectual property in 2017. In August, Vision Technology was awarded the National Intellectual Property Demonstration Enterprise. Value and pragmatism, useful innovation, defiance, help technology, strong country, defiance of science and technology, the "patent based on neural network model-based target tracking method and device" patent, which is awarded the China Patent Excellence Award, is the basis of accurate tracking of target objects based on artificial intelligence technology. The patent can better detect and track the target for video, improve the speed and accuracy of target tracking, and solve the existing target tracking method. There are repeated calculations, which leads to increased computing time, affecting the computing speed, and the target of the video to be processed. The test results cannot be mutually optimized, which affects the accuracy of the detection and tracking. It has very important significance in practical applications such as live TV, public security, and intelligent transportation. The invention patent has been widely used as a core patent technology in the defensive security video structured products, serving the public safety management of more than 100 cities across the country, and the accumulated services have guaranteed dozens of international and domestic conferences such as the Boao Forum and the G20 Summit. It has played a major role in maintaining social public safety. 2018 is the 40th anniversary of reform and opening up and the tenth anniversary of the implementation of the National Intellectual Property Strategy Outline. At the moment, artificial intelligence has become a new engine of innovation growth in China, which embodies China's overall technological innovation strength and plays a pivotal role in industry transformation, innovation and upgrading. As the first batch of enterprises in China to set foot on the wave of artificial intelligence revolution, Defiance Technology has always regarded technological innovation as its driving force. At present, contempt has established independent research institutes in Beijing, Shanghai, Nanjing, Chengdu and Seattle, and has established artificial intelligence joint laboratories with Xi'an Jiaotong University, Hong Kong University of Science and Technology, Shanghai University of Science and Technology and other institutions of higher learning. In November 2017, Vision Technology officially established the Academic Committee. Academician Yao Zhizhi, the only Chinese winner of the Turing Award, served as the chief consultant, and promoted the underlying technological innovation through the combination of talent gathering and production, study and research. At the same time, in the practice of artificial intelligence basic research and industrial integration, contempt has also established its own technical production and engineering capability system, and built a complete technical matrix around the core computer vision capabilities. In the future, under the state's emphasis on and support for intellectual property rights, Defiance Technology will further strengthen its technological beliefs, innovate constantly, enhance its patent application and layout quality, and use more high-value artificial intelligence patents to help enterprises develop and help ¡°scientific and technological powers¡±. "strategy.Despise Technology Tang Wenbin: In-depth Scene Polishing Products Realizing the Value Creation of Artificial Intelligence On November 27th, 36keWISE 2018 ¡°The King of the New Economy¡± Summit officially kicked off in Beijing. As the leading enterprise in the field of artificial intelligence in China, Tang Wenbin, the co-founder of Vision Technology, was also invited to attend the summit and gave a speech on "How AI creates value for industry and society." ¡ø Defare Technology Co-founder Tang Wenbin attended 36 WISE 2018 ¡°King of New Economy¡± Summit and delivered a speech. At the time when the new economic tide completely subverts the industrial development, WISE 2018 ¡°King of the New Economy¡± summit focuses on ¡°new economy, new¡± The annual theme of ¡°Leader, New Asia, New Future¡± brings together the most influential and innovative ¡°king of the new economy¡± of this era to jointly explore and promote the future of new commercial civilization. What is changing the world is not the value created by technology-derived products. The current new economy is based on the information revolution. Its core is to promote the rapid development of the digital economy driven by next-generation information technologies such as big data, cloud computing and artificial intelligence. At present, various industries and enterprises are fully embracing the digital transformation, exploring and establishing a new stage of commercial value. However, many companies are obsessed with the aura that AI and other technologies bring to themselves. They lack thinking about the products that ultimately carry the technology. They can't tell the difference between the means and the purpose. They don't actually reduce the cost for the company, create their own value, and eventually become a bubble. portion. In this regard, Tang Wenbin gave his own opinion: "Enterprise digitalization, any data online is a means, does not bring real value, but the final formation is the innovation of business operations and management, this is the purpose. In fact, we see Artificial intelligence companies, or the artificial intelligence products we are doing ourselves, we will find that all the technologies we do are essentially means, and AI technology is a means to make products, and the products you make are actually realizing the value of the scene. Means. This is the same as contempt for its own position. Defiance has always emphasized that contempt is not an AI company, but a product company with AI technology as its core. Defiance of the ultimate focus is a valuable product, not the technology itself. What is the value? Reducing costs, improving efficiency, and optimizing the experience. Since its establishment, it has been deeply involved in the field of artificial intelligence for seven years. From the beginning of its establishment, it has always adhered to and implemented the "technical belief" and "value and pragmatism", hoping to use artificial intelligence to create beautiful for mankind. . This year, contempt for the mission of the enabling industry has become clearer about its mission ? to create maximum value for customers and society with extraordinary technology. But specifically, what is the value of contempt to create? Tang Wenbin gave the answer at the summit: ¡°Reducing costs, improving efficiency, and optimizing the experience ? it is the value of contempt for the continuous output of the industry customers.¡± Tang Wenbin for example: ¡°For example, we are in the process of handling bank loans. At that time, I have to carry my ID card to the bank outlet to handle it, but in 2015, I defrauded the launch of FaceID online authentication products. We can make real-name authentication on the mobile phone through face recognition. We hope this Things don't need you to go to the outlets and you can go online directly, which is essentially reducing costs.¡± Now, through the FaceID online face authentication platform, contempt has provided ¡°free for home¡± for 400 million people. "Or a "just one run" intelligent financial service experience, bringing cost control improvements to many financial companies and users. In "improving efficiency" and "optimizing the experience," Tang Wenbin also reflected in the intelligent upgrade of security and buildings. In the past security operation mode, it was a tedious and lengthy task to search for the suspects from the surveillance video. This is why it takes a lot of manpower and enough time for the staff to look over and over again. Surveillance video; today, defying a series of end-to-end smart security products, the application of the landing, significantly reduced the police process and time, greatly improving the efficiency of the police. In addition, Tang Wenbin also introduced that the face recognition access control products that despise research and development have helped many companies and buildings to replace the past fingerprints or credit card access methods, and the door is open when you walk past. The general experience is becoming the first choice for the optimized experience of major companies and office buildings. At present, contempt is along the strategic layout of its own AI+IoT, and continues to bring the value of ¡°reducing costs, improving efficiency, and optimizing experience¡± for many industries involving public IoT, commercial IoT and personal IoT. Defying the value creation logic in the scene to practice "perception, decision-making, execution" as a CV company, and at the same time in the emerging industry of artificial intelligence, what kind of "means" to achieve their own value creation? In this regard, Tang Wenbin also gave the answer: "Our approach was first to do computer vision perception, but in practical applications, we found that only doing computer vision can not present the ultimate value, this value needs to rely on later decisions and Actions are presented. For example, we are just talking about the security business scenario. In a case investigation, we identified a fugitive for a certain person. If there is an action, that is, if you get the police to arrest him, you can count it as the crack and completion of the case. Let's say that we know a lot of new retail scenes. We know that a customer picks up a bottle of mineral water and looks at it, but he finally took the soda next to it. There is only such scene data. Not enough to help the store to improve the efficiency, we need to help him make a decision-making system to help him improve." Therefore, despising the use of technology-based value creation is following the "from perception to decision to execution" Logic. This logic requires the enterprise to touch the real scene and push back from the scene to clarify the logic application. Tang Wenbin took the scorn of entering the robot field as an example: ¡°Defiance of logistics robots as one of its core businesses. We found that in the logistics industry warehouses, pickers sometimes need to walk 30 times a day in a minus 10 degree environment. -40 km, most people are not willing to do such a hard work, which leads to high labor costs and turnover rate. For this scenario, we choose to do robots, we hope to be in the eye of the empowerment machine In addition, using the machine's 'legs' to solve the problem of action, using the machine's 'hands' to solve the problem of grabbing, we use a series of product portfolios to achieve cost reduction and experience optimization for such scenarios." This set of logic defied the beginning of its own logistics robot business practice. At present, Defiance has created the largest robotic smart warehouse in Asia, and actually invested in 500 AGV robots, adding robotic arms and a series of other intelligent equipment. In this year's Double Eleven, the warehouse had more than 80,000 orders on the same day, and the overall efficiency increased by 44%. Robots and algorithms are essentially means in nature, and the means are destined to serve specific scenarios. Defiance is the origin of perceptual technology. What you need to do after sensing is control. When you can control many machines, you need to let the machines work together to complete the operation of the scene, and finally realize the value creation of artificial intelligence products. In the face of the future, Tang Wenbin also planned the road of contempt for technology: "We hope to return to the value of the scene through some means like this, and return to how I can help the scene to reduce costs and improve efficiency. We hope to provide a name called The brain of the robot network, this is what we want to do next."Despise contracting CCPC China University Student Programming Competition 5 years of sponsorship AI Science and Technology Review: After the intense competition on November 24-25, 2018, the 4th China University Student Programming Contest (CCPC) Finals on the 25th At the end of the curtain, "Tsinghua University _ Second Power" stood out from the 114 teams and won the championship with absolute solution. China Collegiate Programming Contest (CCPC) is an annual event organized by the China University Student Programming Competition Organizing Committee. It aims to improve and demonstrate the ability of Chinese university students to design innovation and solve practical problems through competitions. Excellent computer talents lead and promote the reform of program design teaching and talent cultivation in Chinese universities. The CCPC competition has been held for the fourth time. The main sponsor of this year's event is Vision Technology. According to the final list data of CCPC 2018, "Tsinghua University _ Zhongli Zhili" successfully solved 10 questions and won the championship in one fell swoop. The runner-up team was the "Nanjing University_Coffee Chicken" team from Nanjing University, and the "Fudan University_Prayer" team won the third place. The remaining teams that won gold medals came from many universities, including Fudan University, Hong Kong University, East China Normal University, Shanghai Jiaotong University, Zhejiang University, Peking University, Guangdong University of Technology, and Zhongshan University. (Enterprise team does not count) CCPC 2018 Finals final list CCPC Competition Chairman of the Competition Committee Professor Yu Yong said in an interview after the game that the biggest feature of the CCPC event is that it is rooted in China and emphasizes the integration of Chinese background in the thinking. From the training of players with the ability to solve the real problems of the Chinese industry, rather than simply through the sea of ??tactics to develop a solution to the "routines." In this regard, Tsinghua University ACM coach Professor Xiao Xiaoying expressed his approval. He believes that this year's proposition level is relatively high, and the set questions are difficult. There is no trap in the topic design and description of the title. The team members can focus on algorithm analysis, design and implementation. Give full play to the strength of the team. It is understood that in order to fully prepare for this competition, Tsinghua University will arrange training in the mode of ¡°taking the old and the younger¡± from the beginning of the year, so that the seniors will teach the young members the experience. Defeat Technology Co-founder Tang Wenbin (second from right) presented the CCPC 2018 Competition Champion as the organizer of CCPC Finals. Wang Xuan, Dean of Harbin Institute of Technology (Shenzhen) School of Computer Science, told reporters that the reasons for the promised hosting of the event were mainly Two points, one of which is to take into account the formality of the event, whether it is from the scale of the event, the effect of publicity, the strength of sponsorship, and the idea of ??the problem, I believe that it can inspire the computer students of the school. Second, he also hopes to let more students know about Harbin Institute of Technology (Shenzhen) campus through the competition. At the same time, the young entrepreneurs who came from Tang Wenbin's competitions supported the CCPC's actions. Wang Xuan, the dean, was also very impressed.¿õ ¿Æ¼¼ ¿Æ¼¼ ¿Æ¼¼ ¿Æ¼¼ CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC CC Under the advocacy, Defiance Technology is also the general sponsor of this year's CCPC competition. In the competition environment and the setting of the game, Tang Wenbin said to Lei Feng.com that the CCPC competition is one of the best programming competitions in China, which can guarantee fairness, professionalism and differentiation. Defeat Technology Co-founder and CTO? Tang Wenbin is the former gold medal in the information science Olympic competition, the sixth in the world finals of the ACM/ICPC international college programming competition, and the fifth in the TopCoder Target in China. Tang Wenbin believes that the past competition Experience has greatly contributed to the growth of oneself. The gains include: one is the ability to solve problems, the competition can cultivate the ability to model problems, and develop the way of thinking to solve problems; the second is to win the heart, during the competition The psychology of winning will greatly stimulate personal potential; the third is the ability of teamwork. Because the competition requires three people to work together to answer questions, it is a test of the cooperation between the teams. The process will also involve the coordination of the team, invisible. It has fostered the leadership of the coordinator. Therefore, Tang Wenbin hopes that college students can participate in the competition without affecting their academic performance, and he will also give back to the competition through physical means. Despise will continue to be the sponsor of the CCPC competition in the next 5 years, so that the organizing committee can Continue to expand the influence of the event without any worries, so that more students will benefit. The contestants should "stand the scene from a technical point of view and look at the technology from the perspective of the scene." Tang Wenbin said that Desperate Technology welcomes contestants from the competition to join the company team. He highly recognizes the strong technical strength of the students from the competition, and also emphasizes that the lack of exercise in the engineering system is a problem that cannot be ignored. Therefore, he suggested that students can usually carry out engineering practice, and at the same time strengthen the literacy of the humanities, so that they can comprehensively think about the problem from the perspective of users. "Looking at the scene from a technical point of view and looking at the technology from the perspective of the scene", Tang Wenbin believes that such talents can be met, and it is also indispensable for ignoring the talents within the technology that are "being strong, growing, and dependent". . According to AI Science and Technology Review, Vision Technology's current business focus is on personal IOT (mobile phone), public IOT (security, education) and commercial IOT (smart robot). Joining the contempt team will have the opportunity to get in touch with these. Field of business. Talking about the attraction of science and technology to talents, Tang Wenbin said that there will be three points: First, the business of defiance of technology can specifically generate social value, and in the process of concrete participation in the business, it will invisibly cultivate the sense of mission of the individual; Second, defiance of technology business has a certain threshold, not everyone has the ability to complete, for those who like the challenge will be able to get a great sense of accomplishment; third, the employees in the contempt are basically comprehensive People with strong quality and ability to work with the strong can learn a lot from each other. In the face of today's AI boom, many computer professional students want to join the AI ??industry, how to be eliminated in the high-speed development of the AI ??industry, he also has some suggestions for students. "First, we must be keen and confident in ourselves. Second, we must always adhere to self-learning. Defiance of technology will provide a very rich learning curriculum, and even regularly invite pilots from different fields to share internally. I hope that through these courses, Every contempt person continues to grow and climbs to a higher level to maintain his own industry competitiveness. Of course, self-driving is the key."