通过人工智能了解智慧城市下的智慧园区投放方案	随着科技发展，中国的城市建设也步入高速并进入转型，城市向着智慧化发展，由此催生了智慧园区的概念。所谓智慧园区指形成由人工智能、大数据、云计算等科技驱动的城市决策机制，并根据数据和实况，合理化、高效化、综合化调配数据和资源，从而达到最优运行效率的园区。在中国人工智能飞速发展的当下，智慧园区这个理念已经不是一个新鲜的概念，我们可以通过一些实际的案例来了解智慧园区的真正面貌，从而发现人工智能城市中的惊喜的一面。中国的人工智能技术发展到现在，架构已经越来越完善，而很多技术在许多应用领域内都已经投放成功，甚至已经出现了非常多成功的例子。智慧园区是在智慧城市的基础上面诞生出来的一个新的概念，所谓的智慧城市就是以数据为驱动力，整个城市的所有的决策机制，全部基础都是来源于数据。通过对数据进行分析和综合调配，从而对整个城市的公共资源进行规划和调动，这样做的目的是不断的提高整个城市运作的效率，促使资源的运用可以得到最优。而智慧园区其实也是在这一个概念上面延伸出来的，针对一个小空间范围的，一个办公场所，一个居住空间所设定的智慧空间方案。在这个方案当中，我们会接触到更加多的人工智能技术，比如无人驾驶，线上课堂，以及远程诊治等等，这些覆盖公共场合及公共措施的人工智能科技产品，都将会为进一步的实现智慧城市带来贡献。对于智慧园区，范围细分的同时，人工智能的项目针对投放领域也会更细致，比如针对办公区域性质的智慧园区，将会更多的投放人脸识别闸机，会议签到，速通门等等的人工智能产品，以满足智慧园区的日常运作需求。而针对居住区域的智慧园区，则可能更多的涉及到人脸识别技术方面的配置，比如陌生人报警系统，闸机等等，以确保园区生活的安全。所有的这些，都将进一步的改变智慧城市或者智慧园区的未来生活场景，而且也会进一步的影响到中国的人工智能产业的发展。相关专业人士认为，基于这一点，智慧城市及智慧园区的建立，通过人工智能的辅助，将会呈现出无限的创造力，同时，通过技术的适应能力，将会有更加多的创新的，高效的产品和技术落户，进一步的在实践当中证明人工智能智慧园区的可行性。
习近平：推动我国新一代人工智能健康发展	新华社北京10月31日电中共中央政治局10月31日下午就人工智能发展现状和趋势举行第九次集体学习。中共中央总书记习近平在主持学习时强调，人工智能是新一轮科技革命和产业变革的重要驱动力量，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。要深刻认识加快发展新一代人工智能的重大意义，加强领导，做好规划，明确任务，夯实基础，促进其同经济社会发展深度融合，推动我国新一代人工智能健康发展。北京大学教授、中国工程院院士高文就这个问题作了讲解，并谈了意见和建议。中共中央政治局各位同志认真听取了讲解，并就有关问题进行了讨论。习近平在主持学习时发表了讲话。他强调，人工智能是引领这一轮科技革命和产业变革的战略性技术，具有溢出带动性很强的“头雁”效应。在移动互联网、大数据、超级计算、传感网、脑科学等新理论新技术的驱动下，人工智能加速发展，呈现出深度学习、跨界融合、人机协同、群智开放、自主操控等新特征，正在对经济发展、社会进步、国际政治经济格局等方面产生重大而深远的影响。加快发展新一代人工智能是我们赢得全球科技竞争主动权的重要战略抓手，是推动我国科技跨越发展、产业优化升级、生产力整体跃升的重要战略资源。习近平指出，人工智能具有多学科综合、高度复杂的特征。我们必须加强研判，统筹谋划，协同创新，稳步推进，把增强原创能力作为重点，以关键核心技术为主攻方向，夯实新一代人工智能发展的基础。要加强基础理论研究，支持科学家勇闯人工智能科技前沿的“无人区”，努力在人工智能发展方向和理论、方法、工具、系统等方面取得变革性、颠覆性突破，确保我国在人工智能这个重要领域的理论研究走在前面、关键核心技术占领制高点。要主攻关键核心技术，以问题为导向，全面增强人工智能科技创新能力，加快建立新一代人工智能关键共性技术体系，在短板上抓紧布局，确保人工智能关键核心技术牢牢掌握在自己手里。要强化科技应用开发，紧紧围绕经济社会发展需求，充分发挥我国海量数据和巨大市场应用规模优势，坚持需求导向、市场倒逼的科技发展路径，积极培育人工智能创新产品和服务，推进人工智能技术产业化，形成科技创新和产业应用互相促进的良好发展局面。要加强人才队伍建设，以更大的决心、更有力的措施，打造多种形式的高层次人才培养平台，加强后备人才培养力度，为科技和产业发展提供更加充分的人才支撑。习近平强调，我国经济已由高速增长阶段转向高质量发展阶段，正处在转变发展方式、优化经济结构、转换增长动力的攻关期，迫切需要新一代人工智能等重大创新添薪续力。我们要深入把握新一代人工智能发展的特点，加强人工智能和产业发展融合，为高质量发展提供新动能。要围绕建设现代化经济体系，以供给侧结构性改革为主线，把握数字化、网络化、智能化融合发展契机，在质量变革、效率变革、动力变革中发挥人工智能作用，提高全要素生产率。要培育具有重大引领带动作用的人工智能企业和产业，构建数据驱动、人机协同、跨界融合、共创分享的智能经济形态。要发挥人工智能在产业升级、产品开发、服务创新等方面的技术优势，促进人工智能同一、二、三产业深度融合，以人工智能技术推动各产业变革，在中高端消费、创新引领、绿色低碳、共享经济、现代供应链、人力资本服务等领域培育新增长点、形成新动能。要推动智能化信息基础设施建设，提升传统基础设施智能化水平，形成适应智能经济、智能社会需要的基础设施体系。习近平指出，要加强人工智能同保障和改善民生的结合，从保障和改善民生、为人民创造美好生活的需要出发，推动人工智能在人们日常工作、学习、生活中的深度运用，创造更加智能的工作方式和生活方式。要抓住民生领域的突出矛盾和难点，加强人工智能在教育、医疗卫生、体育、住房、交通、助残养老、家政服务等领域的深度应用，创新智能服务体系。要加强人工智能同社会治理的结合，开发适用于政府服务和决策的人工智能系统，加强政务信息资源整合和公共需求精准预测，推进智慧城市建设，促进人工智能在公共安全领域的深度应用，加强生态领域人工智能运用，运用人工智能提高公共服务和社会治理水平。要加强人工智能发展的潜在风险研判和防范，维护人民利益和国家安全，确保人工智能安全、可靠、可控。要整合多学科力量，加强人工智能相关法律、伦理、社会问题研究，建立健全保障人工智能健康发展的法律法规、制度体系、伦理道德。各级领导干部要努力学习科技前沿知识，把握人工智能发展规律和特点，加强统筹协调，加大政策支持，形成工作合力。（完）CVPR  旷视科技Face++率先提出DocUNet 可复原扭曲的文档图像	全球计算机视觉顶会 CVPR 2018 （Conference on Computer Vision and Pattern Recognition，即IEEE国际计算机视觉与模式识别会议）将于6月18日至22日在美国盐湖城举行。作为大会钻石赞助商，旷视科技Face++研究院也将在孙剑博士的带领下重磅出席此次盛会。??论文链接：https://www3.cs.stonybrook.edu/~cvl/content/papers/2018/Ma_CVPR18.pdf导语由于移动摄像头数量剧增，随手拍照已成为一种对物理文档进行数字化记录的普遍方式，并可据此展开后续操作，比如文字识别。但是，由于物理文档时常存在扭曲或变形，以及光线条件差等情况，文字识别难以达到理想效果。针对这一问题，旷视科技Face++首次提出一种基于学习的堆叠式 U-Net，称之为 DocUNet，可以平整和复原扭曲变形的文档图像。DocUNet 填补了深度学习领域的一项技术空白。由于平整变形文档图像的有效和效率，DocUNet 可大幅降低文字识别的难度，优化 OCR 技术发展，进而推动真实、网络等不同场景下的文本识别和检索能力，从底层技术的维度为办公自动化、智慧零售、无人超市甚至是自动驾驶的革新添砖加瓦、铺平道路。设计思想文档数字化是保存现有打印文档的一种重要方式，可以随时随地访问。传统方法借助平板式扫描仪数字化文档，但是不易携带，成本高昂。最近，随着移动摄像头日益增多，拍摄物理文档成为最便捷的一种文档扫描方式。一旦拍摄，图像可由文本检测和识别技术进一步处理，实现内容分析和信息提取。拍摄文档图像常见的一个实际问题是文档页的扫描条件不理想：它们可能弯曲、折叠、弄皱，或者放在非常复杂的背景上。试想一张从钱包取出的褶皱收据。所有这些因素都可能为文档图像的自动分析流程带来严重问题，如图 1 所示。因此存在数字化平整拍摄图像中扭曲文档的需求。??图 1：文档图像的平整化及其用途。(a) 展示了本文工作的一些成果。上面是输入图像，下面是输出图像。(b) 本文网络显著提升了当前最优文本检测系统的效能：相较于上面的扭曲图像，下面的复原文档图像可以检测出更多单词（绿色）。文档图像的平整化不是一个新问题，已有多种解决方案。一些视觉系统依赖于精心设计和校准的硬件，比如立体摄像头，或者结构光投影仪以测量文档的 3D 扭曲；它们表现很好，但额外的硬件限制了其应用；其他工作吸取这一教训，通过多视角图像重建扭曲文档图像的 3D 形状。一些人则致力于通过各种低层的手工特征（比如明暗度，文本行等）分析单一图像而复原文档图像。本文给出一种基于学习的全新方法，来复原任意弯曲和折叠的文档拍摄图像。不同于先前方法，本文提出首个端到端学习方法，可以直接预测文档扭曲。先前方法只使用学习提取特征，而最后的图像复原仍基于传统的优化技术；本文方法则借助卷积神经网络（CNNs）端到端复原图像。相较于优化方法，前馈网络的测试表现非常抢眼。此外，如果具备合适的训练数据，这一数据驱动的方法还可以更好地泛化至其他文档类型（文本、数字、手写体等）。该方法把这一问题转化为寻找合适的 2D 映射，以复原失真图像文档。它预测一个映射域，把扭曲的源图像 S(u, v) ?中的像素移动到结果图像 D 中的 (x, y)?。由此本文发现该任务与语义分割有一些共性；对于后者而言，网络为每个像素分配一类标签。相似地，本文网络则为每个像素分配一个 2D 向量。这启发作者在网络结构中使用语义分割领域家喻户晓的 U-Net 解决本文的回归问题，并定义一个全新的损失函数以驱动网络为 S 中的每个像素回归 D 中的坐标 (x, y)。获取带有标签的海量数据是深度监督学习面临的首个挑战。为训练网络，作者需要扭曲程度不同的大量文档图像及相应的变形图像作为输入以实现完美复原。可惜目前这样的数据集不存在。获取真实的变形标签图像非常难，所以本文最后选择合成数据。通过随机扭曲平整的文档图像，本文合成了 100K 张图像，以便把扰动图像作为输入，而本文用来扭曲图像的网络则是旨在复原的逆变形。同样也没有评估文档平整化的可用公共基准。先前方法要么在少量图像上进行评估，要么数据集只包含若干个扭曲类型。作者创作了一个包含 130 张图像的基准填补了这一空白，在文档类型、扭曲程度及类型以及拍摄条件方面差异巨大。数据集本文方法基于 CNN，需要大量训练数据。在该任务中，文档变形可以表征为 3D 网格、曲面法线、2D 流动等，在现实世界中以任意形式精确地拍摄它非常困难，需要诸如深度摄像头（range camera）或者标定立体视觉系统等额外硬件，同时预估变形的精确度通常依赖于硬件成本。此外，通过手动扭曲/变形文档文件以涵盖全部实际情形是很不现实的。本文考虑使用合成数据进行训练，这在最近的深度学习中很常见，并允许完全掌控数据集的变化。一个直观的想法是在 3D 渲染文档中直接渲染扭曲的文档，但由于下述原因这是不切实际的。首先，通过物理模拟生成物理上正确的 3D 网格非常难且慢。第二，通过路径追踪渲染同样非常费时。渲染 100K 图像耗时将超过两月。--2D 扭曲图像合成本文直接合成 2D 训练图像。尽管已忽略基础的物理建模，但操纵 2D 网格相当简单，且生成图像也很快。由于本文目的是把扭曲纸张映射到复原纸张，因此数据合成是反向过程，即，把复原图像进行多种类型的扭曲。当创建扭曲图时，本文遵循以下实证原则：i）一张真实的纸张是局部刚性的，不会延展或压缩。一点上的扭曲将带来空间上的改变。ii）存在两类扭曲：折叠和弯曲，分别产生纸张的折痕和卷曲。实际情形通常是这两类扭曲的结合。本文首先搜集大量平整的数字文档，包括论文、书籍和杂志页面等；接着扭曲这些图像，如图 2 所示。??图 2：2D 合成扭曲文档图像。扰动网格生成：给定图像 I，本文在其上放置一个 m x n 网格 M 以为扭曲提供控制点。在 M 上选择一个随机顶点 p 作为初始变形点。变形的方向和强度标记为 v，且也随机生成。最后，基于 i），v 通过权重 w 传播至其他顶点。扭曲网格上的顶点被计算为 p_i + wv, ?i。扰动图像生成：扰动网格提供一个稀疏的变形域。本文以线性方式对其进行插值，以从像素层面构建密集的扭曲图，接着把扭曲图应用到原始图像以生成扰动图像。作者通过这种方式在单块 CPU 上合成了 100K 张图像。每张图像最多包含 19 种合成变形（30% 是弯曲，70% 是折叠）。弯曲需要保证高斯曲率在任意位置都应为 0，折叠则随意。样本如图 5 所示。??图 5：合成数据中的样本图像。DocUNet--网络架构类似于语义分割，本文自行设计网络以强化逐像素的监督。出于其在语义分割任务上的简洁性和有效性，本文选择 U-Net 作为基础模型，它基本上是一个全卷积网络，包含一系列的下采样层和随后的上采样层，特征映射在上、下采样层之间连接。但是，单一 U-Net 的输出并不令人满意，应该进行优化，因此在第一个 U-Net 的输出上堆叠另外一个 U-Net 作为 refiner。如图 3 所示。??图 3：网络架构。该网络由两个 U-Net 堆叠而成。该网络从第一个 U-Net 的输出中分割和输出一个前向映射 y_1。应用在 y_2 的同一损失也应用在 y_1。接着 y_1 连接到第一个 U-Net 的输出特征映射，并作为第二个U-Net 的输入。y_2 可直接用于生成复原图像。本文有一个层负责把去卷积特征转化为最后的输出 (x, y)。第一个 U-Net 在最后一个去卷积层之后分叉为两支。把第一个 U-Net 的去卷积特征和中间预测 ?y_1 ?连接起来作为第二个 U-Net 的输入。第二个 U-Net 最后给出一个优化的预测 y_2 ，作者将其用作网络的最后输出。本文在训练时把同一损失函数应用于 y_1 和 y_2。但是在测试时，只把 y_2 用作网络的输出。不同于语义分割本质上是一个像素分类问题，该网络输出（为映射 F）的计算是一个回归的过程。语音分割的输出通常有 C 个通道，其中 C 是语义类别的数量。该网络只为 (x, y) 坐标输出 2 个通道。--损失函数损失函数包含两个部分：1. 输出的映射 y 和其对应的 groundtruth 映射 y^star 之间的绝对误差（element-wise loss）。2. 输出的不同点的映射的相对位置 y_1 - y_2 和它们对应的 groundtruth 映射相对位置 y_1^star - y_2^star 之间的相对误差（shift invarient loss）。其中绝对误差本文表示为：??相对误差表示为：??假设 d_i = y_i - y_i^star，Eq. 5?可表示为：??本文同时发现 L1 （Eq. 7）优于 L2（Eq. 6），因此损失函数可重写为：??F 中与 S 的背景像素相对应的元素是常数 -1，因此 ?Eq. 7 中的部分损失来自背景。实际上网络没有必要把这些元素精确回归到 -1。任意负值都应该足够。因此本文把 hinge loss 用于背景像素：??同时 Eq. 7 只用于前景像素。实验本文首先介绍评估单一图像上扭曲文档复原的基准；接着评估本文提出的基于学习的方法，并与先前非学习方法的结果作对比。--基准图像：基准之中的图像是手机拍摄的物理纸张文档的图像。搜集 65 个各种内容/形式的纸张文档，其中每个文档拍照两张，共有 130 张图像。基准包含原始图像和剪裁框正的图像（document centered cropped images?），实验使用后者，因为本文的重点是平整化纸张而不是定位图像中的文档。基准的创建基于以下考量：i）文档类型：选择的文档类型各不相同，有收据、信件、文件、杂志、论文、书籍等；ii）扭曲：原始的平整纸张文档由不同的人进行物理扭曲；iii）环境：图像由两个人用两部不同的手机在室内、室外不同的光照条件下拍摄。Groundtruth：在折叠已选择的纸张文档之前，通过平板式扫描仪对其扫描。调整已获取图像的大小和整体颜色以尽可能地匹配原始的平整文档。图 6 是基准中的一些实例。??图 6：基准样本。--结果基准评估表明该方法优于先前的 Tian et al. [27]。具体而言，该方法的成绩在 MS-SSIM?和 LD?分别是 0.41 和 14.08，相比之下，[27] 的成绩分别为 0.13 和 33.69。这是因为 [27] ?主要针对文本行文档而设计，严重依赖于文本行追踪的质量，因此无法处理更为复杂的文档，比如混合文本行和数字，或者文本行追踪失败的区域，如图 10 所示。??图 10：对比Tian et al. [27]。在计算效率方面，[27] 借助 Matlab 实现在 1 块 CPU 处理 1 张图像耗时 3 到 4 分钟。相比之下，本文网络在 GTX 1080 Ti GPU?上的运行速度是 28 fps，虽然这种对比有点不公平。瓶颈在于从映射中生成复原图像。本文未优化的 Matlab 实现在 CPU 上大约耗时 3 到 4 秒。整体上该方法快 [27] 一个数量级，如下表所示：??更多对比结果请见图 8 和 图 9：??图 8：对比 You et al. [36]。尽管 [36] 使用 5 到 10 张图像，本文方法依然相当有竞争力。??图 9：对比 Das et al. [6]。[6] 的方法专门针对折叠两次的文档而设计。这种情况下本文方法同样表现良好。上图中的实例图像来自 [6]。结论本文展现了首个平整和复原扭曲文档图像的端到端神经网络。作者提出一个带有中间监督的堆叠式 U-Net，并对它进行端到端训练以直接预测可以移除图像扭曲的映射。作者还创建了合成训练数据，以及一个包含在各种条件下拍摄的真实图像的基准。实验结果证实了该方法的有效和效率。在未来工作中，作者将应用 GAN 把这一网络更好地泛化至实际图像上，并希望加入亮度模型以移除复原图像上的高光或阴影。另一方面，作者还会优化从映射中生成复原图像的代码，并在移动端实现整个流程的实时部署。参考文献[6]?S. Das, G. Mishra, A. Sudharshana, and R. Shilkrot. The Common Fold: Utilizing the Four-Fold to Dewarp Printed Documents from a Single Image. In Proceedings of the 2017 ACM Symposium on Document Engineering, DocEng ’17, pages 125C128. ACM, 2017.[7] D. Eigen, C. Puhrsch, and R. Fergus. Depth map prediction from a single image using a multi-scale deep network. In Advances in Neural Information Processing Systems, 2014.[21] G. Meng, Y. Wang, S. Qu, S. Xiang, and C. Pan. Active flattening of curved document images via two structured beams. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2014.[25] O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation. In Proceedings of the International Conference on Medical Image Computing and Computer Assisted Intervention. Springer, 2015.[27]?Y. Tian and S. G. Narasimhan. Rectification and 3D recon- struction of curved document images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2011.?[28] Y.-C. Tsoi and M. S. Brown. Multi-view document rectification using boundary. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2007.[36]?S.You,Y.Matsushita,S.Sinha,Y.Bou,andK.Ikeuchi.Multiview Rectification of Folded Documents. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017.
2018/11/1	CVPR 2018 | 旷视科技物体检测冠军论文――大型 mini-batch 检测器MegDet	全球计算机视觉顶会 CVPR 2018 （Conference on Computer Vision and Pattern Recognition，即IEEE国际计算机视觉与模式识别会议）将于6月18日至22日在美国盐湖城举行。作为大会钻石赞助商，旷视科技研究院也将在孙剑博士的带领下重磅出席此次盛会。??论文链接：https://arxiv.org/abs/1711.07240导语深度学习时代，计算机视觉领域的基石之一物体检测技术获得一次飞跃式发展，新模型新方法不断涌现。本文从 mini-batch 角度为加速深度神经网络的训练提供了一种新型检测 MegDet，通过把 mini-batch 扩大至 256，从而可以充分利用 128 块 GPU 并大大缩短了训练时间。从技术上讲，warmup 学习率策略和 Cross-GPU 批归一化（CGBN）共同保证了大型 mini-batch 检测器 MegDet 的成功训练，并且时间更短(从 33 小时缩至 4 小时)精度更高。这意味着 MegDet 从精度和速度两个核心维度优化了物体检测技术，为该技术的落地及其他计算机视觉的应用甚至安防、新零售和无人驾驶等领域的发展进一步铺平了道路。设计思想R-CNN?之后，Fast/Faster R-CNN，Mask R-CNN， RetinaNet 等一系列新模型层出不穷，这些基于 CNN?的方法在物体检测领域进展巨大，仅仅两年内，COCO AP 由 19.7（Fast R-CNN）拔升至 39.1（RetinaNet），上述进步的背后，是更优的基础网络，更好的检测架构，更佳的 loss design 以及不断改进的池化方法。CNN 图像分类模型的一个新近趋势是通过大型 mini-batch 大幅缩减训练时间。比如，通过大小分别为 8192 或 16000 的 mini-batch，ResNet-50?可以 1 小时或 31 分钟完成训练，同时精度几乎不掉点。相反，CNN 图像检测模型的 mini-batch 普遍很小，比如 2-16，而一般分类模型的 mini-batch 大小通常为 256。针对这一问题，本文给出一个技术方案，使得大型 mini-batch 同样适用于检测模型。小型 mini-batch 有何问题？简单说，有三点：首先，训练极其费时；其次，通过小型 mini-batch 训练无法精确统计批归一化（BN）；最后，小型 mini-batch 中正、负实例的数量更易失衡。??图 2：带有正负 proposal 的实例图像。(a-b) 两个实例的比率不平衡；(c-d)两个实例比率平衡且中等。如果简单地增大 mini-batch，又会面临哪些挑战？正如图像分类问题一样，主要困难在于大型 mini-batch 通常需要配置高学习率以保持精度。但是在物体检测中，高学习率很可能导致模型无法收敛；如果使用较低的学习率，获得的结果通常又较差。为解决上述问题，本文提出了名为 MegDet 的解决方案：首先，作者提出线形缩放的一种新解释，并在早期阶段借助“warmup”学习率策略逐渐提高学习率；接着，为解决精度和收敛问题，作者引入多 GPU 批归一化（Cross-GPU Batch Normalization/CGBN）以更好地统计 BN。CGBN 不仅会涨点精度，还会使训练更加稳定，从而可以安全无虑地享用业界强大的算力加持，这很有意义。??图 1：当 mini-batch 大小分别为 16（8 GPUs）和 256（128 GPUs）时，COCO 数据集上训练的同一 FPN 物体检测器的验证集精度。大型 mini-batch 检测器更为精确，训练速度也快了近一个数量级。MegDet 通过 128 块 GPU 可在 4 小时内完成 COCO 训练，甚至精度更高；相比之下，小型 mini-batch 需要 33 小时完成训练，并且精度更低。这意味着可以把创新周期几乎缩短一个数量级，甚至性能更优。基于 MegDet，旷视夺得 ?COCO 2017 物体检测挑战赛第一名。方法MegDet 作为一个大型 mini-batch 检测器既可以更短时间完成训练，又可实现精度涨点，本节将介绍其方法原理。由于小型 mini-batch 存在若干问题，而简单增大 mini-batch 必须处理精度与收敛之间的权衡，为此作者引入了针对大型 mini-batch 的学习率策略（warmup）。虽然这在一定程度上优化了收敛，但是对于较大的 mini-batch 比如 128 或者 256 来说，依然有所欠缺。接着作者引入 CGBN，它是大型 mini-batch 训练的关键所在。CGBN批归一化是一项训练深度卷积神经网络的重要技术，本文试图将其应用于物体检测。值得一提的是，分类网络的输入图像通常是 224 × 224 或者 299 × 299，一块内存 12G 的 NVIDIA TITAN Xp GPU?足以处理 32 张以上这样的图片。由此，可在每个设备上单独计算 BN。但是对于物体检测来说，检测器需要处理不同尺寸的物体，因此需要输入较高分辨率的图像，并在多块 GPU 执行批归一化以从更多样本中搜集足够的统计信息。跨 GPU 执行批归一化需要计算所有设备的汇总均值/方差统计信息。绝大多数现有深度学习框架使用 cuDNN?中的 BN 实现，但是只提供高级 API 而无法修改内部统计信息。因此需要初级数学表达式来执行 BN，并通过 AllReduce?操作汇总统计信息。这些细粒度表达式通常显著增加运行时间的开销，而 AllReduce 操作在大多数框架中是缺失的。CGBN 实现如图 3 所示：??图 3：CGBN 实现。椭圆表示设备之间的同步，圆角框表示多个设备的并行计算。实验这次实验使用的数据集是 COCO Detection，它分为训练集，验证集和测试集，涵盖 80 个类别和超过 250000 张图像。Backbone 是在 ImageNet 上完成预训练的 ResNet-50；检测框架是特征金字塔网络（FPN）。训练集图像数量超过 118000 张，验证集为 5000 张图像，SGD optimizer momentum 为 0.9，weight decay 为 0.0001，mini-batch 16 的基础学习率是 0.02。实验的主要结果如表 3 所示：?图 4：16-batch 和 256-batch 的验证集精度，使用长期训练策略。两个检测器的 BN 大小相同。垂直的虚线表示学习率衰减的时刻。第三，如表 3 最后一部分所示，本文调查了长期训练策略。较长的训练时间会带来精度的轻微涨点。最后，如图 4 所示，256-batch 在早期阶段的 epochs 中表现欠佳，但是在最后阶段反超了 16-batch（第二次学习率衰减之后）。这一情况大不同于图像分类，其中精度曲线和收敛分值在不同大小的 mini-batch 设置中非常接近。结论本文提出了一种大型 mini-batch 检测器 MegDet，可在更短时间内实现更高精度。这项工作意义重大，极大地缩短了研究周期。借助 MegDet，旷视科技摘取了 COCO 2017 检测挑战赛的桂冠，一些细节如下：????图 5：MegDet 在 COCO 数据集上的示例。??表 4：（增强的）MegDet 在 COCO test-dev 上的结果。本文的技术贡献主要有 4 个方面：-基于保持相等损失方差的假设，本文在物体检测的语境中为线性缩放规则提出一种新解释。-本文实现首次在物体检测框架中训练 BN；实验证明 CGBN 不仅有助于精度的涨点，还会使训练更易收敛，尤其是对于大型 mini-batch 来讲。-本文首次（基于 ResNet-50）使用 128 块 GPU 在 4 小时内完成 COCO 训练，并实现更高精度。-MegDet 作为 backbone 在 COCO 2017 物体检测夺冠中发挥了关键作用。参考文献R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich fea- ture hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 580C587, 2014.P. Goyal, P. Dolla ?r, R. Girshick, P. Noordhuis, L. Wesolowski, A. Kyrola, A. Tulloch, Y. Jia, and K. He. Accurate, large minibatch SGD: Training ImageNet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.A. Krizhevsky. One weird trick for parallelizing convolutional neural networks. arXiv preprint arXiv:1404.5997, 2014.K. He, G. Gkioxari, P. Dollar, and R. Girshick. Mask R-CNN. In The IEEE International Conference on Computer Vision (ICCV), Oct 2017.T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollar. Focal loss for dense object detection. In The IEEE International Conference on Computer Vision (ICCV), Oct 2017.
2018/11/1	CVPR 2018 | 旷视科技Face++新方法――通过角点定位和区域分割检测场景文本	全球计算机视觉顶会 CVPR 2018 （Conference on Computer Vision and Pattern Recognition，即IEEE国际计算机视觉与模式识别会议）将于6月18日至22日在美国盐湖城举行。作为大会钻石赞助商，旷视科技Face++研究院也将在孙剑博士的带领下重磅出席此次盛会。??论文链接：https://arxiv.org/abs/1802.08948导语在机器之眼的检测矩阵中，自然场景文本是一类不可避及的重要对象，且有外景、视频、网页、字幕、截图等多种表现形式。旷视科技Face++通过吸取物体检测与语义分割的各自优势，并作创新性整合，突破性地提出了一种新型文本检测器，把检测精度推进到全新高度。这种底层检测技术迭代升级的影响是普适性的，意味着绝大多数与文本识别相关的实际应用都可得到不同程度的优化和完善，促进文本检测技术在直播、电商、论坛等 UGC 型内容平台网站，或者弹幕、评论、群聊、昵称等视频网站与社交 APP 中的应用；进一步提升产品和图像中关于文本的搜索检索能力，促进智能零售、无人超市等产业的发展和普及，甚至是促进自动驾驶技术的进步。由此可见，旷视科技推出的新型文本检测技术不仅有助于帮助客户走出海量数据的困境，制定个性化策略，高效过滤多类垃圾文字及敏感词，消除文本隐患，进而营造智能、安全、文明的社会环境，还可以推动新零售、无人超市、自动驾驶的进步发展。设计思想最近，由于实际应用需求不断增长，从现实场景图像中提取文本信息变得日益流行。场景文本检测――一种自然图像文本的定位技术――在各种文本阅读系统中发挥着不可或缺的作用。由于内外两种因素，场景文本检测挑战重重。外部因素是指噪音、模糊、遮挡等外在环境，它们同样是困扰一般物体检测的主要根源。内部因素来自场景文本的属性。相较于一般物体检测，场景文本检测更为复杂，因为：1）自然场景中文本可以是任意方向的，因此需要检测的边界框通常为旋转的矩形或四边形；2）场景文本边界框的长宽比变化很大，且通常会存在极端的长宽比；3）场景文本的粒度多样，有字符、单词或者文本行等多种形式，算法在定位边界框时会难以判定文本实例。?图 1：上行和下行自左至右依次是已预测的左上、右上、右下、左下角点和位置敏感图。过去几年中，场景文本检测获得大量研究，加之一般物体检测和语义分割的推动，场景文本检测近期成果显著，演化出两类主流的检测器。第一类基于一般物体检测器 SSD、YOLO、DenseBox，可以直接预测候选边界框；第二类基于语义分割，可以生成分割图，通过后处理给出最终的文本框。本文结合了上述两类方法的思想，并加以创新，其提出主要基于下面两个发现：1）我们可以通过矩形的角点（corner point，左上，右上，右下，左下，如图 1 所示）来确定一个矩形，而不用考虑其大小、长宽比或者方向；2）文本区域分割图可以提供有效的文本定位信息，位置敏感（position-sensitive）的文本区域分割图（图 1）可以提供有效的文本实例信息。因此，本文首先直接检测文本的角点而不是回归文本框。另外，本文预测位置敏感的的分割图而不是文本/非文本图。最后，本文通过采样和组合已检测的角点生成候选边界框，并根据分割信息消除不合理的边界框。本文提出方法的 pipeline 如图 2 所示。?图 2：本文方法概览。给定一张图像，网络借助角点检测和位置敏感的分割输出角点和分割图；然后通过采样和组合角点生成候选框；最后，这些候选框通过分割图进行评分，并由 NMS 抑制冗余的候选框。本文方法的主要亮点有：1）由于通过采样和组合角点的方式来检测场景文本，该方法可以处理任意方向的文本；2）由于检测角点而不是文本边界框，该方法可以自然而然地避免长宽比大幅变化的问题；3）通过位置敏感的分割，该方法可以很好地分割文本实例，而不管其是字符、单词或者文本行；4）在该方法中，候选框的边界由角点决定。相较于基于 anchor 或者文本区域回归文本边界框，该方法生成的边界框更精确，特别是对于长文本。这一方法的有效性在水平文本、多方向文本、多方向长文本以及多语种文本的公开数据集上得到验证，结果证明了它在精度和速度上的优势。尤其是，该方法的 F-Measures?在 ICDAR2015、MSRA-TD500 和 MLT?上分别是 84.3%、81.5% 和 72.4%，显著优于先前最佳方法。另外，该方法在效率方面同样具有竞争优势，在输入图片大小为 512x512 情况下，每秒可处理超过 10.4 张图像。网络架构本文方法是一个全卷积网络，可实现特征提取、角点检测和位置敏感的文本区域分割，其网络架构如图 3 所示。给定一张图像，则网络给出候选角点和分割图。??图 3：该网络包含 3 部分：Backbone、角点检测器和位置敏感分割检测器。Backbone 沿用DSSD。角点检测器构建在多个特征层（粉色模块）之上。位置敏感分割检测器与角点检测器共享粉色模块。--特征提取该模型的 backbone 改编自预训练的 VGG16 网络，并基于下述考量进行设计：1）场景文本的大小变化巨大，因此 backbone 必须足以应对该问题；2）自然场景中的背景非常复杂，因此特征最好包含较多的语境。鉴于 FPN/DSSD 结构在上述问题上的良好表现，本文通过 FPN/DSSD backbone 提取特征。--角点检测本文使用一个正方形框来表示一个角点，并用 default box 来回归角点。其中，框的中心点为角点位置，框的边长为角点所属的文本框的最短边。与 SSD/DSSD 每个 default box 输出一种相应候选框的分类分值和偏移量（offset）不同，角点检测更为复杂。因为同一位置可以存在多个的角点，因此本文中 default box 对应的输出分别为 4 类角点的 4 个候选框的分类分值和偏移量。本文以卷积的方式通过预测模块预测两个分支的分值和偏移量。对于每个单元中带有 k 个 default box 的 m × n?特征图，“分值”分支和“偏移量”分支分别为每个 default box 的每个类型的角点输出 2 个分值和 4 个偏移量。这里，在“分值”分支中 2 表示该位置是否有角点存在。总体上，“分数”分支和“偏移量”分支的输出通道是 k×q×2 和 k×q×4，其中 q 表示角点类型。 q 默认等于 4。训练阶段则遵从 SSD 中 default box 和 groundtruth 的匹配策略。为检测不同大小的场景文本，本文在多个层特征上使用不同大小的 default box。--位置敏感分割先前基于分割的文本检测方法通过生成分割图表征每个像素属于文本区域的概率。但是由于文本区域的重叠和文本像素的不当预测，分值图中的文本区域经常无法彼此分离。为从分割图中获得文本边界框，需要进行复杂的后处理。受到 InstanceFCN?启发，本文使用位置敏感分割生成文本分割图。相较于先前的文本分割方法，相对位置信息被引入。具体而言，通过一个 g x g 规则网格把文本边界框 R 分成多个 bin。对于每个 bin 来说，可使用一个分割图决定该图的像素是否属于该 bin。如图 4 所示，借助位置敏感的分割图， 本文可以有效地处理相近或相互重叠的文本区域。本文在统一网络中构建位置敏感分割，利用特征 F3 , F4 , F7 , F8 , F9 等预测 g x g 张文本区域分割 map。默认 g 为 2。?图 4：位置敏感的区域分割能提供实例信息，有效地过滤掉虚警。（a）输入图像；（b）已预测文本 proposal 和分割图。（c）评分。红框分别是对应于单词（有效）、相近单词和相互覆盖的单词（无效）的文本 proposal。文本框 proposal 的评分由旋转的位置敏感 ROI 平均池化层（算法1）计算。训练与推理对于输入训练样本，本文首先把 groundtruth 中的每个文本框（任意四边形）转化为一个能覆盖这个文本框且面积最小的矩形，并确定 4 个角点的相对位置。转化后的矩形相对位置应遵循以下原则：1）左上、左下角点的 x 轴必须分别小于右上、右下角点的 x 轴；2）左上、右上角点的 y 轴必须分别小于左下、右下角点的 y 轴。基于角点的相对位置，本文可以生成角点和位置敏感的分割的 groundtruth，如图 5。?图 5：为角点检测和位置敏感分割生成标签。 (a) 重新定义角点并用正方形表示（白色，红色，绿色，蓝色框），边长设置为文本边界框 R（黄框）的短边。 (b) ?(a) 中对应于位置敏感分割的 R 的 groundtruth。在推理阶段，会产生很多包含预测位置、短边长度和置信度信息的角点。高分值角点（默认值大于0.5）被保留。NMS 之后，根据相对位置信息组成 4 个角点集。采样和分组角点之后会产生大量的候选边界框。本文使用位置敏感的区域分割对候选文本框打分。处理过程如图 6 所示。图 6：评分过程概览。 (a) 中的黄框是候选框。(b) 是已预测分割图。本文通过集合分割图生成候选框的实例分段(c)。分值通过平均实例分段区域来计算。为处理旋转的文本边界框，本文提出旋转的位置敏感 ROI 平均池化层。具体地，对于一个旋转的边界框，本文首先把框分成 g x g 个 bin，对于每一个 bin，计算其对应预图 bin区域内所有像素的均值，最后对所有 bin 的均值求平均。具体过程如算法 1 所示。??算法 1：旋转的位置敏感 ROI 平均池化层。低评分的候选框将被过滤掉。本文默认阈值为 0.6。实验结果为验证本文方法的有效性，作者在 5 个数据集上开展实验：ICDAR2015，ICDAR2013，MSRA-TD500，MLT，COCO-Text，分别检测了多方向文本，水平文本，多方向长文本，多语种文本以及泛化能力。--多方向文本本文在 ICDAR2015 数据上测试了该模型在任意方向文本检测上的性能，并与其他当前最优方法进行对比，所有结果如表 2 所示。该方法大幅超越先前方法。当在单尺度上测试时，该方法的 F-measure?为 80.7%，优于其他所有方法；当在多尺度上测试时，该方法的 F-measure?为 84.3%，优于当前最佳方法 3.3%。??表 2：ICDAR2015 结果。? 表示多尺度，? 表示模型的基础网络不是 VGG16。--水平文本本文在 ICDAR2013 数据上测试了该模型在水平文本检测上的性能，结果如表 3 所示。当在单尺度上测试时，该方法的 F-measure?为 85.8%，略低于最高值。另外，该方法每秒可处理 10.4 张图像，快于绝大多数方法。当在多尺度上测试时，该方法的 F-measure?为 88.0%，同样很有竞争优势。??表 3：ICDAR2013 结果。? 表示多尺度，? 表示模型的基础网络不是 VGG16。注意，前三行的方法是在 “ICDAR2013” 评估协议下进行的。--多方向长文本本文在 MSRA-TD500 数据上测试了该模型在多方向长文本检测上的性能，结果如表 4 所示，其性能大幅优于先前所有方法。该方法在召回率、精确度和 F-measure 上同时取得当前最佳性能（87.6%，76.2% 和 81.5%?），并显著优于先前最佳结果（81.5% vs. 77.0%?）。这说明该方法较于其他方法更擅长检测任意方向的长文本。??表 4：MSRA-TD500 结果。? 表示模型的基础网络不是 VGG16。--多语种文本本文在 MLT 数据上测试了该模型在多语种文本检测上的性能。如表 5 所示，该方法超越其他方法至少 3.1%。??表 5：MLT 结果。? 表示多尺度。--泛化能力为评估该模型的泛化能力，本文使用在 ICDAR2015 数据集上训练得到的模型在 COCO-Text 数据集上进行测试，结果如表 6 所示。无需训练，该方法在COCO-Text 数据集上的 F-measure 为 42.5%，优于其他方法。??表 6：COCO-Text 结果。? 表示多尺度。结论本文提出一种场景文本检测器，它可以通过角点检测和位置敏感分割定位文本。作者在若干个专门的多方向文本，水平文本，多方向长文本，多语种文本公共基准上评估了该检测器，其优越的性能证实了该方法的有效性和鲁棒性。该方法的贡献有如下 4 个方面：1）提出一种结合物体检测和分割思想的新型场景文本检测器，可以实现端到端的训练与评估；2）基于位置敏感的 ROI 池化，提出一种位置敏感的旋转 ROI 平均池化层，可以处理任意方向的 proposals；3）该方法可同时应对多种困扰先前多方向文本检测方法的难点，比如旋转、长宽比变化、非常接近的文本实例等；4）该方法在精度和效率方面同样取得了更优或更具竞争力的结果。未来，作者将会基于该方法构建一个端到端的 OCR 系统。参考文献[1] Zhou et al. EAST: An Efficient and Accurate Scene Text Detector. CVPR2017[2] Fu et al .DSSD : Deconvolutional single shot detector. ?Arxiv[3] Tychsen-Smith et al. ?Denet: Scalable realtime object detection with directed sparse sampling. ?ICCV2017[4] Wang et al. Point linking network for object detection. Arxiv[5] Dai et al. Instance-sensitive fully convolutional networks. ECCV2016[6] Li et al. Fully convolutional instance-aware semantic segmentation.?CVPR2017
2018/11/1	新闻联播8分钟！习总书记强调AI有“头雁”效应，要勇闯无人区！	去年，国家出台《新一代人工智能发展规划》，首次将人工智能上升为国家战略，人工智能作为新一轮产业变革的核心驱动力，不断释放历次科技革命和产业变革积蓄的巨大能量。昨天（10月31日），新闻联播以接近8分钟的视频报道了国家领导人集体学习，主要关注人工智能发展现状和趋势。在会上，北京大学教授、中国工程院院士高文作相关讲解，并谈了意见和建议。本文分三部分：1、这次集体学习的主要内容。2、高文院士此前有关中国人工智能的观点和见解。3、国家各个层面推出的促进人工智能发展的政策。AI有“头雁”效应，支持科学家勇闯“无人区”据新华社报道，这次集体学习是在今天下午举行，主要就人工智能发展现状和趋势举行的第九次集体学习。人工智能是引领这一轮科技革命和产业变革的战略性技术，具有溢出带动性很强的“头雁”效应。在移动互联网、大数据、超级计算、传感网、脑科学等新理论新技术的驱动下，作为“头雁”的人工智能加速发展，呈现出深度学习、跨界融合、人机协同、群智开放、自主操控等新特征，正在对经济发展、社会进步、国际政治经济格局等方面产生重大而深远的影响。因此，作为新一轮科技革命和产业变革的重要驱动力量，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。战略之下，需要把增强原创能力作为重点，以关键核心技术为主攻方向，夯实新一代人工智能发展的基础。有以下几点需要加强：加强基础理论研究，支持科学家勇闯人工智能科技前沿的“无人区”，努力在人工智能发展方向和理论、方法、工具、系统等方面取得变革性、颠覆性突破，确保我国在人工智能这个重要领域的理论研究走在前面、关键核心技术占领制高点。主攻关键核心技术，以问题为导向，全面增强人工智能科技创新能力，加快建立新一代人工智能关键共性技术体系，在短板上抓紧布局，确保人工智能关键核心技术牢牢掌握在自己手里。强化科技应用开发，紧紧围绕经济社会发展需求，充分发挥我国海量数据和巨大市场应用规模优势，坚持需求导向、市场倒逼的科技发展路径，积极培育人工智能创新产品和服务，推进人工智能技术产业化，形成科技创新和产业应用互相促进的良好发展局面。加强人才队伍建设，以更大的决心、更有力的措施，打造多种形式的高层次人才培养平台，加强后备人才培养力度，为科技和产业发展提供更加充分的人才支撑。高文院士曾指出AI的五个新端倪，希望机器学习新算法出现进步这次参与国家领导人集体学习讲解的高文院士是北京大学教授、博士生导师、IEEE Fellow、中国工程院院士，日本东京大学博士。北大数字媒体研究所所长，数字视频编解码技术国家工程实验室主任，北大信息工程学院数字媒体中心主任。据中国科技网报道，高文院士曾在2018年第二十六届媒体融合技术研讨会（ICTC2018）上，强调了当前人工智能展现出的五个新端倪：端倪一：大数据上的深度学习+自我锻炼的综合进化技术端倪二：基于网络的群体智能已经萌芽端倪三：人机一体化技术导向混合智能端倪四：跨媒体推理已经兴起端倪五：无人系统迅速发展人工智能的发展到现在三起两落，本身是一个螺旋式的发展，未来将在包括计算机科学、电子学、自动化等方面进行轮番的演练。高文院士指出，中国下一代的人工智能在机器学习的新算法上面已具备了更多的布局，希望在机器学习新算法方法有更多的进步。总理仔细看最高水平芯片，主席书架上有AI书籍高层领导人对AI发展非常重视，也多次学习。不久前，总理参观比利时微电子研究中心（IMEC），详细了解高精度纳米芯片的投产时限、能效和在民生领域应用等情况，问得十分仔细。IMEC中心通过精密光刻技术不断缩短芯片上电路与电路之间的距离，提高通信效率和运算速度，目前已经生产出3纳米的芯片，是迄今为止世界最高水平。据人民日报报道，当时总理“摘下眼镜，对一张黑胶唱片大小的芯片近距离端详了许久，问了四五个问题。”这张照片让不少网友“扎心”。另据人民日报消息，本月26日，十三届全国人大常委会第六次会议在北京人民大会堂闭幕，闭幕会后，十三届全国人大常委会举行第七讲专题讲座。中国科学院院士谭铁牛作了题为《人工智能的创新发展与社会影响》的讲座。谭铁牛曾在多个场合详细介绍过人工智能的发展现状，他曾指出，“智能＋X”应用范式日趋成熟，AI向各行各业快速渗透融合进而重塑整个社会发展，这是人工智能驱动第四次技术革命的最主要表现方式。而在今年的新年致辞中，细心的电视观众发现国家主席的书架上不仅放着社会主义经典著作，还放着人工智能书籍，其中就有著名机器学习专家Pedro Domingos的《终极算法》和Brett Kingde 《智能浪潮》。Domingos认为，AI技术中所有学习问题的答案是一个终极“主”算法，这个算法可以给AI系统提供反馈，让系统一直进化。比尔・盖茨将这本书推荐为必读AI书籍。Domingos表示，中国在AI竞赛中有优势是因为它拥有大量的数据，而驱动机器学习发展的正是数据。在《智能浪潮》一书中，作者举出了大量的案例和丰富的图片向我们展示了一个智能的未来，研究机器人将如何取代人类工作，以及人工智能是否会将我们归为低能。人工智能上升为国家战略，国家出台多个AI相关政策近年来，我国不断出台人工智能相关政策，大力促进人工智能技术和产业的发展。去年“两会”，人工智能首次出 现在《政府工作报告》。李克强总理在《政府工作报告》 中提到：“一方面要加快培育新材料、人工智能、 集成电路、生物制药、第五代移动通信等新兴产业，另一方面要应用大数据、云计算、物联网等技术加快 改造提升传统产业，把发展智能制造作为主攻方向。”去年7月，国家正式出台《新一代人工智能发展规划》，首次将人工智能上升为国家战略。《规划》指出，人工智能作为新一轮产业变革的核心驱动力，将进一步释放历次科技革命和产业变革积蓄的巨大能量，并创造新的强大引擎，重构生产、分配、交换、消费等经济活动各环节，形成从宏观到微观各领域的智能化新需求，催生新技术、新产品、新产业、新业态、新模式，引发经济结构重大变革，深刻改变人类生产生活方式和思维模式，实现社会生产力的整体跃升。去年一年，国家层面出台数个人工智能相关政策。今年“两会”政府工作报告中，总理再次指出，加强新一代人工智能研发应用，在医疗、养老、教育、文化、体育等多领域推进“互联网+”。发展智能产业，拓展智能生活。现在，作为国家战略的人工智能正在作为基础设施，逐渐与产业融合，加速经济结构优化升级，对人们的生产和生活方式产生深远的影响。
CVPR 2018 | 旷视科技Face++提出用于语义分割的判别特征网络DFN	全球计算机视觉顶会 CVPR 2018 （Conference on Computer Vision and Pattern Recognition，即IEEE国际计算机视觉与模式识别会议）将于6月18日至22日在美国盐湖城举行。作为大会钻石赞助商，旷视科技Face++研究院也将在孙剑博士的带领下重磅出席此次盛会。?论文链接：https://arxiv.org/abs/1804.09337导语在大量的计算机视觉应用中，语义分割是一项不可或缺的底层技术。旷视科技Face++近期发表的一篇 CVPR 2018 收录论文《Learning a Discriminative Feature Network for Semantic Segmentation?》提出判别特征网络 DFN，有效解决了语义分割的两个基本问题，显著提高了其精度，可以帮助机器之眼更好地理解复杂的图像和场景，解析静态或动态人体及其他物体，有助于从根本上推动自动驾驶、手机影像、医疗影像、无人零售、物流安防等 AI 驱动型产业的普及与发展。设计思想本文提出的判别特征网络（Discriminative Feature Network/DFN）包含两个子网络 Smooth Network 和 Border Network，它有效解决了绝大多数现有语义分割方法面临的类内不一致（intra-class inconsistency）与类间无差别（inter-class indistinction）问题。具体而言，为应对类内不一致问题，作者专门设计带有通道注意力模块（Channel Attention Block/CAB）和全局平均池化的 Smooth Network 以选择更具判别力的特征；而 Border Network 则借助多层语义边界监督区分边界两边的特征。伴随着以全卷积网络（Fully Convolutional Network/FCN）为代表的卷积神经网络的新近发展，很多工作成效显著。但是，上述网络学习的特征经常存在判别性不强，难以区分的问题，表现为：1) 标签相同但外观不同的图像块，称之为类内不一致，如图 1 第一行所示；2) 两个相邻的图像块，标签不同但外观相似，称之为类间无差别，如图 1 第二行所示。??图 1：棘手的语义分割实例。第二列是 FCN 模型的输出；第三列是本文方法的输出。第一行中，图中牛的左下角被识别为马，这属于类内不一致问题。第二行中，电脑主机上的蓝光及黑色机壳与显示器相似，因此难以区分，这属于类间无差别问题。为解决上述两个挑战，本文从一个更加宏观的角度重新思考语义分割，将其看作一项把一致的语义标签分配给一类物体而不是每个单一像素的任务。这就需要把每个类别的像素看作一个整体，进而同时兼顾类内一致（intra-class consistency）与类间差别（inter-class variation）。这意味任务需要判别特征，所以本文提出一个全新的判别特征网络(DFN) 以学习特征表征。DFN 有两个组件：Smooth Network 和 Border Network。Smooth Network 用来解决类内不一致问题，从而需要学习一个鲁棒特征表征，为此本文主要考虑两个关键因素。一方面，需要多尺度和全局语境特征编码局部和全局信息。比如，由于缺乏足够的语境信息，图 1(a) 中的白色小图像块经常无法预测正确的类别；另一方面，随着引入多尺度语境，对于一定尺度的物体来说，特征具有不同程度的判别力，其中一些可能预测假标签。因此，有必要选择高效的判别特征。正是出于上述两方面的考虑，Smooth Network 展现为 U 形结构，以抓取不同尺度的语境信息，并通过全局平均池化抓取全局语境。此外，本文还提出通道注意力模块(CAB)，利用高层特征逐阶段地指导低层特征的选择。Border Network 负责区分外观相似但标签不同的相邻图像块。大多数现有方法把语义分割看作一种密集识别问题，无法明确建模类间关系。以图 1(d) 为例，如果越来越多的全局语境整合进分类过程，相邻于显示器的电脑主机由于外观相似很容易被误认是显示器。因此，明确地使用语义边界指导特征的学习非常重要，这可以增强特征两边的变化。训练时，作者把语义边界损失整合进 Border Network 以学习判别特征，增大类间差别。网络架构有关DFN的网络架构，首先详述它的两个组件 Smooth Network 和 Border Network；接着，具体解释两者如何实现类内一致和类间差别；最后描述 DFN 完整的编码器-解码器网络架构。??图 2：判别特征网络概览。（a）网络架构。（b）优化残差模块（Refinement Residual Block/RRB）的组件。（c）通道注意力模块（CAB）的组件。红线、蓝线分别表征上采样和下采样算子。绿线仅是信息传递路径，不改变特征图的大小。--Smooth Network绝大多数现有方法无法保证正确预测每个图像块的类别，尤其当图像块属于较大区域和复杂场景之时；这种类内不一致问题的主要原因在于语境的缺失，为此作者提出带有全局平均池化的全局语境。但是，全局语境只具有高语境信息，无助于复原空间信息，作者需要多尺度感受野和语境来优化空间信息，正如大多数现有方法那样。然而，由于不同尺度的感受野其判别力也各不相同，从而造成不一致的结果，从而需要选择更具判别力的特征预测某个特定类别的统一语义标签。具体而言，本文使用 ResNet 作为基础识别模型；根据特征图大小，该模型可划分为 5 个阶段。据观察，不同阶段识别能力各不相同，一致性表现也各不相同。在低级阶段，网络编码更精细的空间信息，但是由于缺乏空间语境指导和感受野较小，其语义一致性表现欠佳；而在高级阶段，由于感受野较大，语义一致性表现较佳，但是预测的空间信息较粗糙。总体而言，低级阶段有着更精确的空间预测，而高级阶段有着更精确的语义预测。基于这一观察，本文提出 Smooth Network 以整合两者的优势，利用高级阶段的一致性指导低级阶段获得最优的预测。?图 3：通道注意力模块图示。在（a）中，黄色模块表征低级阶段的特征，红色模块表征高级阶段的特征。作者结合相邻阶段的特征以计算权重向量，从而更新低级阶段特征图的权重。较深色模块表征高权重值。（b）是第 4 阶段通道注意力模块的真实注意力值向量。蓝色越深，表征权重值越大。当下流行的语义分割架构主要有两种 style，一种是 Backbone，如 PSPNet 和 Deeplab v3；另一种是 Encoder-Decoder，比如 RefineNet 和全局卷积网络。但上述架构并不完备，为此，本文首先嵌入一个全局平均池化层把 U 形架构扩展为 V 形架构，为网络引入最强的一致性约束作为指导；此外，本文提出通道注意力模块以优化一致性，如图 2(c)?所示。该设计结合相邻阶段的特征以计算通道注意力向量（图 3(b)）。高级阶段的特征给出一个强大的一致性指导，而低级阶段的特征给出特征的不同判别信息，从而通道注意力向量可以选择判别特征。通道注意力模块：CAB 的设计目的是改变每一阶段的特征权重以优化一致性，如图 3 所示。在 FCN 架构中，卷积算子输出一个 score map，给出每一类别在每个像素上的概率。其实际意义在于暗示了不同通道的权重是平等的。然而，如上所述，不同阶段的特征判别力不同，造成预测的一致性各不相同。为实现类内一致预测，应该提取判别特征，并抑制非判别特征，从而可以逐阶段地获取判别特征以实现预测类内一致。优化残差模块：特征网络中每一阶段的特征图全都经过 RRB，如图 2(b) 所示。该模块的第 1 个组件是 1 x 1 卷积层，作者用它把通道数量统一为 512。同时，它可以整合所有通道的信息。接着是一个基本的残差模块，它可以优化特征图。此外，受 ResNet 启发，该模块还可以强化每一阶段的识别能力。--Border Network在语义分割任务中，预测经常混淆外观相似的不同类别，尤其当它们在空间上相近之时，因此需要加大特征的差别。出于这一考虑，本文采用语义边界指导特征学习，同时应用显式监督提取精确的语义边界，使网络学习类间差别能力强大的特征，进而提出 Border Network 加大特征的类间差别。Border Network 直接通过显式语义边界监督学习语义边界，类似于语义边界检测任务。这使得语义边界两边的特征变得可区分。本文的工作需要语义边界具有更多的语义含义。因此 Border Network 的设计是自下而上的。它可以同时从低级阶段获取精确的边界信息和从高级阶段获取语义信息，从而消除一些缺乏语义信息的原始边界。由此，高级阶段的语义信息可以逐阶段地优化低级阶段的细节边界信息。借助传统的图像处理方法，比如 Canny，作者可以从语义分割的 groundtruth 中获得网络的监督信号。Border Network 主要关注分离边界两边的类别的语义分割。要精确地提取语义边界，需要两边的特征更加可区分，而这正是作者的目的所在。--网络结构作者使用预训练的 ResNet 作为基础网络。Smooth Network 通过在网络顶部添加全局平均池化层以获得最强的一致性；接着利用 CAB 改变通道的权重进一步提升一致性。同时，Border Network 通过明确的语义边界监督获得精确的语义边界并使两边的特征更易区分。由此，类内特征更加一致，类间特征更易区分。对于显式的特征优化，需要使用多层监督以获取更佳性能，同时网络也更容易训练。Smooth Network 借助 softmax loss 监督每一阶段的上采样输出（全局平均池化层除外），而本文借助 focal loss 监督 Border Network 的输出。两个子网络在一起联合训练，其 loss 通过一个参数控制两者的权重。实验结果本文在两个开源数据集 PASCAL VOC 2012 和 Cityscapes 上评估这一方法。数据集介绍、实现细节结果分析等从略，本文将直接给出 DFN 最终的评估结果，了解更多请参见原论文。??表 5：DFN 在 PASCAL VOC 2012 测试集上的表现。在 MS-COCO 上预训练的方法用“+”标记。??表 6：DFN 在 Cityscapes 测试集上的表现。“-”表明该方法未在发表的论文中展示结果。结论最后总结一下，本文的贡献主要有 4 个方面：-从一个新的宏观视角重新思考语义分割，将其看作一项把一致的语义标签分配给一类物体（而不仅仅是在像素层面）的任务。-提出 DFN 同时解决类内一致和类间差别问题。DFN 分别在 PASCAL VOC 2012 和 Cityscapes 数据集上取得 86.2% 和 80.3% 的当前最优 mean IOU，证实了该方法的有效性。-提出 Smooth Network，通过全局语境和通道注意力模块提升类内一致性。-提出一种自下而上的 Border Network，利用多层边界监督信号增大语义边界两边的特征变化，同时优化预测的语义边界。参考文献[1]?L.-C. Chen, G. Papandreou, F. Schroff, and H. Adam. Rethinking atrous convolution for semantic image segmentation.arXiv, 2017.[2]?K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. InIEEE Conference on Computer Vision and Pattern Recognition, 2016.[3]?J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks.arXiv, 2017.[4]?G. Lin, A. Milan, C. Shen, and I. Reid. Refinenet: Multi-path refinement networks with identity mappings for high-resolution semantic segmentation. InIEEE Conference on Computer Vision and Pattern Recognition, 2017.[5]?W. Liu, A. Rabinovich, and A. C. Berg. Parsenet: Looking wider to see better. InInternational Conference on Learning Representations, 2016.[6]?C. Peng, X. Zhang, G. Yu, G. Luo, and J. Sun. Large kernel mattersCimprove semantic segmentation by global convolutional network. InIEEE Conference on Computer Vision and Pattern Recognition, 2017.
人工智能按下“快进键”	10月31日，习近平总书记在主持中共中央政治局集体学习时强调，人工智能是新一轮科技革命和产业变革的重要驱动力量，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。要深刻认识加快发展新一代人工智能的重大意义，加强领导，做好规划，明确任务，夯实基础，促进其同经济社会发展深度融合，推动我国新一代人工智能健康发展。近年来，我国人工智能产业飞速发展，已经涌现出一大批领先科研成果和全球主导企业。在浙江乌镇举行的第五届世界互联网大会上，发布了15项“世界互联网领先科技成果”，我国多项国内企业主导的人工智能研发成果入选。清华大学发布的《中国人工智能发展报告2018》显示，中国人工智能发展已进入国际领先集团。但业内人士同时指出，当前仍存在核心技术领域力量相对薄弱、对人工智能道德伦理和安全规制关注不够等现实问题。有人气关注热度增长最快“坐无人车的感觉特别酷！”上个周末，7岁的张添然小朋友和家人从北京大兴赶到海淀公园，排了一个半小时队，终于坐上了公园内的“阿波龙”无人驾驶小客车。张添然的母亲说：“坐在无人车上感觉挺安全，只要前面有东西，车马上就能停下来。”11月1日起，北京海淀公园变身人工智能公园。市民可以在智能跑道上“刷脸”查看运动情况，在智能凉亭里和语音助手唱歌聊天，通过一块搭载增强现实（AR）技术的屏幕练习太极拳……开园两周，公园已经服务游客10万人次。在无人车等车点，记者看到三四十位市民正在排队等待，以老人和儿童居多。“阿波龙”是全国首辆商用级无人驾驶电动车。车上没有方向盘、刹车和油门，由安全员通过一块电子屏控制车辆。由于无人车运力有限，许多没能体验上的市民十分遗憾，纷纷说要下次再来。《中国人工智能发展报告2018》显示，从2016年到2017年，人工智能热度飙升，成为年度关注度增长最快的科普话题。有关问卷调查显示，过半受访者支持人工智能全面发展，只有6.23%的受访者对人工智能不了解。人工智能产品并非停留在尝鲜体验阶段，不少产品已经走入千家万户。例如各类智能音箱，只用轻轻呼唤一声，房间内灯光、空调、空气净化器应声打开。“智能家居的本质是不断迭代更新，不断提供更智能、更贴心的用户体验。过去的智能家居产品造价高、维护成本高，我们从开发WiFi模块起步，解决智能家居的无线连接问题，让智能家居软件的升级迭代成为可能，降低了使用成本，让智能家居从过去的酒店别墅走入如今的两室一厅，得到了用户认可。”业内人士指出接地气垂直领域遍地开花“头疼睡不着，该挂哪个科？”记者在微信公众号“厦门大学附属第一医院互联网医院”上输入了身体情况。公众号上的“小嘉医生”详细询问年龄、性别和其他症状后，向记者推荐了睡眠专科门诊的李骏医生。“小嘉医生”并不是真人，而是一位人工智能导诊助手。患者只需打字输入或者语音描述症状，就可以在“小嘉医生”的指引下轻松找到相应科室。“小嘉医生”背后，是将人工智能技术运用在医学领域的AI+医疗项目。目前，这一智能导诊技术已覆盖全科全病种，导诊准确率达98%。除了导诊，腾讯觅影还利用人工智能技术分析医学影像，一秒钟能看10张片子，帮助医生筛查乳腺癌、食管癌、糖尿病视网膜病变等疾病。近年来，人工智能不再是象牙塔中的“高精尖”技术，《2018世界人工智能产业发展蓝皮书》显示，人工智能已经渗透到医疗、金融、商业、教育、安防等垂直领域，甚至应用于制造业和农业生产。在大街小巷，人工智能可以充当巡逻员，实时监控并上报突发安全事件；在田间地头，人工智能成了技术员，帮助监控分析土壤的湿度、温度、光照、酸碱度，实现精准施肥用药；在工厂技术车间，人工智能成了质检员，一刻不停地筛选剔除流水线上的不合格产品。在深圳，依托人工智能、大数据等技术的“城市交通大脑”让交通更顺畅。深圳交警建立全市所有信号交叉口的实时监控系统，制定精准的交通信号管控模式；利用人工智能技术识别违章图片，识别准确率达95%以上，效率提升了10倍。2017年深圳道路交通事故率和全市道路交通拥堵指数下降，城市交通文明指数大幅度提升。“在单纯技术领域，美国在基础理论、创新算法和芯片等领域处于优势地位，但中国在产业化结构、数据化水平以及政策支持力度、基础设施改造上有自己的优势。”有底气科研成果全球领先11月7日，第五届世界互联网大会发布15项“世界互联网领先科技成果”。这些成果从全球20多个国家的400多项成果中挑选出来，展现全球互联网领域最新科技。其中，360安全大脑―分布式智能网络安全防御系统、京东智能供应链技术服务平台、百度Apollo自动驾驶开放平台、小米面向智能家居的人工智能开放平台……多项国内企业主导的人工智能研发成果入选。“要在人工智能研究上取得突破，一方面得拥有对前沿算法有研究、能够融会贯通的高精尖人才。另一方面要能够把算法和实际产业结合，这需要大量数据作为支撑，以及对业务场景和垂直行业的深刻理解。”斯坦福大学计算机系博士、香侬科技创始人李纪为说。《中国人工智能发展报告2018》指出，中国人工智能论文总量和高频被引用论文数量都是世界第一，人工智能专利数量全球最多，人工智能人才总量居世界第二位。同时，中国人工智能企业数量居全球第二，并成为全球人工智能投融资规模最大的国家。2017年，国务院印发《新一代人工智能发展规划》，确立了人工智能发展“三步走”战略。各地政府也出台相应政策，推进人工智能发展。今年9月17日，上海市在世界人工智能大会期间，发布《关于加快推进人工智能高质量发展的实施办法》，围绕集聚高端人才、突破核心技术、推进示范应用等五个方面提出了22条具体举措，大力促进人工智能发展。业内人士指出，中国人工智能发展虽进入国际领先集团，但存在核心技术领域力量薄弱、产研结合转化仍有短板、对人工智能道德伦理和安全规制关注不够等问题。“发展人工智能要注意防范法律和伦理风险。人工智能的立法应以网络安全和用户权益为核心，以促进人工智能发展和规范为目的，以落实平台主体责任和法律底线为抓手。人工智能立法可以单独立法或分类立法，比如有只针对无人驾驶、智能家居的专门法律，也可以通过涵盖性立法统一规定，再分类细化。”相关专家人工智能产业背景和发展趋势	AI，全称是Artificial Intelligence，人工智能的意思。是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。人工智能从诞生以来，理论和技术日益成熟，应用领域也不断扩大，可以设想，未来人工智能带来的科技产品，将会是人类智慧的“容器”。人工智能是一门极富挑战性的科学，从事这项工作的人必须懂得计算机知识，心理学和哲学。人工智能是包括十分广泛的科学，它由不同的领域组成，如机器学习，计算机视觉等等，总的说来，人工智能研究的一个主要目标是使机器能够胜任一些通常需要人类智能才能完成的复杂工作。AI的发展历程1950年，一位名叫马文・明斯基(“人工智能之父”)的大四学生与他的同学邓恩・埃德蒙一起，建造了世界上第一台神经网络计算机。同样是在1950年，被称为“计算机之父”的阿兰・图灵提出了一个举世瞩目的想法――图灵测试。按照图灵的设想：如果一台机器能够与人类开展对话而不能被辨别出机器身份，那么这台机器就具有智能。而就在这一年，图灵还大胆预言了真正具备智能机器的可行性。时间跳转到了70年代，人工智能也步入了一段艰难险阻的岁月。对于人工智能的研究，科研人员对于难度估量过低，缺乏经费，结果导致与美国国防高级研究计划署的合作计划失败，社会舆论的压力也开始慢慢压向人工智能这边,导致很多研究经费被转移到了其他项目上，这也让大家对人工智能的前景思虑担忧。人工智能产业面临衰落，但科技并不会因外界因素而停止发展，直至80年代初期人工智能产业开始崛起.时至今日，在人工智能接近70年的发展历程中，科研技术人员不断突破阻碍，让我们可以看到今天人工智能所取得的辉煌成果，2016谷歌AlphaGO战胜韩国李世h。这也是人工智能胜过人类的一个里程碑式的象征。人工智能产业现状当前的人工智能产业的发展浪潮，主要是源于深度学习算法的提出，在数据量和计算能力的基础上实现大规模计算，属于技术性突破。属于超级人工智能的，关于意识起源、人脑机理等方面的基础理论研究仍有继续突破的余地。目前，苹果、谷歌、微软、亚马逊、Facebook这五大巨头无一例外都投入了越来越多的资源，来抢占人工智能市场，甚至将自己整体转型为人工智能驱动型的公司。国内互联网领军者“BAT”也将人工智能作为重点战略，凭借自身优势，积极布局人工智能领域。现今中国人工智能行业的创业公司发展领域各色各异，计算机视觉领域拥有最多创业公司，其次就是服务机器人领域，而排名第三的是语音及自然语言处理领域，智能医疗、机器学习、智能驾驶等也是相比比较热门的领域之一。计算机视觉技术是人工智能的重要核心技术之一，可应用到安防、金融、硬件、营销、驾驶、医疗等领域，而目前我国计算机视觉技术水平已达到全球领先水平，广泛的商业化渠道和技术基础是其成为最热门领域的主要原因。人工智能产业链可以分为基础设施层、应用技术层和行业应用层。基础层：主要有基础数据提供商、半导体芯片供应商、传感器供应商和云服务商；技术层：主要有语音识别、自然语言处理、计算机视觉、深度学习技术提供商；应用层：主要是把人工智能相关技术集成到自己的产品和服务中，然后切入特定场景。目前来看，自动驾驶、医疗、安防、金融、营销等领域是业内人士普遍比较看好方向。人工智能未来趋势人工智能是对人的意识、思维的信息过程的模拟。人工智能不是人的智能，但能像人那样思考、也可能超过人的智能。机器人是人工智能的一种形式，它是能模仿人的某些活动的一种自动机械。一般能实现行走和操作生产工具等动作，可用在人所不能适应的环境下代替人工作。现代机器人都配装电子计算机，通过编排程序，能具有一定程度的人工智能，如识别语言和图像，并作出适当的反应等。过去的科技进步主要是指提升执行指定任务的能力。而当今的人工智能则是赋予机器反应和适应能力以优化产出。通过与物联网、机器人等技术的结合，人工智能能够构造出一个整合的信息物理世界。当今人工智能发展势头正猛，未来有望在全球多个行业和场景下得到广泛运用，尤其是我们将会看到大量的人类工作被机器取代。当然，技术可行性只是影响自动化速度及程度的一个因素，还有其他因素需要考虑，包括研发和应用成本、劳动力市场供需、经济效益，以及社会和政府监管部门的接受度。展望未来，人工智能可成为应对一些社会核心挑战的强大工具。在医疗领域，人工智能将极大提升我们分析人类基因组和为患者开发个性化治疗方案的能力，甚至大大加快治愈癌症、阿海默症和其他疾病的进程。在环保领域，人工智能能够分析气候特征并大规模降低能耗，帮助人类更好地监控和应对气候变化问题。人工智能甚至可以在地球以外地区发挥作用，他日或助力人类探索火星及外太空。
CVPR 2018 | 为移动 AI 而生――旷视(Face++)最新成果 ShuffleNet 全面解读	在视觉人工智能系统中，卷积神经网络（CNN）起着至关重要的作用。日前，旷视(Face++)研究院发表了《ShuffleNet：一种极高效的移动端卷积神经网络》一文，作者针对移动端低功耗设备提出了一种更为高效的卷积模型结构，在大幅降低模型计算复杂度的同时仍然保持了较高的识别精度，并在多个性能指标上均显著超过了同类方法。本文将对该成果进行详细解读。论文下载地址：https://arxiv.org/abs/1707.01083设 计 思 想卷积神经网络是现代视觉人工智能系统的核心组件。近年来关于卷积模型的研究层出不穷，产生了如 VGG、ResNet、Xception 和 ResNeXt 等性能优异的网络结构，在多个视觉任务上超过了人类水平。然而，这些成功的模型往往伴随着巨大的计算复杂度（数十亿次浮点操作，甚至更多）。这就限制了此类模型只能用于高性能的服务器集群，而对于很多移动端应用（通常最多容许数百万至数千万次浮点操作）则无能为力。解决这一难题的方法之一是设计更为轻量级的模型结构。现代卷积神经网络的绝大多数计算量集中在卷积操作上，因此高效的卷积层设计是减少网络复杂度的关键。其中，稀疏连接（sparse connection）是提高卷积运算效率的有效途径，当前不少优秀的卷积模型均沿用了这一思路。例如，谷歌的”Xception“网络[1]引入了”深度可分离卷积”的概念，将普通的卷积运算拆分成逐通道卷积（depthwise convolution）和逐点卷积（pointwise convolution）两部进行，有效地减少了计算量和参数量；而 Facebook 的“ResNeXt”网络[2]则首先使用逐点卷积减少输入特征的通道数，再利用计算量较小的分组卷积（group convolution）结构取代原有的卷积运算，同样可以减少整体的计算复杂度。ShuffleNet 网络结构同样沿袭了稀疏连接的设计理念。作者通过分析 Xception 和 ResNeXt 模型，发现这两种结构通过卷积核拆分虽然计算复杂度均较原始卷积运算有所下降，然而拆分所产生的逐点卷积计算量却相当可观，成为了新的瓶颈。例如对于 ResNeXt 模型逐点卷积占据了 93.4% 的运算复杂度。可见，为了进一步提升模型的速度，就必须寻求更为高效的结构来取代逐点卷积。受 ResNeXt 的启发，作者提出使用分组逐点卷积（group pointwise convolution）来代替原来的结构。通过将卷积运算的输入限制在每个组内，模型的计算量取得了显著的下降。然而这样做也带来了明显的问题：在多层逐点卷积堆叠时，模型的信息流被分割在各个组内，组与组之间没有信息交换（如图 1(a) 所示）。这将可能影响到模型的表示能力和识别精度。图 1 逐点卷积与通道重排操作因此，在使用分组逐点卷积的同时，需要引入组间信息交换的机制。也就是说，对于第二层卷积而言，每个卷积核需要同时接收各组的特征作为输入，如图 1(b) 所示。作者指出，通过引入“通道重排”（channel shuffle，见图 1(c) ）可以很方便地实现这一机制；并且由于通道重排操作是可导的，因此可以嵌在网络结构中实现端到端的学习。网 络 结 构基于分组逐点卷积和通道重排操作，作者提出了全新的 ShuffleNet 结构单元，如图 2 所示。该结构继承了“残差网络”（ResNet）[3]的设计思想，在此基础上做出了一系列改进来提升模型的效率：首先，使用逐通道卷积替换原有的 3x3 卷积，降低卷积操作抽取空间特征的复杂度，如图 2(a)所示；接着，将原先结构中前后两个 1x1 逐点卷积分组化，并在两层之间添加通道重排操作，进一步降低卷积运算的跨通道计算量。最终的结构单元如图 2(b) 所示。类似地，文中还提出了另一种结构单元（图2(c)），专门用于特征图的降采样。借助 ShuffleNet 结构单元，作者构建了完整的 ShuffeNet 网络模型。它主要由 16 个 ShuffleNet 结构单元堆叠而成，分属网络的三个阶段，每经过一个阶段特征图的空间尺寸减半，而通道数翻倍。整个模型的总计算量约为 140 MFLOPs。通过简单地将各层通道数进行放缩，可以得到其他任意复杂度的模型。另外可以发现，当卷积运算的分组数越多，模型的计算量就越低；这就意味着当总计算量一定时，较大的分组数可以允许较多的通道数，作者认为这将有利于网络编码更多的信息，提升模型的识别能力。图 2 ShuffleNet 结构单元实 验 结 果作者通过一系列在 ImageNet 2016 分类数据集上的控制实验说明了 ShuffleNet 结构单元每个部件存在的必要性、对于其他网络结构单元的优越性。接着作者通过在 MS COCO 目标检测上的结果说明模型的泛化能力。最后，作者给出了在 ARM 计算平台上 ShuffleNet 实际运行时的加速效果。分组化逐点卷积作者对于计算复杂度为 140 MFLOPs 、 40 MFLOPs、13 MFLOPs的 ShuffleNet 模型，在控制模型复杂度的同时对比了分组化逐点卷积的组数在1~8时分别对于性能的影响。从 表1 中可以看出，带有分组的(g>1)的网络的始终比不带分组(g=1)的网络的错误率低。作者观察到对于较小的网络(如 ShuffleNet 0.25x )，较大的分组会得到更好结果，认为更宽的通道对于小网络尤其重要。受这点启发，作者移除了网络第三阶段的两个结构单元，将节省下来的运算量用来增加网络宽度后，网络性能进一步提高。表1 组数对分类错误率的影响通道重排通道重排的目的是使得组间信息能够互相交流。在实验中，有通道重排的网络始终优于没有通道重排的网络，错误率降低 0.9%~4.0%。尤其是在组数较大时(如g=8)，前者远远优于后者。对比其他结构单元作者使用一样的整体网络布局，在保持计算复杂度的同时将 ShuffleNet 结构单元分别替换为 VGG-like、ResNet、Xception-like 和 ResNeXt 中的结构单元，使用完全一样训练方法。表2 中的结果显示在不同的计算复杂度下，ShuffleNet 始终大大优于其他网络。表2 和其他网络结构的分类错误率对比（百分制）对比MobileNets和其他网络结构最近 Howard et al. 提出了 MobileNets[4]，利用[1]里的逐通道卷积的设计移动设备上高效的网络结构。虽然 ShuffleNet 是为了小于 150 MFLOPs 的模型设计的，在增大到 MobileNet 的 500~600 MFLOPs 量级，依然优于 MobileNet。而在 40 MFLOPs 量级，ShuffleNet 比 MobileNet 错误率低 6.7%。详细结果可以从表3中得到。表3 ShuffleNet 和 MobileNet 对比和其他一些网络结构相比，ShuffleNet 也体现出很大的优势。从表4中可以看出，ShuffleNet 0.5x 仅用 40 MFLOPs 就达到了 AlexNet 的性能，而 AlexNet 的计算复杂度达到了 720 MFLOPs，是 ShuffleNet 的 18 倍。表4 ShuffleNet 和其他网络结构计算复杂度的对比MS COCO物体检测在 Faster-RCNN[5]框架下，和 1.0 MobileNet-224 网络复杂度可比的 ShuffleNet 2x，在 600 分辨率的图上的 mAP 达到 24.5%，而 MobileNet 为 19.8%，表明网络在检测任务上良好的泛化能力。实际运行速度最后作者在一款 ARM 平台上测试了网络的实际运行速度。在作者的实现里 40 MFLOPs 的 ShuffleNet 对比相似精度的 AlexNet 实际运行速度快约 13x 倍。224 x 224 输入下只需 15.2 毫秒便可完成一次推理，在 1280 x 720 的输入下也只需要 260.1 毫秒。应 用 展 望很多重要的需要语义信息的计算机视觉任务，如目标检测、物体识别等，都需要一个好的“基础模型”作为特征提取器。在移动设备越发重要的今天，在其之上运行的视觉算法模型会越多、准确率要求会越来越高。无论目标检测和识别、人脸检测和识别，还是图片风格化编辑、美颜，抑或是直播用户行为分析，都离不开基础模型的支持。好的基础模型可以让因为原始运算力需求过大而无法在手机上高效运行的模型能高效运行，将众多不可能变为可能。此外，其他常用的模型压缩技术，如稀疏化、网络量化等技术也可以在 ShuffleNet 上应用，提高存储效率和运行速度，进一步降低视觉算法和应用的落地门槛。参 考 文 献[1]Fran?ois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv:1610.02357, 2016.[2]Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. arXiv:1611.05431, 2016.[3]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770C778, 2016.[4]Howard, Andrew G., et al. "Mobilenets: Efficient convolutional neural networks for mobile vision applications." arXiv preprint arXiv:1704.04861 (2017).[5]Ren, Shaoqing, et al. "Faster R-CNN: Towards real-time object detection with region proposal networks." Advances in neural information processing systems. 2015.
CVPR 2018 | 旷视科技Face++提出RepLoss，优化解决密集遮挡问题	全球计算机视觉顶会 CVPR 2018 （Conference on Computer Vision and Pattern Recognition，即 IEEE 国际计算机视觉与模式识别会议）将于6月18日至22日在美国盐湖城举行。作为大会钻石赞助商，旷视科技Face++研究院也将在孙剑博士的带领下重磅出席此次盛会。论文链接：https://arxiv.org/abs/1711.07752导语人群检测是计算机视觉技术发展不可绕过的关键一环，其中密集遮挡（crowd occlusion）问题是最具挑战性的问题之一。旷视科技Face++从技术底层的层面提出一种全新的人群检测定位模型 Repulsion Loss（RepLoss），在相当程度上优化解决了这一难题。底层技术创新的适用范围异常广泛，这意味着绝大多数与人群检测相关的产品应用皆可实现不同程度的提升，从根本上推动安防监控、自动驾驶、无人零售、智慧城市的落地和发展。此外，人群定位技术 RepLoss 的检测对象并不仅限于人，还可迁移泛化至一般物体检测，其底层创新驱动力的波及范围十分广泛，有助于机器之眼打造一个人、物、字、车的检测矩阵，进一步看清楚、看明白这个世界。RepLoss 设计思想检测人群之中的行人依然是一个充满挑战性的问题，因为在现实场景中行人经常聚集成群，相互遮挡。一般而言，物体遮挡问题可以分为类内遮挡和类间遮挡两种情况。类间遮挡产生于扎堆的同类物体，也被称为密集遮挡（crowd occlusion）。在行人检测中，密集遮挡在所有遮挡问题中占比最大，严重影响着行人检测器的性能。密集遮挡的主要影响表现在显著增加了行人定位的难度。比如，当目标行人T被行人B遮挡之时，由于两者外观特征相似，检测器很可能无法进行定位。从而本应该框定T的边界框转而框定B，导致定位不准确。更糟糕的是，由于非极大值抑制（non-maximum suppression/NMS）需要进一步处理主要的检测结果，从T移走的边界框可能会被B的预测框抑制，进而造成 T 漏检。即，人群遮挡使得检测器对 NMS 阈值很敏感：较高的阈值会带来更多的误检（false positives），较低的阈值则造成更多的漏检（missed detection）。这会让大多数实例分割框架失效，因为它们也需要精确的检测结果。因此，如何精确地定位人群之中的每个行人是检测器最为关键的问题之一。?图 1：RepLoss 图示。在当前最优的检测框架中，边界框回归技术常用来定位物体，其中回归器被训练用来缩小 proposal 和 groundtruth box 之间的差距（通过一些距离度量进行测量，比如 Smooth_L1 或者 IoU）。尽管如此，现有方法只需要 proposal 接近其指定目标，并不考虑周遭的物体。如图 1 所示，在标准的边界框回归损失中，当预测框移向周遭物体时，对其并没有额外的惩罚。这不免使人设想：如果要检测人群之中的一个目标，是否应该考虑其周遭物体的定位？在磁极相互排斥吸引的启发下，本文提出一种全新的定位技术，称之为Repulsion Loss（RepLoss），通过它，每一个 proposal 不仅会靠近其指定目标T，还会远离其他 groundtruth 物体以及指定目标不是 T 的其他 proposal。如图 1 所示，由于与周遭的非目标物体重叠，红色边界框移向B将受到额外的惩罚。因此，RepLoss 可以有效防止预测边界框移向相邻的重叠物体，提升检测器在人群场景中的鲁棒性。密集遮挡的影响本节将借助实验探讨当前最优的行人检测器如何受到密集遮挡（crowd occlusion）的影响，更加深入地理解密集遮挡问题。密集遮挡主要会造成两个方面的问题，漏检和误检，下面会通过两个图示分别作出解释，其中基线检测器是针对行人检测优化的 Faster R-CNN，并使用新型行人检测数据集 CityPersons?。??图 3：基线与 RepGT 的错误检测分析。图 3(a)?是不同检测分值下在 reasonable-crowd 子集上的漏检数量，红线表示基线的 groundtruth 行人漏检数量。在现实应用中，只考虑带有高置信度的预测边界框，曲线左端的高漏检量意味着离实际应用还很远。图 3(b) 表示由密集遮挡导致的误检占全部误检的比例，红线表明基线的这一比例大概在 20% 左右。如图 3 红、蓝线对比所示，RepGT 损失分别有效降低了由密集遮挡造成的漏检和误检数量。?图 4：错误检测的可视化实例。红框表示由密集遮挡引起的误检。如图 4 所示，绿框是正确的预测边界框，而红框是由密集遮挡造成的误检，并给出了检测器的置信值。如果预测框轻微或显著移向相邻的非目标 groundtruth 物体（比如右上图），或者框定若干个彼此遮挡物体的重叠部分（比如右下图），则经常出现检测错误。此外，密集遮挡引起的检测错误通常有着较高的置信度，从而造成高排名的误检。这表明为提高检测器在密集场景中的鲁棒性，需要在执行边界框回归时有更具判别力的损失。下面是另一个可视化实例：??图 9：基线与 RepLoss 的对比。蓝框表示误检，红框表示漏检。灰色虚线上、下两部分的第一行是基线的预测结果；第二行是添加 RepLoss 之后的预测结果。通过分析错误检测表明，密集遮挡对行人检测器的影响令人吃惊，不仅是漏检的主要来源，还在增加定位难度的同时造成了更多的误检。正是为解决上述问题，提升行人检测器在密集场景中的鲁棒性，RepLoss 被提了出来。RepLoss计算方法本节将详述如何计算 RepLoss。受到磁石属性的启发，RepLoss 包括 3 个组件，表示为：??其中 L_Attr 是吸引项，需要预测框靠近其指定目标；L_RepGT 和 L_RepBox 是排斥项，分别需要预测框远离周遭其他的 groundtruth 物体和其他指定目标不同的预测框。系数 α 和 β 充当权重以平衡辅助损失。为简明起见，下面仅考虑两类检测，假定所有的 groundtruth 物体属于同一类别。分别使 P = (l_P,t_P,w_P,h_P)?和 G = (l_G, t_G, w_G, h_G)?为 proposal 边界框和 groundtruth 边界框，并分别由它们的左上点坐标及其高度、宽度表示。P_+ = {P}?是所有 positive proposal 的集合（那些和至少一个 groundtruth box 有高 IoU 的被视为正样本，反之为负样本）；G = {G}?是一张图片中所有 groudtruth box 的集合。--吸引项本文沿用 Smooth_L1 ?构造吸引项。给定一个 proposal P ∈ P_+，把具有极大值 IoU 的 groundtruth box 作为其指定目标：G^P_Attr = arg max_G∈G IoU(G,P)。B^P 是回归自 proposal P 的预测框。由此吸引损失可计算为：?--排斥项（RepGT）RepGT 损失旨在使 proposal 受到相邻的非目标 groundtruth 物体的排斥。给定一个 proposal P ∈ P_+，它的排斥 groundtruth 物体被定义为除了其指定目标之外带有最大 IoU 区域的 groundtruth 物体。受 IoU 损失的启发，RepGT 损失被计算以惩罚 B^P 和 G^P_Rep 之间的重叠（由 IoG 定义）。IoG(B, G) ∈ [0, 1]?，从而 RepGT 损失可写为：?其?中 Smooth_ln?是一个在区间 (0, 1)?连续可微分的平滑 ln 函数，σ ∈ [0, 1)?是调节RepLoss 对异常值的敏感度的平滑参数。由此可见，proposal 越倾向于与非目标 groundtruth 物体重叠，RepGT 损失对边界框回归器的惩罚就越大，从而有效防止边界框移向相邻的非目标物体。--排斥项（RepBox）NMS 是绝大多数检测框架中不可或缺的后处理步骤，为降低检测器对 NMS 的敏感度，作者接着提出 RepBox 损失，意在排斥来自不同指定目标的proposal。RepBox 损失可计算为：?从上式可以看到，为最小化 RepBox 损失，指定目标不同的两个预测框之间的 IoU 区域需要较小。这意味着 RepBox 损失可以降低 NMS 之后不同回归目标的边界框合并为一的概率，使得检测器在密集场景中更鲁棒。RepLoss实验结果本节将直接给出 RepLoss 在数据集 CityPersons 和 Caltech-USA?上的评估结果，包括在 CityPersons 上分别评估和分析 RepGT 损失 和 RepBox 损失；在 CityPersons 和 Caltech-USA 上把 RepLoss 与当前最优的方法相对比。实验设置和实现细节从略，了解更多请参见原论文。??表 3：在 CityPersons 上评估的 RepLoss 行人检测结果。模型在训练集上训练，并在验证集上测试。ResNet-50?是 backbone。最佳的 3 个结果分别标为红、蓝、绿色。??表 4：在新注释中评估的 Calech-USA 测试集 (reasonable) 结果。?在 0.5 IoU 阈值下，作者进一步在强基线上把当前最优推进到显著的 4.0 MR^?2。当把 IoU 阈值增至 0.75，持续的涨点证明了 RepLoss 的有效性。??图 7：在基线和 RepBox 的 NMS 之前的预测框可视化对比。RepBox 结果中两个相邻的 groundtruth 之间的预测较少，模型输出的边界框的分布更加明晰。图 10：更多的 CityPersons 数据集检测实例(左右滑动查看更多)。绿框中是预测的行人，其分值([0, 1.0])?大于 0.8。结论RepLoss 专为行人检测精心设计，尤其提升了密集场景的检测性能，其主要想法在于目标物体的吸引损失并不足以训练最优的检测器，来自周遭物体的排斥损失同样至关重要。为充分发挥排斥损失的潜能，本文提出 RepGT 和 RepBox，并在流行数据集 CityPersons 和 Caltech-USA 上取得了当前最优水平。特别是，本文结果在未使用像素注释的情况下优于使用像素注释的先前最佳结果大约 2%。详细的实验结果对比证实了 RepLoss 在大幅提升遮挡场景下检测精度方面的价值，并且一般的物体检测?(PASCAL VOC)?结果进一步表明了其有效性。作者希望 RepLoss 在诸多其他物体检测任务中也有更为广泛的应用。参考文献[1]Dollar, C. Wojek, B. Schiele, and P. Perona. Pedestrian detection: A benchmark.In IEEE Computer Vision and Pattern Recognition, 2009.[2]K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. InIEEE Conference on Computer Vision and Pattern Recognition, 2016.[3]J. Mao, T. Xiao, Y. Jiang, and Z. Cao. What can help pedestrian detection?In IEEE Conference on Computer Vision and Pattern Recognition, 2017.[4]S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towardsreal-time object detection with region proposal networks.In NIPS, 2015.[5]J. Yu, Y. Jiang, Z. Wang, Z. Cao, and T. Huang. Unitbox: An advanced object detection network.In Proceedings of the 2016 ACM on Multimedia Conference.[6]S. Zhang, R. Benenson, and B. Schiele. Citypersons: A diverse dataset for pedestrian detection.In IEEE Conference on Computer Vision and Pattern Recognition, 2017.
人工智能被赋引领变革重任 传统产业技术升级有望成风口?	中共中央政治局10月31日就人工智能发展现状和趋势举行第九次集体学习，会议强调人工智能具有很强的“头雁”效应，推动新一代人工智能发展已成为赢得科技竞争主动权的关键抓手。此项事业的发展不仅事关经济、社会、国际政治经济格局等方方面面，还是我国科技发展、产业升级、生产力进步的重要推力。人工智能已经成为引领新一轮科技革命和产业变革的战略性技术。人工智能被赋予引领变革重任此次会议提出人工智能具有多学科综合、高度复杂的特征，因此要加强基础理论的研究，支持科学家勇闯“无人区”；主攻关键核心技术，确立问题导向意识，抓紧补足短板；强化科技应用开发，坚持需求导向、市场倒逼的科技发展路径；促进人才队伍建设，创建多形式、高层次人才培养平台。人工智能和产业深度融合乃大势所趋。会议提出建设现代化经济体系，要求人工智能在各个领域发挥融合效应，要依赖于“移动互联网、大数据、超级计算、传感网、脑科学等”形成共振，提高全要素生产率；培育人工智能企业和产业的“排头兵”，发挥其在产业升级、产品开发、服务创新等方面的技术禀赋；赋能信息基础设施建设，提高其智能化水平。从年初政府工作报告到年中的信息消费规划，再到9月的全球人工智能在上海召开、如今的中央政治局的集体学习，人工智能始终是各项政策直营的重要方向，显示国家领导层对于人工智能未来能够对中国经济乃至整体的民生社稷的影响力给予了高度的重视。因此，未来人工智能有望帮助国家实现产业全面升级、供给侧改革、产业附加值提升等各项规划。我国AI规模增长第一目前，各国政府密集发布人工智能战略，科技巨头亦纷纷高调加码。继中国在2017年7月发布《新一代人工智能发展规划》之后，2018年以来世界各国密集跟进，3月法国宣布人工智能发展战略，并提出将在2022年之前投入15亿欧元，4月英国发布《英国人工智能发展的计划、能力与志向》，欧盟提交《欧盟人工智能》报告并提出三大目标，7月德国政府通过“人工智能战略计划”，目标打造人工智能强国，9月美国众议院签发AI白皮书《机器崛起：人工智能及对美国政策不断增长的影响》。据前瞻产业研究院发布的《人工智能行业市场前瞻与投资战略规划分析报告》统计数据显示，2014年中国人工智能市场规模仅仅达到50亿元左右，到了2016年中国人工智能市场规模突破100亿元，达到了100.6亿元。2017后中国人工智能市场规模超150亿元，预计2018年中国人工智能市场规模将超过230亿元，增速全球第一，2025年有望超过美国。传统产业技术升级有望成风口？随着移动互联网时代向人工智能新时代的加速过渡，AI将加速赋能，并为医疗、金融、安防、教育、交通、物流等各类传统行业带来机遇与发展潜力。在人工智能技术发展将会面临改变的六大行业中，交通运输行业作为非常重要的部分出现，其被广泛认为将最先引爆AI技术的巨大变革。AI+医疗也是人工智能技术实现落地应用的重点方向，大数据、人工智能对医疗行业的赋能表现在多个方面，如辅助医生诊疗决策、提升患者就诊效率。目前人工智能的成熟度已有明显提高，各行各业在积极推动“AI+”的落地应用，AI技术和应用都在迅速取得突破，传统产业技术升级有望成突破风口，例如机器视觉、语音识别、自动驾驶、数据挖掘等应用场景，同时，AI技术在农业、制造业、服务业领域的融合发展也具备广阔前景，将成为人工智能的突破风口。
CVPR 2018 | 旷视科技人体姿态估计冠军论文――级联金字塔网络CPN	全球计算机视觉顶会 CVPR 2018 （Conference on Computer Vision and Pattern Recognition，即IEEE国际计算机视觉与模式识别会议）将于6月18日至22日在美国盐湖城举行。作为大会钻石赞助商，旷视科技研究院也将在孙剑博士的带领下重磅出席此次盛会。??论文链接：https://arxiv.org/abs/1711.07319GitHub：https://github.com/chenyilun95/tf-cpn.git导语人体姿态估计是计算机视觉领域的基本研究方向之一，多人姿态估计（Multi-Person Pose Estimation）是该方向上的一个经典难题；在传统算法遭遇瓶颈之时，虽然卷积神经网络的再次崛起和快速迭代为解决这一问题带来了新工具，多人姿态估计依然面临着一些百啃不动的“硬骨头”。为此，旷视科技提出级联金字塔网络（Cascaded Pyramid Network/CPN），可优化解决关键点难以识别的问题，结果证明非常奏效。CPN 的这一技术突破将促进人体姿态估计相关应用领域的发展，比如游戏动画、安防（异常行为检测等）、体育（裁判辅助等）、自动驾驶等。设计思想多人姿态估计旨在识别和定位图像之中所有人体的关键点，对于很多视觉应用比如人体动作识别和人机交互来说，这是一个基本的研究课题。最近，由于深度神经网络的快速发展，多人姿态估计获得显著提升。比如 Mask R-CNN 首先预测人体边界框，接着据此压缩特征图以获取人体关键点。尽管成果不断，但面临的挑战并未减少，比如在关键点重叠，关键点不可见以及背景拥挤的情况下很难实现定位；究其原因主要有两方面：1）上述“困难”点无法只根据其外观特征被简单识别，比如躯干点；2）上述“困难”点在训练期间并没有被明确处理。为此，本文提出一种全新的网络架构――级联金字塔网络（Cascaded Pyramid Network/CPN），它分为两个阶段：GlobalNet 和 RefineNet。GlobalNet 基于特征金字塔网络学习一个好的特征表征。并且，金字塔特征表征可以提供充足的语境信息，这对于推断遮挡和不可见的关键点来说必不可少。在金字塔特征的基础上，RefineNet 显式地处理“困难”点。这是一种 top-down pipeline，先通过检测器检测出图像之中的人，再把每个人抠出来并做单人姿态估计，最后把结果整合到原图上。CPN 这种两阶段架构设计的想法其实也不复杂，甚至可以说是相当朴素直观，来源于人是怎么识别人体关键点，即由特征金字塔网络 GlobalNet先识别出简单关键点，再由（借助 online hard keypoint mining loss 的）RefineNet 整合来自前者的特征表征以识别余下的困难关键点。这样从易到难，层层推进，最终克服了关键点难以识别的问题。此外，本文还探索了不同因素（人体检测器和数据预处理等）对多人姿态估计的影响。比如，通过实验发现检测平均精度（Detection mAP）在达到一定阈值（Det mAP41.1）之后对关键点平均精度(Keypoint mAP)的影响有限。再比如使用Large batch，可以把 CPN 的 mAP 提升 0.4-0.7 个百分点，这说明除了物体检测之外，Large batch 同样适用于关键点识别。这些细节对于研究如何进一步提升 CPN 的准确度和鲁棒性非常有价值。网络架构类似于 Mask R-CNN，CPN pipeline 也是自顶而下的：首先通过人体检测器根据图像生成一个边界框集合；接着通过单人关键点估计器预测每个人关键点的详细定位。采用基于 FPN 的当前最优物体检测器作为人体检测器，并用 Mask R-CNN ROIAlign?替代 FPN ROIPooling。在 Stacked hourglass?等网络的启发下，本文提出 CPN，其架构如图 1 所示。??图 1：级联金字塔网络（CPN）。L2 loss*?表示带有在线困难关键点挖掘的 L2 loss。--GlobalNetCPN 的网络架构基于 ResNet。把不同卷积特征 conv2?5 的最后残差块分别表示为 C_2 , C_3 , ..., C_5，并在其上应用 3 × 3?卷积滤波器生成关键点的热力图。如图 2 所示，浅层特征比如C_2 , C_3 在定位上有着较高的空间分辨率，但是在识别上语义信息较少。另一方面，由于卷积（和池化），深度特征层比如 C_4，C_5 语义信息较多，但空间分辨率较低。因此经常引入 U 型结构同时保留特征层的空间分辨率和语义信息。??图 2：不同特征的输出热力图。绿点表示关键点的 groundtruth 位置。最近，FPN 通过深度监督信息进一步完善了 U 型结构，本文的关键点估计应用了相似的特征金字塔结构。稍微不同于 FPN，在上采样的过程中，作者在逐像素加和之前使用 1 × 1?卷积核，而这一结构正是 GlobalNet。如图 2 所示，基于 ResNet backbone，GlobalNet 可有效定位简单的可见关键点（比如眼睛），却无法精确定位困难的隐藏关键点（臀部）。对臀部这类关键点的定位通常需要更多的语境信息和处理，而不是相邻的外观特征。很多情况下，单一 GlobalNet 无法直接识别这些“困难”点。--RefineNetGlobalNet 生成特征金字塔表征来识别“容易”点，RefineNet?则显式处理“困难”关键点。为提升信息传输的效率，保证信息完整性，RefineNet 在不同层之间传输信息，并通过像 HyperNet?一样的上采样和连接把这些信息整合起来。不同于 Stacked hourglass?的优化策略，RefineNet 接收了来自所有金字塔层的特征信息，而不是类似 hourglass 模块之间仅通过最后一个上采样特征进行信息传递。此外还把更多的 bottleneck 模块来处理更深的特征，其较小的空间尺度可实现效率和性能的良好权衡。随着训练的进行，网络会倾向于关注占比较多的“简单”点，其重要性不及“困难”点，比如遮挡等情况，因此网络对两者的关注应该取得一个平衡。为此，RefineNet 根据训练损失在线地显式选择困难关键点（称之为在线困难关键点挖掘/ OHKM），并只从已选择的关键点反向传播梯度。实验整个 CPN pipeline 按照自顶而下的方式估计多人姿态。首先通过当前最优的人体框检测器生成人体 proposals；对于每个 proposal，假定其裁剪区域之内只包含一个人体，然后再由姿态估计网络给出最后的预测。本节将从实验数据的角度展示 CPN 的性能。CPN 评估选用的数据集是 MS COCO test-dev 和 test-challenge。表 10 是 CPN 在 COCO test-dev 上的最终结果。在没有额外训练数据的情况下，CPN 单一模型的 AP 值为 72.1，CPN 多模型融合（带有不同的 groundtruth 热力图）的 AP 值为 73.0。表 9 给出了 CPN 与其他方法在 COCO test-challenge 2017 上的对比结果，72.1 的 AP 值为该数据集的当前最优结果。表 11 是 CPN 和 CPN+（集成模型）在 COCO minival?上的表现，它为 COCO minival 与 COCO test-dev / test-challenge 之间的差距提供了一个参考。图 3 是一些 CPN 结果示例。??表 9：COCO test-challenge 2017 上的最终结果对比。??表 10：COCO test-dev 上的最终结果对比。??表 11：COCO minival , test-dev 以及 test-challenge 上的相应结果。????图 3：CPN 结果示例。结论按照 top-down pipeline，本文提出一种全新的级联金字塔网络 CPN 以解决“困难”关键点问题。具体而言，CPN 包含一个基于特征金字塔结构的 GlobalNet 和一个把所有金字塔特征连接为语境信息的 RefineNet?。此外，RefineNet 中还引入在线困难关键点挖掘以显式处理“困难”点。该算法在 COCO keypoint 基准上取得了当前最优结果，相较于 COCO 2016 keypoint?挑战赛关进有 19% 的提升。ECCV 2018 | 旷视科技提出统一感知解析网络UPerNet，优化场景理解	全球计算机视觉三大顶会之一 ECCV 2018 （European Conference on Computer Vision）即将于9月8 -14日在德国慕尼黑拉开帷幕。届时，旷视首席科学家孙剑博士将带领团队远赴盛会，助力计算机视觉技术的交流与落地。论文名称：《Unified Perceptual Parsing for Scene Understanding》论文链接：https://arxiv.org/abs/1807.10221代码链接：https://github.com/CSAILVision/unifiedparsing导语人类对世界的视觉理解是多层次的，可以轻松分类场景，检测其中的物体，乃至识别物体的部分、纹理和材质。在本文中，旷视科技提出一种称之为统一感知解析（Unified Perceptual Parsing/UPP）的新任务，要求机器视觉系统从一张图像中识别出尽可能多的视觉概念。同时，多任务框架 UPerNet 被提出，训练策略被开发以学习混杂标注（heterogeneous annotations）。旷视科技在 UPP 上对 UPerNet 做了基准测试，结果表明其可有效分割大量的图像概念。这一已训练网络进一步用于发现自然场景中的视觉知识。背景人类视觉系统一眼即可从一张图像中提取大量语义信息。人类不仅可以立即解析其中的物体，还能识别细节属性，比如其部分、纹理和材质。如图 1 所示，这是一间起居室，有着很多不同物体，比如一张咖啡桌，一幅画，以及墙面。同时，我们还看到，这是一张四腿咖啡桌，桌面之上有一块桌垫，以及桌子是木质的，沙发表层是针织的。可见，从材质、纹理的视觉感知到物体及其部分的语义感知，我们对这一视觉场景的描述是多层次的。图 1：针对 UPP 训练的神经网络可一次性解析不同感知层次的视觉概念，比如场景、物体、部分、纹理、材质等。近年来，由于深度神经网络和大型数据集的发展，计算机视觉识别能力取得重大进步，不断逼近甚至超越人类水准。但是，视觉识别任务不同，其研究也各不相同。比如，物体检测和场景识别已达到人类水平，解析和分割的精确度可至像素级；纹理和材质的感知与识别同样有着充分的研究。设计思想在人类视觉系统中，上述任务的完成是一步到位的，这就抛给计算机视觉模型一个问题：一个神经网络是否可以同时解决若干个不同的视觉任务。本文把这个问题以一项新任务的形式提出，称之为统一感知解析（Unified Perceptual Parsing/UPP），并给出一种全新的学习方法解决它。UPP 有若干个挑战。首先，没有一个涵盖所有层面视觉信息的标注数据集。不同的数据集是针对一项项特定任务而打造的。比如 ADE20K 数据集用于场景解析，DTD 数据集用于纹理识别，OpenSurfaces 数据集用于材质和表面识别。其次，不同感知层面的注解也是混杂的。比如，ADE20K 数据集的注解是像素级的，而 DTD 数据集则是图像级的。为解决上述挑战，本文提出一个新框架，整合不同数据集之间的差异性，并学习联合检测不同视觉概念。一方面，本文从每次迭代中随机采样一个数据源，并只更新相关层，以从数据源中推理概念。这样的设计会规避不稳定行为，比如某一特定概念注解的梯度带有噪音。另一方面，该框架借助单一网络特征的分层属性，即，对于高层语义概念比如场景分类，分类器只基于带有较高级语义信息的特征图而构建；对于较低级语义信息，比如物体和材质分割，分类器只基于所有阶段的或者带有低级语义信息的特征图而构建。进而，本文提出一种训练方法，可使网络只使用图像级的注解即可预测像素级的纹理标签。本文贡献可归纳为如下 3 个方面：1）提出一种新解析任务――统一感知解析（UPP），它需要系统一次性解析多层次视觉概念；2）提出一种带有层级结构的全新网络――UPerNet，可学习不同图像数据集中的差异化数据；3）该网络可实现联合推理，并发掘图像之中丰富的视觉知识。定义 UPPUPP 任务是指从一张给定图像中识别出尽可能多的视觉概念，从场景标签，物体，到其部分、纹理和材质，视觉概念是多层次的。该任务依赖于不同训练数据的可用性。由于没有一个现有数据集可满足条件，本文通过整合若干个图像标注源而成一个新数据集――Broden+。--Broden+新数据集构建的基础是 Broadly Densely Labeled Dataset（Broden），这是一个包含不同视觉概念的混杂数据集。但是由于其设计初衷，Broden 并不适用于分割网络的训练。为此本文从 4 个方面做出优化，得到了 Broden+ 数据集：1-去掉不同数据集的相似概念；2-只保留至少出现在 50 张图像以上、在整个数据集中至少包含 50000 像素的物体类别；3-手动去掉 OpenSurfaces 数据集中的下采样标签；4-把 ADE20K 数据集中 400+ 个场景标签映射到 Places 数据集中的 365 个标签。这样，经过标准化工作而得到的新数据集共包含 57095 张图像，其中 22210 张来自 ADE20K，10103 张来自 Pascal-Context 和 Pascal-Part，19142 张来自 OpenSurfaces，5640 张来自DTD，如表 1 所示。图 3 是一些实例。表 1：Broden+ 数据集中每一标签类型的统计信息，其评估指标也已给出。图 3：Broden+ 数据集实例。--指标一般来讲，分割任务的衡量指标是 P.A. 和 mIoU。为了解决 mIoU 不计数未标注区域的预测的问题，使其更适合部分分割等任务，本文在一些特定任务中使用 mIoU，但也计数背景区域的预测，这一新指标称为 mIoU-bg。具体而言，对于借助 ADE20K，Pascal-Context，OpenSurfaces 数据集的物体和材质解析任务，使用评估标准 P.A. 和 mIoU；对于物体部分，则使用 P.A. 和 mIoU-bg；对于场景和纹理分类，则使用 top-1 精度。UPerNet--背景当前最优的分割网络主要基于全卷积网络（FCN）。由于缺乏足够的训练样本，分割网络通常初始化自针对图像分类任务的预训练网络。为使语义分割实现高分辨率预测，dilated conv 技术被提出，在缓解下采样副作用的同时，保证了感受野的扩充率；使用这一技术的网络也成为了语义分割任务的标准范式。但是针对本文提出的 UPP 任务，这一方法有 2 个缺陷：1-最近提出的深度卷积网络虽在图像分类和语义分割任务中大获成功，但层数往往达到数十、数百层；其设计结构如此复杂，以至于在网络早期阶段由于感受野较大和计算复杂度较低的原因，下采样率快速增长。2-这种网络只利用了其中最深的特征图。使用高级语义特征分割高级概念（比如物体）是合理的，但是并不适合分割多层次的感知属性，尤其是低级概念（比如纹理、材质）。有鉴于此，本文提出了多任务新框架 UPerNet。--架构图 4：UPerNet 架构图。UPerNet（Unified Perceptual Parsing Network）网络架构如图 4 所示，它基于特征金字塔网络（FPN）。尽管理论上讲，深度卷积网络的感受野足够大，但实际可用的要小很多。为克服这一问题，本文把 PSPNet 中的金字塔池化模块（PPM）用于骨干网络的最后一层，在其被馈送至 FPN 自上而下的分支之前。结果实验证明，在带来有效的全局先验表征方面，PPM 和 FPN 架构是高度一致的。本文使用多个语义层次的特征。由于图像级信息更适合场景分类，Scene head 直接被附加到 PPM 模块之后的特征图。Object head 和 Part head 被附加到与来自 FPN 的所有层相融合的特征图。Material head 被附加到 FPN 中带有最高分辨率的特征图。Texture 被附加到 ResNet 中的 Res-2 模块，并在整个网络完成其他任务的训练之后进行优化，这一设计背后的原因有 3 个：1-纹理是最低级的感知属性，因此它纯粹基于明显的特征，无需任何高级的信息；2-正确预测纹理的核心特征是在训练其他任务时被隐式学习的；3-这一分支的感受野需要足够小，因此当一张正常大小的图像输入网络，它可以预测不同区域的不同标签。实验本节首先给出了 UPerNet 在原始语义分割任务和 UPP 任务上的量化研究，接着将这一框架用于发掘场景理解背后的视觉常识知识。--结果整体架构。为证明 UPerNet 在语义分割上的有效性，本文给出了不同设置下借助物体标注在 ADE20K 数据集上的结果，如表 2 所示。表 2：ADE20K 数据集上该方法（基于ResNet-50）与当前最优方法的对比分析。混杂标注的多任务学习。本文给出了在分离或融合的不同标注集上的训练结果。表 3：UPerNet 在 Broden+ 数据集上的结果。量化结果。本文给出了 UPerNet 的量化结果。如图 5 所示。UPerNet 可统一结构性视觉知识，同时有效预测层级输出。图 5：UPerNet（ResNet-50）在验证集上的预测。--视觉知识UPP 要求模型从一张图像之中识别尽可能多的视觉概念，如果模型成功做到这一点，就可以发现隐藏在现实世界之下的丰富视觉知识，回答诸如“这个杯子的材质是什么”的问题，有助于机器视觉系统更好理解周遭世界。本节证明，在 Broden+ 数据集上训练的 UPerNet 可发现多层次的结构性知识。研究者以分层的方式定义了若干类关系，如表 4 所示。表 4：UPerNet 发掘的视觉知识。结论本文定义了名为统一感知解析（UPP）的识别任务，从场景、物体、部分、材质到纹理，其试图一次性解析图像的多层次视觉概念。一个多任务网络和处理混杂标注的训练策略被开发和测试。本文进而利用已训练的网络发现场景之中的视觉知识。参考文献Peng, C., Xiao, T., Li, Z., Jiang, Y., Zhang, X., Jia, K., Yu, G., Sun, J.: Megdet:A large mini-batch object detector. arXiv preprint arXiv:1711.07240 (2017)Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In:IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). (2017) 2881C2890Chen, L.C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L.: Deeplab:Semantic image segmentation with deep convolutional nets, atrous convolution,and fully connected crfs. arXiv preprint arXiv:1606.00915 (2016)Kirillov, A., He, K., Girshick, R., Dollr, P.: Mscoco challenge 2017: stuff segmentation,team fair. (2017)Zhou, B., Lapedriza, A., Xiao, J., Torralba, A., Oliva, A.: Learning deep features for scene recognition using places database. In: Advances in neural information processing systems. (2014) 487-495
人脸识别公司在未来城市建设当中的作用	中国城市未来的建设发展，更多的体现在于科技创新带来的改变，在这个过程当中，人工智能起到了非常重要的作用。对于人脸识别公司来说，未来的城市建设将会呈现出一个更有利于他们发展的格局，不仅是因为城市发展的需求，同时还是因为来自于政府等相关部门的大力支持。在科技创新的过程当中，更多的人工智能元素将会诞生，同时这些东西将会进一步的影响到整个城市生活的状态。更多人相信，未来的城市将会是一个人工智能的时代，而人脸识别公司在这个过程当中将会起到中流砥柱的作用，因为如果没有他们的话，科技创新与人工智能的发展步伐就不可能启动，也不可能为城市建设带来更大的贡献。据悉，国家目前针对未来城市建设的发展需求开放，并且定制的一些比较利好人脸识别公司发展的政策，借助政策的东风，更加多的科技型的公司将会建立，另外针对一部分已经拥有了成熟技术及经验的人脸识别公司，他们也将会在这一股政策的东风之下，不断的前行，开发出更加多有利于城市发展的项目，并把这些人工智能相关的产品投放到不同的应用场合里面，对整个城市发展带来积极的影响。比如现在我们经常都会在公共场合接触到的人脸识别闸机，在工作场所里面遇到的签到系统等等，其实这些科技产品都是来源于人工智能企业开发。这些方案都是基于智慧城市或者是智能办公室的基础上面打造出来的，通过科技创新来赋予这些设备或者硬件更多智能元素，让他们可以替代传统的人力资源，更高效的完成企业或者用户的需求。据了解这些带着智能元素的项目或者硬件设备产品，未来将会在城市建设发展当中起着重要的作用，他们将会不断的改变中国人的生活现状，成为引领智慧城市发展的重要力量。未来的城市发展速度将会越来越快，需求也将会越来越多元化，对于人脸识别公司而言，如何把握政策的东风，怎样借助国家相关部门的支持方案，为公司带来更多利润，并为整个城市建设带来更积极的贡献，这都将会是一个值得思考的问题，也将会是这些科技型的公司必须要面对的挑战。
ECCV 2018 | 旷视科技Oral论文解读：IoU-Net让目标检测用上定位置信度	全球计算机视觉三大顶会之一 ECCV 2018 （European Conference on Computer Vision）即将于9月8 -14日在德国慕尼黑拉开帷幕。届时，旷视首席科学家孙剑博士将带领团队远赴盛会，助力计算机视觉技术的交流与落地。论文名称：《Acquisition of Localization Confidence for Accurate Object Detection》论文链接：https://arxiv.org/abs/1807.11590代码链接：https://github.com/vacancy/PreciseRoIPooling导语现代基于 CNN 的目标检测器依靠边界框回归和非极大抑制（NMS）来定位目标，其对类别标签的预测概率可以天然反映每个框的分类置信度，然而却缺失了框的定位置信度。这使得原本定位准确的边界框会在迭代回归的过程中偏离目标，又或甚至在 NMS 过程中受到抑制。为此，旷视科技提出 IoU-Net，可学习预测每个检测得到的边界框和与之匹配的目标之间的 IoU 作为该框的定位置信度。利用这种定位置信度，检测器能确保定位更准确的边界框在 NMS 过程中被保留下来，从而改进 NMS 过程。此外，将预测得到的 IoU 作为优化目标，一种基于优化的边界框修正方法也同时被提出。目标检测技术（计算机视觉的基石之一）的这一底层的原创性突破，不仅将优化上层技术的发展，还将为技术落地带来有益影响，比如视频智能理解、智能地产和零售以及智能相机等，推动数字中国、城市大脑、无人超市等产业的进步。背景目标检测是很多下游视觉应用的前提基础，比如实例分割、人体骨架绘制、人脸识别和高级目标推理。它结合了目标分类和定位两个任务。现代大多数目标检测器的框架是 two-stage，其中目标检测被定义为一个多任务学习问题：1）区分前景物体框与背景并为它们分配适当的类别标签；2）回归一组系数使得最大化检测框和目标框之间的交并比（IoU）或其它指标。最后，通过一个 NMS 过程移除冗余的边界框（对同一目标的重复检测）。在这样的检测流程中，分类和定位被用不同的方法解决。具体来说，给定一个提议框（proposal），每个类别标签的概率可自然而然地用作该 proposal 的“分类置信度”，而边界框回归模块却只是预测了针对该 proposal 的变换系数，以拟合目标物体的位置。换而言之，这个流程缺失了“定位置信度”。定位置信度的缺失带来了两个缺点：1-在抑制重复检测时，由于定位置信度的缺失，分类分数通常被用作检测框排名的指标。在图 1(a) 中，研究者展示了一组案例，其中有更高分类置信度的检测框却与其对应的目标物体有更小的重叠。就像 Gresham 著名的 “劣币驱逐良币”理论一样，分类置信度和定位准确度之间的不匹配可能导致定位更准确的边界框在 NMS 过程中反被更不准确的边界框抑制。2-缺乏定位置信度使得被广泛使用的边界框回归方法缺少可解释性或可预测性。举个例子，之前的研究 [3] 报告了迭代式边界框回归的非单调性。也就是说，如果多次应用边界框回归，可能有损输入边界框的定位效果（见图 1(b)）。图 1：由缺乏定位置信度所造成的两个缺点的图示。这些示例选自 MS-COCO minival。（a）分类置信度和定位准确度不对齐的示例。黄框表示真实目标框，红框和绿框都是 FPN 所得到的检测结果。定位置信度由研究者提出的 IoU-Net 计算得到。使用分类置信度作为排名指标，会导致定位更准确的边界框（绿框）在传统的 NMS 流程被错误地删去。（b）在迭代式边界框回归中非单调定位的示例。设计思想在这篇论文中，研究者引入了 IoU-Net，其能预测检测到的边界框和它们对应的真实目标框之间的 IoU，使得该网络能像其分类模块一样，对检测框的定位精确程度有所掌握。这种简单的预测IoU值能为研究者提供前述问题的新解决方案：1-IoU 是定位准确度的一个天然标准。研究者可以使用预测得到的 IoU 替代分类置信度作为 NMS 中的排名依据。这种技术被称为 IoU 引导式 NMS（IoU-guided NMS），可消除由误导性的分类置信度所造成的抑制错误。2-研究者提出了一种基于优化的边界框修正流程，可与传统的基于回归的边界框修正方法分庭抗礼。在推理期间，预测得到的 IoU 可用作优化目标，也可作为定位置信度的可解释性指示量。研究者提出的精准 RoI 池化层（Precise RoI Pooling layer）让研究者可通过梯度上升求解 IoU 优化。研究者表明，相比于基于回归的方法，基于优化的边界框修正方法在实验中能实现定位准确度的单调提升。这种方法完全兼容并可整合进各种不同的基于 CNN 的检测器。边界框修正图示：上行是传统方法的结果，下行是本文提出方法的结果。目标定位本节探讨了目标定位的两个缺点：分类置信度与定位精确度之间的不匹配以及非单调边界框回归。标准的 FPN 检测器在 MS-COCO trainval35k 上被训练以最为基线，并在 minival 上测试以供进一步研究。--分类&定位准确度不匹配图 2：边界框与其对应目标框的 IoU 与分类/定位置信度之间的关系。对那些与目标框的 IoU 高于 0.5 的检测框，其 Pearson 相关系数为 (a) 0.217 和 (b) 0.617。（a）分类置信度表示了一个边界框的类别，但不能被解读成定位准确度。（b）为了解决这个问题，研究者提出了 IoU-Net 来预测每个检测到的边界框的定位置信度，即其与对应的目标框的 IoU。图3：经过 NMS 之后得到的正例边界框的数量，根据它们与对应的目标框之间的 IoU 分组。在传统 NMS 中（蓝色条形图），定位准确的边界框中有很大一部分会被错误抑制，这是由分类置信度和定位准确度之间的不匹配造成的，而 IoU-guided NMS（黄色条形图）则能保留定位更准确的边界框。--非单调边界框回归图 4：基于优化的与基于回归的 BBox 优化。如上图所示，（a）表示在 FPN 中比较。当迭代式地应用回归时，检测结果的 AP（平均精度）首先会提升，但会在之后的迭代中快速降低。（b）表示在 Cascade R-CNN 中比较。迭代 0、1、2 表示 Cascade R-CNN 中的第 1、2、3 个回归阶段。在多轮回归之后，AP 稍有下降，而基于优化的方法则进一步将 AP 提高了 0.8%。IoU-Net为了定量地分析 IoU 预测的有效性，研究者首先提出用于训练 IoU 预测器的方法。接着分别展示了如何将 IoU 预测器用于 NMS 和边界框修正的方法。最后，研究者将 IoU 预测器整合进了 FPN 等现有的目标检测器中。--学习预测 IoU图 5：IoU-Net 的完整架构。在上图中，输入图像首先输入一个 FPN 骨干网络。然后 IoU 预测器读取这个 FPN 骨干网络的输出特征。研究者用 PrRoI 池化层替代了 RoI 池化层。这个 IoU 预测器与 R-CNN 分支有相似的结果。虚线框内的模块能构成一个单独的 IoU-Net。--IoU-guided NMS算法 1：IoU-guided NMS。在这个算法中，分类置信度和定位置信度是解开的（disentangled）。研究者使用定位置信度（预测得到的 IoU）来给所有被检测到的边界框排名，然后基于一个类似聚类的规则来更新分类置信度。--边界框修正作为优化过程算法 2：基于优化的边界框修正。精准 RoI 池化（Precise RoI Pooling）。研究者引入了精准 RoI 池化（简写成：PrRoI 池化）来助力研究者的边界框修正。其没有任何坐标量化，而且在边界框坐标上有连续梯度。给定 RoI/PrRoI 池化前的特征图 F（比如，来自 ResNet-50 中的 Conv4），设 wi,j 是该特征图上一个离散位置 (i,j) 处的特征。使用双线性插值，这个离散的特征图可以被视为在任意连续坐标 (x,y) 处都是连续的：其中，??是插值系数。然后将 RoI 的一个 bin 表示为??，其中 (x_1,y_1) 和 (x_2,y_2) 分别是左上角和右下角的连续坐标。给定 bin 和特征图 F，研究者通过计算一个二阶积分来执行池化（比如平均池化）：为更便于理解，研究者在图 6 中可视化了 RoI 池化、RoI Align 和研究者的 PrRoI 池化：在传统的 RoI 池化中，连续坐标首先需要被量化（quantization），以计算该 bin 中激活的和；为了消除量化误差，在 RoI Align 中，会采样该 bin 中 N=4 个连续点，表示成 (a_i,b_i)，而池化就是在这些采样的点上执行的。RoI Align 中的 N 是预定义的，而且不能根据 bin 的大小进行调整；与此不同，研究者提出的 PrRoI 池化是直接基于连续特征图计算二阶积分。图 6：RoI 池化、RoI Align 和 PrRoI 池化的图示。--联合训练这种 IoU 预测器可集成到标准的 FPN 流程中，以进行端到端的训练和推理。为了清楚说明，研究者将用于图像特征提取的 CNN 架构称为骨干（backbone），将应用于各个 RoI 的模块称为头（head）。如图 5 所示，这个 IoU-Net 使用了 ResNet-FPN 作为骨干网络，其架构是自上而下的，可构建特征金字塔（feature pyramid）。FPN 能根据 RoI 的特征的比例从这个特征金字塔的不同层级提取这些 RoI 的特征。其中原来的 RoI 池化层被换成了精准 RoI 池化层。至于该网络的头，这个 IoU 预测器根据来自骨干网络的同一视觉特征而与 R-CNN 分支（包括分类和边界框回归）并行工作。实验研究者在有 80 个类别的 MS-COCO 检测数据集上进行了实验。具体来讲，在 8 万张训练图像和 3.5 万张验证图像的并集（trainval35k）上训练了模型，并在包含 5000 张验证图像的集合（minival）上评估了模型。为验证该方法，研究者与目标检测器分开而训练了一个独立的 IoU-Net（没有 R-CNN 模块）。IoU-guided NMS 和基于优化的边界框修正被应用在了检测结果上。--IoU-guided NMS表 1 总结了不同 NMS 方法的表现。尽管 Soft-NMS 能保留更多边界框（其中没有真正的“抑制”），但 IoU-guided NMS 还能通过改善检测到的边界框的定位来提升结果。因此，在高 IoU 指标（比如 AP_90）上，IoU-guided NMS 显著优于基准方法。表 1：IoU 引导式 NMS 与其它 NMS 方法的比较。通过保留定位准确的边界框，IoU-guided NMS 在具有高匹配阈值的 AP（比如 AP_90）上的表现显著更优。图 7：在匹配检测到的边界框与真实目标框的不同 IoU 阈值下，不同 NMS 方法的召回率曲线。研究者提供了 No-NMS（不抑制边界框）作为召回率曲线的上限。研究者提出的 IoU-NMS 有更高的召回率，并且在高 IoU 阈值（比如 0.8）下能有效收窄与上限的差距。--基于优化的边界框修正研究者提出的基于优化的边界框修正与大多数基于 CNN 的目标检测器都兼容，如表 2 所示。将这种边界框修正方法应用在原来的使用单独 IoU-Net 的流程之后还能通过更准确地定位目标而进一步提升表现。即使是对有三级边界框回归运算的 Cascade R-CNN，这种改进方法能进一步将 AP_90 提升 2.8%，将整体 AP 提升 0.8%。表 2：基于优化的边界框修正能进一步提升多种基于 CNN 的目标检测器的表现。--联合优化IoU-Net 可与目标检测框架一起并行地端到端优化。研究者发现，将 IoU 预测器添加到网络中有助于网络学习更具判别性的特征，这能分别将 ResNet50-FPN 和 ResNet101-FPN 的整体 AP 提升 0.6% 和 0.4%。IoU-guided NMS 和边界框修正还能进一步提升表现。研究者使用 ResNet101-FPN 得到了 40.6% 的 AP，相比而言基准为 38.5%，提升了 2.1%。表 4 给出了推理速度，表明 IoU-Net 可在计算成本承受范围之内实现检测水平的提升。表 3：在 MS-COCO 上的最终实验结果。IoU-Net 表示嵌入预测器的 ResNet-FPN。在这个 FPN 基准上，研究者实现了约 2% 的 AP 提升。表 4：多种目标检测器在单个 TITAN X GPU 上得到的推理速度。这些模型都有一样的骨干网络 ResNet50-FPN。输入分辨率为 1200x800。所有超参数设置相同。结论本文提出一种用于准确目标定位的全新网络架构 IoU-Net。通过学习预测与对应真实目标的 IoU，IoU-Net 可检测到的边界框的“定位置信度”，实现一种 IoU-guided NMS 流程，从而防止定位更准确的边界框被抑制。IoU-Net 很直观，可轻松集成到多种不同的检测模型中，大幅提升定位准确度。MS-COCO 实验结果表明了该方法的有效性和实际应用潜力。从学术研究的角度，本文指出现代检测流程中存在分类置信度和定位置信度不匹配的问题。更进一步，研究者将边界框修正问题重定义为一个全新的优化问题，并提出优于基于回归方法的解决方案。研究者希望这些新视角可以启迪未来的目标检测工作。参考文献Cai, Z., Vasconcelos, N.: Cascade r-: Delving intoobject detection. arXiv preprint arXiv:1712.00726 (2017)Lin, T.Y., Doll ?ar, P., Girshick, R., He, K., Hariharan, B., Belongie, S.: Feature pyramid networks for object detection. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)He,Dolla ?r.In:Conference on Computer Vision (ICCV) (2017)Lin, T.Y., Doll ?ar, P., Girshick, R., He, K., Hariharan, B., Belongie, S.: Feature pyramid networks for object detection. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)Ren, S., He, K., Girshick, R., Sun, J.: Faster r-: Towards real-time objectwith region proposal networks. In: Advances in neural information processing systems. pp. 91C99 (2015)Wang, X., Xiao, T., Jiang, Y., Shao, S., Sun, J., Shen, C.: Repulsion loss: Detecting pedestrians in a crowd. arXiv preprint arXiv:1711.07752 (2017)
第五届世界互联网大会进入倒计时 旷视科技与你相约乌镇	11月7日至9日，全球互联网领域的目光将再度聚焦美丽的水乡乌镇，共同关注第五届世界互联网大会的召开。与此同时，作为世界互联网大会的重要组成部分，由国家网信办、科技部、工信部和浙江省人民政府共同主办的第五届“互联网之光”博览会，也将于11月6日至10日在乌镇举办。届时，旷视科技也将携多项原创人工智能黑科技亮相本届博览会主场馆，向世界展示中国人工智能技术的创新发展成果。展览时间：2018年11月6日-10日（9:00-17:00，10日9:00-12:00）展览地点：浙江省桐乡市乌镇环河路646号乌镇互联网国际会展中心展区位置：3号馆一层综合展馆 A3-1F-10号第五届世界互联网大会旷视展位设计图第五届世界互联网之光博览会聚焦世界互联网发展趋势和前沿技术，突出展示全球范围内的新产品、新技术、新应用。人工智能，作为引领新一轮科技革命和产业变革的战略性技术，每年都成为博览会上各互联网企业和创新企业的展示热点，而作为以人工智能为核心的行业物联构建者，同时也是全球人工智能领域的领军企业，旷视科技自2015年开始便将自研的先进AI技术和产品带到博览会上做展示。今年，旷视携自身在安防、手机、车载、零售、物流领域的最新原创再度出发，并将与合作伙伴艾迈斯半导体（ams）联合展示智能视觉、智能家居及可穿戴解决方案。在大会即将来临之际，我们先带来一手展品资料先睹为快。一、旷视城市天眼2.0城市天眼系统，是旷视于2015年研发上线的云端智能研判平台，结合大数据与深度学习算法，可实现治安防控数据可视化和轨迹追踪功能。2018年，旷视正式推出城市天眼2.0平台，将自研的人脸识别、行人识别、车辆识别、轨迹追踪、视频结构化等领先的AI视觉技术，与城市安防、城市交通、城市治理中的实际场景需求所结合，提供智能识别公安重点关注人员、交通违章违规行为、城市流动摊贩等服务。在2018年亚欧安防展、北京安博会等多个展会上，旷视城市天眼都成为观众参观体验的焦点。二、端到端智能安防作为行业领先的端到端智能安防产品及解决方案提供商，旷视是最早进入安防领域的人工智能公司。针对安防业务中的典型场景，和“情、指、勤”联动的实战诉求，旷视正在通过“算法、技术、硬件产品、解决方案、数据”全价值链输出，着力打造覆盖全业务流程的端到端解决方案体系，帮助公安用户构建从前端感知，到云端研判，再到终端应用的新型智能安防闭环体系。如今，旷视智能安防已在全国100多城市落地，并成为G20峰会、厦门金砖峰会、海南博鳌论坛、上合组织峰会等国际重大活动的重要安保方案提供商。三、移动端AI解决方案针对手机行业中AI应用浪潮，旷视也于业界率先推出软硬一体的移动端AI感知全栈解决方案，可从算法创新、应用开发、设备制造到解决方案，为行业客户实现AI赋能。目前，旷视基于核心的深度学习和计算机视觉技术一举推出人脸支付、人脸识别解锁、人像光效、人像背景虚化、3D Animoji等一系列移动端 AI?产品，以满足不同手机厂商在人脸解锁、图像增强、相机增强、智能图像和视频处理上的需求，在不到一年时间内已与华为、小米、vivo、OPPO等国内头部手机企业实现深度合作。在本届博览会上，旷视将展示为 OPPO Find X 提供的3D人脸解锁支付及3D人像光效技术，和采用ams模组的智能视觉、智能家居及可穿戴解决方案。此外，旷视全新研发的车载AI视觉解决方案也将亮相于本届博览会。四、智能零售解决方案在零售行业中，旷视针对线下零售场景数据缺失，无法用数据驱动决策的痛点，基于业界领先的计算机视觉算法及物联感知终端体系，自主研发了一套“云服务+智能端”的新零售行业解决方案。可多维度感知并理解顾客的身份属性、行为信息及与货架、商品触发的各类数据，通过对数据的融合分析和深度挖掘，帮助商家提升店务运营人员的能力边界、优化经营策略与供应链管理，以在门店数据化进程中实现降本增效的目的。目前，旷视已经为包括名创优品、鲜生活、银座Mall、小麦铺等零售行业头部企业在内超过 2000 家连锁门店提供了端到端的智能化方案。五、物流仓储机器人解决方案在旷视以AI+IoT赋能城市终端的实践中，对物流行业的数字化、智能化改造成为旷视重点业务之一。依托于旷视强大的机器人、大数据、人工智能等核心技术研发实力，旷视打造的物流仓储机器人解决方案可满足客户仓储分拣、智能搬运等业务需求，提供“机器人+仓储管理系统+数据分析”等综合性解决方案。在物流行业中，旷视已与众多国内知名电商仓储、物流及制造企业达成战略合作伙伴关系，通过构建开放的智能仓储机器人平台，为更多合作伙伴实现降本增效、创造价值。除展示外，旷视也将在11月8日的互联网之光博览会品牌发布活动上（6号馆2层），作《软硬一体创新手机3D解决方案优化》主题发布，我们期待与你相约乌镇！
ECCV 2018 | 旷视科技提出新方法：通过实例级显著性检测和图划分实现弱监督语义分割	全球计算机视觉三大顶会之一 ECCV 2018 （European Conference on Computer Vision）即将于9月8 -14日在德国慕尼黑拉开帷幕。届时，旷视首席科学家孙剑博士将带领团队远赴盛会，助力计算机视觉技术的交流与落地。论文名称：《Associating Inter-Image Salient Instances for Weakly Supervised Semantic Segmentation》论文链接：http://mftp.mmcheng.net/Papers/18ECCVGraphPartition.pdf导语深度学习方法分为有监督学习和无监督学习，前者为深度学习“攻下一座座城池”，硕果累累，而后者则是希望和未来所在。然而，介于两者之间的弱监督学习同样不容忽视，潜力巨大。在本文中，旷视科技和清华大学通过原创性地整合显著性检测和图划分算法等多种技术，提出一种新型弱监督学习方法，加速语义分割发展，推动该技术在自动驾驶、安防、新零售、物流等行业的落地和普及。这一方法的最大技术亮点是既利用的每个显著性实例的内在属性，又挖掘了整个数据集范围内不同显著性实例的相互关系。实验结果表明了该方法的有效性和高效性。正是通过一个个技术难点的攻克，不断积淀，相互共振，促成 AI 原创技术矩阵，形成 AI+IoT 体系，助力旷视科技以非凡科技持续为客户和社会创造最大价值。背景语义分割是计算机视觉领域最为重要的任务之一，其目的是为图像的每个像素标注语义信息。卷积神经网络强大的学习能力使这一领域取得了巨大的进展，但神经网络的训练需要大量的像素级标注的训练数据，比如 PASCAL VOC 和 MS COCO。弱监督语义分割作为一种降低对像素级标注数据需求的新方法，近期备受关注。这一方法只需要诸如关键词（keywords）、边界框（bounding boxes）、线条（scribbles）、点（points）等标注信息，即可轻松完成数据的构建。本文研究的是只有关键词作为标注信息的弱监督框架。在弱监督语义分割中，一个主要挑战是在关键词与相应的语义目标之间建立有效的连接。绝大多数先前方法使用各种低层信息检测器（low-level cue detectors）捕捉像素级信息以从原始图像中生成辅助（proxy）ground-truth。显著性模型和注意力机制都是常用的方法。由于上述方法只给到像素级显著性/注意力信息，很难把不同前景目标目标区分开。因此，判别语义实例的能力尤为关键。随着显著性检测算法的快速发展，一些显著性检测器，比如 MSRNet 和 S^4Net，不仅可以实现显著性区域的像素级预测，还可以提取显著实例。通过借鉴上述实例级显著目标检测器的优点，本文提出利用 S^4Net 从而在早期显著性检测阶段执行实例提取任务，这极大地简化了pipeline，一些由 S^4Net 生成的实例级显著性图像如图 1(b) 所示。图 1：本文方法图示。由于通过显著性检测等低层特征检测器获得的前景不含语义信息，对于多标签训练样本，为每个前景目标分配正确的关键词（标签）是需要解决的重要任务。传统方法处理弱监督问题时，着眼于独立处理每一张图像。本文不仅利用了每个显著性实例的内在特征，而且借助在整个数据集范围内所有显著性实例的语义相互关系，为每个显著性实例分配正确的语义标签，生成 proxy ground-truth。这一算法可以使用图划分建模。设计思想为了利用带有边界框的显著性实例掩码，需要克服两个主要困难。第一，一张图像可能标注多个关键词，因此要解决关键词和显著性实例的对应问题。第二，并不是所有的由显著性实例检测器生成的实例都是在语义上有意义的，纳入这些噪声实例会影响后续操作的准确性。因为识别和去除这些噪声实例在本文方法中很重要。上述两个困难都可以表示为标签分配问题，即分别为语义实例和噪声实例打上正确的标签。本文在整个训练集内，综合考虑一个显著性实例的内在信息和显著性实例间的相互关系。通过注意力机制等方法，仅仅考虑 RoI 的内部信息，即显著性实例的本质特征，对显著性实例赋予正确的标签也是可能的。但是，除了每个 RoI 的内在属性，每个显著性实例之间还有语义上的相互关系：同一类别的显著性实例通常有着相似的语义特征。将其考虑在内对标签分配很重要。具体而言，一方面，这一新框架包含一个注意力模块，基于内在属性预测某个显著性实例属于各个标签的概率；另一方面，通过一个提取器为每个显著性实例预测语义特征，以获取语义关系。在语义上相似的显著性实例有着近似的语义特征向量。基于语义特征可以得到一张相似性图，其中顶点表示显著性实例，边权重记录一对显著性实例之间的语义相似性。本文通过一个图划分算法把图分为若干个子图，其中每个子图表示一个具体的类别。图划分流程被建模为一个混合整数二次规划问题（MIQP），从而获得一个全局最优解。其目标是使每个子图内部的顶点尽可能相似。图划分过程也会把显著性实例的内在属性考虑在内。本方法给出了高质量的 proxy-ground-truth 数据，可训练全监督语义分割模型。当在 DeepLab 上处理语义分割任务之时，本文方法在 PASCAL VOC 2012 测试集上 mIoU 为 65.6%，优于当前最优方法。在像素级语义分割之外，本文还利用实例级 proxy-ground-truth 数据训练了实例级分割模型，首次证明了只使用关键词标注的弱监督框架进行实例级分割的能力。网络架构在这一部分，首先给出 pipeline 概述，接着讨论网络结构和标签分配算法。该框架如图 2 所示。绝大多数依赖于像素级线索（比如显著性、边缘、注意力图）的先前工作把实例判别作为一项关键任务。但是，随着深度学习的发展，显著性检测器可以预测显著性图以及实例边界框。在给定只标有关键词的训练图像的情况下，研究者借助实例级显著性分割网络 S^4Net 从每张图像中提取显著性实例。每个显著性实例有一个边界框和一个掩码，表明图像中有一个视觉可见的前景目标。这些显著性实例是类别不可知的，因此提取器 S^4Net 无需针对本文训练集进行训练。尽管显著性实例包含训练分割掩码的 ground-truth 掩码，但是使用这些显著性实例训练分割网络有两个主要的限制。首先，一张图像可以标注多个关键词。其次，由 S^4Net 检测的实例不一定在训练集的类别之中。本文把这些显著性实例看作是噪声实例，消除它们是本文 pipeline 不可或缺的一部分。两个限制可通过解决标签分配问题而解决，其中研究者把显著性实例与基于图像关键词的正确标签相联，并把其他实例标为噪音。图 2：Pipeline。本文 pipeline 同时考虑了一个单一区域的内在属性和所有显著性实例之间的关系。一个分类网络输出的分值图中，目标所在区域（像素）内会有对正确的类别的较强响应。因此，在类激活映射（class activation mapping/CAM）的启发下，本文利用注意力模块直接根据其内在属性识别显著性实例的标签。现有弱监督分割工作的一个弱点是一张张处理训练集，忽略了整个训练集中显著性实例之间的关系。但是，属于同一类别的显著性实例有着相似的语义信息，可在标签分配中发挥作用。本文架构提取每个显著性实例的语义特征，语义信息相似的区域有着相似的语义特征，并由此构建一个相似性图。标签分配现在变成了一个图划分问题，同时利用了单一显著性实例的内在属性和所有显著性实例的整体关系。实验本节展示了该方法在 PASCAL VOC 2012 语义分割基准上的结果，同时与一些当前最佳方法做了对比。结果表明该框架大幅超出所有现有的弱监督方法。本文同样也通过一系列实验分析每一组件的重要性。本文进而给出了在 MS COCO 实例分割任务上的初步结果。表 3 给出了在 PASCAL VOC 2012 验证集和测试集上新的当前最优结果。具体而言，相较于 Mining Pixels 的基线结果，该方法在测试集和验证集上分别实现了 6% 和 5.8% 的提升。另外，值得注意的是，该方法甚至优于（以线条和点的形式）带有额外监督的其他方法。除了语义分割结果，本文还展示了只使用关键词的弱监督方法的实例分割结果。表 4 把本文方法与当前最优的全监督方法进行了结果对比。只借助带有关键词的原始 RGB 图像，即可实现实例级分割。表 3：本文方法在 PASCAL VOC 2012 验证集和测试集上的像素级分割结果及与现有最佳方法的对比。表 4：本文方法在 COCO 测试集上的实例分割结果及对比。结论本文提出一个全新的弱监督分割框架，旨在基于提取自训练图像的显著性实例和被分配的标签，生成精确的 proxy-ground-truth 数据。本文把显著性实例引入弱监督分割，极大地简化了现有工作中的目标判别流程，并使得该框架可执行实例级分割。本文把标签分配任务建模为一个网络划分问题，通过整数二次规划对这一问题进行求解。为提升标签分配的准确性，来自单一的显著性实例的内在信息和整个数据集中所有目标的关系同时被考虑在内。实验表明该方法在 PASCAL VOC 2012 语义分割基准上取得了新的当前最优结果，并首次展示了只有关键词作为标注信息的弱监督方法在 MS COCO 实例级语义分割任务中所取得的结果。参考文献Lin, D., Dai, J., Jia, J., He, K., Sun, J.:: Scribble-supervised convolutionalfor semantic segmentation. In: CVPR. (2016) 1, 4, 13Fan, R., Hou, Q., Cheng, M.M., Mu, T.J., Hu, S.M.: s4:salient-instance. arXiv preprint arXiv:1711.07618 (2017) 2, 4, 5Li, G., Xie, Y., Lin, L., Yu, Y.: Instance-level salient object segmentation. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE (2017) 247C256 2Bliek1u ?, C., Bonami, P., Lodi, A.: Solving mixed-integer quadratic programming problems with-: a progress report. In: Proceedings of the twenty-sixth RAMP symposium. (2014) 16C17 3, 9, 14Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.: Learning deep features for discriminative localization. In: CVPR. (2016) 4, 5He, K., Gkioxari, G., Dolla ?r, P., Girshick, R.: Mask r-. In: Computer Vision (ICCV), 2017 IEEE International Conference on, IEEE (2017) 2980C2988 3, 5, 13
人工智能：解锁智慧城市，未来已来。	一、中国人工智能城市发展概况在有限的城市空间里，打造无限智能化城市效用中国的城市建设经历20世纪90年代至今的高速发展，逐步进入城市转型发展的新常态。城市建设目标从追求规模和经济效益为主开始转向对生态、人文、社会公平和可持续性等立体的价值追求，尤其强调以人为本发展目标，城市向着“智慧化”建设发展；随着人工智能技术条件越来越成熟条件，城市管理形成以数据为驱动的城市决策机制，从顶层设计着手，自上而下的”AI化”使城市功能和产业转型更加显著，为城市创造以技术为驱动的商业价值，最终形成一个多元化的有机生态城市系统。以人工智能为首的智联网发展是智慧城市下一阶段的关键早在90年代，IBM首次提出“智慧城市”概念后，中国也在1995年启动数字城市建设，这是中国智慧城市的1.0版本；随着2008年“智慧地球”概念的提出，中国智慧城市建设再次进入到3.0感知智慧城市时代；在2013年，WiFi、3G/4G的网络传输与云计算、大数据的后端数据存储、处理与分析的技术进步下，开启了4.0认知智慧城市时代；在不久的将来，数据积累以及传输带宽和速度的再次腾飞，使得智慧城市达到整体架构协同管理，“人工智能城市”的时代也将到来。政府鼓励人工智能发展，将大力辅助未来城市建设政府在近三年时间密集出台鼓励人工智能技术发展的政策，说明十分重视此次技术发展的机遇，从大力促成中国到2030年成为世界人工智能创新中心的决心可见，希望中国能够“赶得上”这一次的技术革命，而不再仅仅是“不掉队”的要求。而中国城市的政策方向则回归以人为本的的核心，城市的发展都围绕着“高效、惠民、可持续发展”理念，让城市建设迎来转型升级的重大机遇。未来，城市经济结构升级依赖科技创新带来经济动力中国的GDP十年来成倍增长，而国家中心城市的整体创新效率提升水平并不显著。北京、武汉、郑州较十年前的创新效率水平有明显提升，其他城市则维持不变甚至有所下滑。可见各大城市目前创新投入和产出都未能跟上经济发展的步伐，说明经济结构当中科学技术提升带来的收益占比低，未来应该重视提高创新效率的投入（人才、资金、技术……），以及重点考察创新带来的经济效益。迫在眉睫：解决有限城市空间的效率最优化问题中国城镇人口在2011年首次超过乡村人口，未来区域城镇化将会是国家发展战略的重要部署；2015年全国城市建设与2008年相比，不足十年时间，城市建成区面积增长43.5%，道路长度增长40.4%，而这一切都发生在城区面积仅增长7.7%，公共交通系统运营车辆增长了21.7%的基础上。在人口进一步密集（城市人口密度增长15.3%）的情况下，“大城市病”――交通拥堵、空气污染、基础设施不足等问题日益严峻，如何在有限的空间下创造更高的城市效率、更优的城市运作、更适合居住的城市环境……成为了国内城市管理迫切解决的难题。中国监控摄像头覆盖面不足，密度远低于英美2017年国家官方数据公布“中国天网”摄像头达2000万个，但对于将近20万平方公里的城区面积来说，摄像头的覆盖面与数量是凤毛麟角；从摄像头数量/千人的维度来看，中国城市摄像头密度平均水平仅达英美的20%-30%，而完善的监控系统是保障城市治安的有力手段，因此，监控摄像头建设工程任重道远；未来，尤其是二线及以下城市的监控摄像头布防发展潜力巨大。人工智能的发展历程二十世纪五十年代到七十年代初，那时人们以为只要能赋予机器逻辑推理能力，机器就能具有智能，人工智能研究处于“推理期”。接着，人们意识到人类之所以能够判断、决策，除了推理能力以外，还需要知识，因此人工智能研究在二十世纪七十年代进入了“知识期”，大量专家系统在此时诞生。随着研究向前进展，专家发现人类知识无穷无尽，并且有些知识本身难以总结再交给计算机，于是一些学者诞生了将知识学习能力赋予计算机本身的想法。发展到二十世纪八十年代，机器学习真正成为一个独立的学科领域、相关技术层出不穷。进入2010年后相继在语音识别、计算机视觉领域取得重大进展。2016年让人工智能在学术界、工业界、媒体界等社会各界引起广泛关注的AlphaGo 的背后，也是深度强化学习和蒙特卡洛树搜索的结合。机智过人还是技不如人？经过海量数据训练，人工智能可在边界清晰的领域内游刃有余，只是与可在开放环境下对变化中的事物不断学习进而适应的人类智能相比，机器在面对超过固定规则设置的罕见场景时，往往不知所措，鲁棒性有待提高。尽管如此，城市发展建设的方方面面都有大量的潜在的可供现有技术能力来升级改造的空间，比如机器的感知、认知、大数据处理以及运动控制等方面取得的能力突破来融合。二、人工智能在城市发展的应用及场景2017年是人工智能的应用元年，未来将有更多城市场景落地AI+安防：计算机视觉+深度学习技术是智能化视频升级的必要条件上千万的摄像头和庞大的监控网络，瞬间就会产生海量监控视频数据，从海量视频数据中高效提取出有效信息，就成为智能视频监控技术的关键。以一个一万路视频规模的城市为例，每月产生12PB 的视频数据量，在这样量级资源中找到目标人员、车辆宛如大海捞针，然而通过人工智能算法，则可自动抓取视频中的目标图片，并提取其语义化的属性数据以及可用来比对检索的特征数据，每月数据大概为仅15亿条，而存储容量下降到300TB左右，即可实现秒级检索，并刻画目标的轨迹、进行行为分析。AI+交通：人类对车辆的控制最终会接近零，实现无人驾驶场景驾驶的进化过程正是自动智能化交通的演变踪迹：现阶段，辅助驾驶的各项功能相对比较成熟，无论是测试还是实际开放环境表现都比较稳定；而自动驾驶的限定场景也有望在未来三年落地，主要落地的是环境相对简单、封闭或乘车人安全有保障的场景，未来，无人驾驶形态还需要通过大量数据积累、校对和测试，以及技术的突破与零部件量产而带来成本下降。AI+身份验证：AI身份验证已显著超越人力身份验证效率由政府组建的政务云平台，为城市管理打通了信息与数据的“孤岛”状态；在智能政务多个场景中，由于而人力验证有效时间是半小时轮岗，因此，身份验证广泛应用于各类识别身份的节点。例如：基于人脸特征信息进行身份识别的生物识别技术，随着深度学习带来的突破，让机器根据训练数据集达到拥有自我学习的能力，最终掌握“人脸”的概念。AI+零售：实体零售智能化是对抗电商零售的唯一出路实体零售需要抓住“新零售”转型升级的机遇，打造信息化的实体店并建立立体数据库，从而达到在更好服务顾客的情况下控制或缩减成本，提升实体零售的竞争力。实体零售可以从各类访问数据入手，在店铺中实时监控、快速捕获消费者的喜恶并进行精准分析，实现智能化运营与管理。AI+娱乐与生活：增强现实技术在图像视频等泛娱乐场景中不断创造价值娱乐与生活市场空间较大，我国智能手机用户对新鲜事物的接受程度较高，并且乐意使用新技术来提升现有产品的体验，短视频与美颜滤镜的瞬间火爆印证了这个观点。目前，增强现实技术主要应用在个人移动设备上的图像视频泛娱乐场景，未来，在硬件设备的升级迭代下，增强现实技术将带来更广阔的商业价值。三、中国人工智能城市未来发展展望随着城市的不断升级转型，对人工智能技术需求越来越大在第四次信息革命的推动下，城市-智慧城市-人工智能城市的不断迭代升级，人工智能技术在城市建设当中越来越重要；从信息化-联网+感知-自主智能化，越来越重视技术革新带来的升级体验；艾瑞认为：未来，城市管理当中人类参与管理与决策将越来越少，最终达到城市自主智能化管理的效果，从而实现高效、安全、节能、可持续发展的城市发展目标。日益完善的ICT架构将加速城市迭代发展技术升级也为城市治理提供了“智慧”决策支撑，从数字城市到人工智能城市，ICT（Information Communication Technology）的完善推动着城市的迭代发展，以云计算、大数据、物联网、通讯为基础设施，人工智能技术在城市发展当中提供了分析、调配、管理、预判的功能；艾瑞认为：在技术和基础设施不断升级的 ICT架构下，提高城市运作效率、更好的居住体验将会是科技改变生活的显著效果；而在这个过程中的每一个环节都将蕴藏极大的商业价值。
人脸识别算法在城市安防当中的重要应用	在中国的一二线城市，监控摄像头的布局密度已经达到了发达国家的一半以上，但是二级以下城市的监控摄像头布局数量却远远不足以支撑未来城市建设的发展，而智能完善的监控系统却能对城市治理、治安维稳发挥巨大的积极作用，因而监控摄像头市场巨大且富有潜力。值得一提的是，在建设升级监控摄像头工程的过程中，人脸识别算法的应用是整个智能化过程中关键的一环。人脸识别算法在监控系统的建立当中肩负着收集、传输、反馈数据的功能。首先通过前端设备记录下行人数据，移动终端设备便能实时的完成识别和结构化过程，接着将视频流和已标注数据传输回后台进行进一步解码处理，并将最终结果传输回流，为管理人员下达指令提出参考。设想所有过程都由人工完成，则必然造成人力物力的大量浪费，所以在城市安防系统建立的过程当中，在人脸识别算法的基础上面架构出更加完善的监控系统，通过识别技术来进一步的得到监测人员想要得到的图像或者视频信息，将成为解决城市安防所需要的各种信息和问题的最优解。在具体运作的过程当中，在城市监控系统当中，一个摄像头系统可以反馈回来非常多的信息，其中包括图像视频等等，从千变万化而且资源丰富的视频素材当中找出需要的人物或者是图像信息的话，就需要利用到识别算法。通过人脸识别算法，就可以从丰富的大量的视频素材当中筛选出目标人物或者是需要的图像信息，为侦查带来一定的帮助。这一点对于城市安防，尤其是公安在追捕逃犯或者嫌疑人的过程当中，能够带来相当不错的辅助作用。当然，人脸识别算法的作用不仅仅如此，不但可以被运用到图像识别或者是监控识别上面，同时还可以被运用到城市安防的各个领域里面，并且发挥出更加有用的作用。在未来的城市建设当中，尤其是在安防项目的落实中，相关的人脸识别算法也将会被继续运用和拓展，成为智能城市在分析数据，反馈实时信息过程当中的重要的武器。通过人脸识别算法更加多潜在的城市的危害，都将会被提前发现，城市居民的安全保障也能够得到进一步的提升。随着科技的发展，未来的人脸识别算法也将会越来越复杂，但是它也将会以一种更简单直观的形式被利用到城市安防系统的建设当中。因为只有这样，这种技术才可以为人类所用，为人类社会造福。
CeMAT ASIA | AI 正当时！ 旷视艾瑞思机器人新品演绎智慧物流的未来	11月6日-11月9日，亚太地区最受瞩目的年度物流技术盛会――亚洲国际物流技术与运输系统展览会CeMAT ASIA 2018即将在沪盛大举行。作为行业领先的智能物流机器人解决方案供应商，旷视艾瑞思将向业界展示多款应用于物流仓储、智能工厂的智能搬运机器人产品和解决方案，并隆重推出业内首款智能机器人开放平台，敬请关注！活动时间：11月6日-11月9日活动地点：上海新国际博览中心W3馆C1展区关于 CeMAT ASIACeMAT ASIA 是中国乃至亚洲最大的物流技术装备展览会，18年来从未让人失望，今年更是如此。据悉，CeMAT ASIA 2018 展示规模已超 60,000 平方米，此次大会设置了包括系统集成与解决方案、自动引导搬运车AGV、叉车及配件、输送分拣设备、物流机器人、AUTO-ID、机器视觉、包装设备、起重设备及配件等十大主题展区，来自海内外的 600 多家物流装备行业的核心力量都将汇集于此。众所周知，物流行业与实体经济密不可分，蕴含着丰富的产业链条和巨大的产业价值。随着人工智能、机器人及大数据技术的渗透应用，国内传统物流行业的发展也进入智能化、柔性化时代。国家相关部委发布“十大产业振兴规划”之后，我国又将物流行业纳入“十二五”规划纲要。该规划纲要(草案)明确提出，“要大力发展现场物流业，加快建立社会化、信息化、专业化物流体系。”在此背景下，旷视艾瑞思机器人聚焦“AI+IoT”，针对智慧物流仓储、智能工厂等实际场景中货品分拣、智能搬运等切实需求打造了“机器人+仓储管理系统+数据分析”等综合性解决方案，旨在以融合人工智能、物联网、机器人技术的方式，持续推动物流仓储、工厂等行业实现智能化、柔性化技术升级，为客户实现降本增效和创造价值。在本届 CeMAT ASIA 2018 中，为多维度、全方位真实展示旷视艾瑞思在以 AI+IoT 赋能城市终端过程中的实践能力和前沿创新技术，旷视艾瑞思展区共划分成三大部分，分别用以展示智能机器人开放平台、智能搬运机器人系列新品以及智能仓储机器人“货到人”解决方案。智能机器人开放平台应用场景业务复杂多变？多个厂商设备不兼容？不同产线产能不匹配？系统部署实施周期长？规模化部署成本高？NO!NO!NO!N 个问题 1 个对策！这就是旷视艾瑞思开发出的智能机器人开放平台易用！开放！智能！支持混合云部署及二次开发CeMAT ASIA 2018 现场我们将通过实时机器人调度为您演示真实模拟平台的智能化工作流程智能机器人系列新品同时，我们也将在这次盛会中集中亮相旷视艾瑞思智能、柔性、高效的系列新品机器人！他们是货架搬运机器人iWR800/ iWR1300料箱搬运机器人iSR200托盘搬运机器人iPR2000互动体验“货到人”解决方案在仓储场景中拣货、搬运往往是最耗费人力物力的存在旷视艾瑞思智能仓储机器人“货到人”解决方案旨在降低仓储人力成本、提高拣货效率为让大家真正体验到智能化的作业流程CeMAT ASIA 2018 期间旷视艾瑞思机器人将通过抽奖互动为大家现场还原无人化管理、多机协作、人机互动的现代化分拣模式在奋力开拓智慧物流行业的路上我们希望通过核心的人工智能和感知智能技术为行业客户打造针对性的智能解决方案帮助客户降本增效、创造价值而所有的答案都将在11月6日-9日CeMAT ASIA 2018上海新国际博览中心W3馆C1展区为您揭晓
身份验证迎来新技术革新	现在我们在很多公共场合里面，都可以通过一些快速通道进入到我们需要进入的场合里面。身份验证已经不再是一个需要等待或者是需要被质疑的过程。因为现在人工智能技术的出现，已经为身份验证提供了一个更强大的支持，在AI的基础之上，身份验证也迎来了一个更高效的方案。如今我们如果需要到一些比较大型的智慧园区上班，基本上都需要通过闸机，而且还需要签到，整个过程都需要耗费人力物力，如果在一些规模比较大的园区，每天上下班的人数非常的多，这时候也会导致时间延误。当然那只是过去，因为现在AI身份验证的时代已经来到，这种更高效的身份验证的方案，能够进一步的解决这些办公园区在身份验证上面的各种难题，帮助他们高效的解决通过人员的身份验证需求。比如现在很多智能办公室都已经有门禁考勤系统，还有签到系统，人脸识别闸机等等，这些设备其实就是在AI身份验证的基础上面产生的硬件设备，他们通过终端的数据分析能够实现机器识别人脸的目的，从而对通过的每一个人员都进行识别，不用派专门的人员驻守，只需要通过前端摄像头来反馈数据就可以毫秒级别的水平识别通过人员的真实身份，然后进一步的核实用户身份，防止陌生人或者一些嫌疑人进入，保障办公室的安全。有了AI身份验证的技术人员，通过率将会更高，而且企业的资源也可以得到最优化，更重要的是办公安全也可以得到一个更大的保障，在节省人力物力的过程当中也可以让办公场景更高效，更安全，对于企业的长远发展有利。除了办公区域之外，现在在很多公共区域，比如火车站，飞机场等等，都有这一类型的AI身份验证的系统及设备。这些设备的普及都将进一步的惠及到更多用户，同时对于智慧城市的建设也是有帮助的。未来AI身份验证的技术将会进一步提高，应用场合也将会越来越广阔，而且之后通过这一个身份验证系统反馈出来的各种信息，也将会更加的经历速度，也将会越来越快。相信届时将会有更加多的企业或者用户收费，从AI技能当中获得一个对生活对工作更高效的解决方案。
泰国副总理颂奇与旷视科技共探泰国数字经济建设中的AI动力	11月6日-7日，泰国副总理颂奇访问北京，期间与旷视科技总裁付英波进行会面，双方就在泰国数字经济及智慧城市建设中的合作内容进行深入探讨。▲颂奇副总理与旷视科技探讨未来合作方向在会谈过程中，付英波介绍了旷视科技自2011年成立以来在技术、人才、资本、业务方面的发展，细数了旷视参与智慧城市、智慧金融、智慧零售、智慧仓储等方面所取得的成绩。他指出，旷视是国内领先的人工智能企业，旷视的人脸识别技术被MIT科技评论杂志评为全球十大突破技术，旷视位列全球最聪明公司第11名，2017年7月，旷视科技作为创新企业代表向李克强总理做创新q新动能汇报，旷视的自主原创技术赢得总理高度认可。2018年泰国提出大规模经济改革计划“泰国4.0”战略，着力打造能促进长期经济发展的东部经济走廊（Eastern Economic Corridor，以下简称EEC），同时寻求与中国在“一带一路”战略下的深度对接，其中数字经济和智慧城市建设是重要内容。▲旷视科技总裁付英波（左二）向颂奇副总理一行汇报据付英波总裁介绍，旷视科技2017年已与泰国政府和企业展开合作交流。例如基于旷视科技“城市大脑”布局的先进人工智能技术被引入到泰国的公共安全防护中，辅助泰国安防部门精准高效打击违法犯罪行为，维护社会治安稳定。同时，基于人脸识别技术，旷视科技还与泰国银行达成合作，帮助其完成线上实名认证和用户身份核验。未来，旷视希望深度参与泰国数字经济和智慧城市建设，将在泰国的合作项目打造为中泰科技创新合作的典范。对此，颂奇副总理表示欢迎：“目前泰国正在进行数字经济建设，也希望外国投资者能到EEC东部经济走廊发展相关产业。希望旷视科技找到双方合作的共同落脚点，在泰国进行整套投资，落地于EEC，推动泰国整体经济结构的改变。泰国政府将给予大力支持。”与此同时，颂奇副总理还就旷视科技参与推动泰国人工智能人才培养表达了热切期望和邀请。双方表示将围绕会见达成的共识深入对接，制定工作方案，推动更多合作落地。▲泰国颂奇副总理与旷视科技总裁付英波在产业和科技大变革的时代中，人工智能越来越成为推动经济社会发展的新引擎，世界各国纷纷投入到数字经济转型和智慧城市建设的浪潮中。旷视科技作为全球领先的行业智能解决方案提供商，一直放眼全球，其产品和方案已经走进泰国、新加坡、日本、韩国等国家。未来，旷视科技将与泰国政企进行更深入的交流磋商以实现双赢；更将进一步把握历史机遇，因地制宜，加强与世界各国的交流合作，促进人工智能技术在全球落地，以人工智能技术造福全人类
《中关村―变革的力量》即将开播 旷视科技约你洞见未来	为隆重纪念改革开放40周年，同时也是中关村园区设立30周年，由中关村科技园区管理委员会联合北京电视台制作的六集系列纪录片《中关村――变革的力量》于近日举办开播启动仪式，宣布将于2018年11月12日至17日每晚22点在北京卫视播出。纪录片《中关村――变革的力量》在京举办开播仪式据悉，《中关村――变革的力量》以“中关村人创新创业史”为主题，共分为六集，以中关村一代代企业家的奋斗故事为切口，分别从“破冰”“突破”“引领”“挑战”“融合”“未来”的角度进行梳理，以人见事、以小见大，展现中关村在改革开放的四十年中引领全国创新发展的丰硕成果。其中，旷视科技联合创始人兼CEO印奇在第六集《千帆竞渡海天阔》中受邀出镜，洞见科技变革的未来。从学生到创客旷视科技“印奇”在高新技术领域并不是一个令人陌生的名字，2011年，印奇抓住时代机遇，与另外两名清华“姚班”同学杨沐、唐文斌共同创立旷视科技，以人工智能技术带动新一轮的科技变革。旷视科技创始人兼CEO印奇众所周知，得益于移动互联网、大数据、和云计算的不断进步，人工智能技术的革新和商业运营模式都得到了突飞猛进的发展。数据统计显示，2017年，全球人工智能核心产业超过了370亿美元的规模，而中国人工智能核心产业规模占比超过了15%。预计到2020年，全球人工智能核心产业更将达到1300亿美元的规模。不难看出，如今人工智能是世界范围内炙手可热的一个领域。而在2011年，当人工智能领域仍旧悄无声息时，还在读大学的印奇就进入了AI领域，并将人工智能坚定为创业乃至人生奋斗的方向，无不显示了印奇对时代机遇的把握能力。此前《麻省理工科技评论》(MIT TR)发布的“2018全球35岁以下科技创新35人”榜单中，刚过而立之年的印奇是唯一入选的人工智能领域企业家。不过，印奇的成就并非一蹴而就。在创业初期，旷视科技主要业务是一款借助于视觉技术的游戏《乌鸦来了》，该游戏当时下载量很大。但是印奇知道，将人工智能技术框定在游戏领域，有些太过于局限，对于有追求有梦想的团队来说，这也不符而他们的长远预期。为了给技术创新提供强有力的支撑，印奇赴美国哥伦比亚大学攻读3D相机方向博士学位。正是这种勇于突破创新、迎难而上的精神，使得印奇先后获得北京青年五四奖章、中关村创新创业青年英豪等奖项。如今，从最初的技术人员到现在的企业家角色，站在科技变革的前沿，印奇还在不断向商业模式、企业融资等全新的领域学习和探索。探索、深耕、落地、引领变革在印奇的带领下，成立七年的旷视科技始终抱着坚定的技术信仰，持续优化自研技术塑造企业核心竞争力，不断探索人工智能创新前沿领域，刷新着中国 AI 技术的高度。截至到目前，旷视科技已经赢得了22项国际人工智能顶级竞赛冠军，其中便包括2017全球计算机视觉顶级竞赛――MS COCO + Places 联合挑战赛中一举摘下的3 项世界冠军，以及2018年的MS COCO + Mapillary 联合挑战赛中的4 项世界冠军。另外，旷视科技还拥有国内外在申及授权专利800 余件，在行业中遥遥领先。与此同时，旷视科技AI技术应用的落地也在不断推进并取得了丰硕的成果。如今，旷视科技的人工智能技术在金融、手机、安防、社区、物流和零售等业务场景都得到了深度应用。其中，在安防领域，旷视科技先进的人脸识别技术已赋能到全国100多座城市的公安系统当中，协助警方破获案件5000余起，并为重大公共活动提供智能化解决案。在手机应用领域，旷视科技推出了人脸支付、人脸识别解锁、人像光效、人像背景虚化、视频美化、3D Animoji等一系列移动端AI产品，以满足不同手机厂商在人脸解锁、图像增强、相机增强、智能图像和视频处理上的需求，在不到一年的时间内已经与华为、小米、vivo、OPPO等国内一线手机厂商实现深度合作。在此基础上，旷视科技的引领作用也不断得到政府及行业的认可。2014年，旷视科技被认定为国家级高新技术企业；2015年，被认定为中关村高新技术企业；2016年11月，入选中关村前沿科技企业；2017年3月，被科技部评为“独角兽”企业，并位列人工智能企业首位。2017年5月旷视科技的核心人脸识别技术被美国著名科技评论杂志《麻省理工科技评论》评定为2017全球十大突破技术，同时旷视科技作为中国唯一一家人工智能企业入榜“全球最聪明公司”；在2018年，旷视科技获得了“十大双创硬创示范科技成果”称号……可以说，作为全球领先的人工智能科技企业，旷视科技早已是各个奖项的常客。如今，推进人工智能技术的革新与落地已成为国家层面的战略，而印奇对旷视科技也有着长远的规划和期望。未来的旷视科技将如何布局？中国科技领域的变革浪潮又将走向何方？尽请期待即将播出的六集纪录片《中关村――变革的力量》，旷视科技印奇与你一起预见未来！
人工智能红利时代：人脸识别算法如何提高劳动率？	人脸识别算法作为一种新的人工智能技术，在未来被投放到各个领域的使用频率将会越来越高。在中共19大的报告当中，明确提出了未来要把人工智能与社会经济发展融合起来，并利用人工智能的优势来推动社会经济的快速发展。其中以人脸识别算法为基础而诞生的各种智能科技及项目，将会替代传统劳动力，从而衍生出新的经济增长点。根据相关数据显示，现在在全球各个发达国家当中，利用人工智能科技来替代传统劳动力的频率越来越高，而且在人脸识别算法介入某些工作环节之后，劳动力的确有了更大的提升。各个发达国家包括英国法国等等，在人工智能替代传统劳动力结构这个方案上面，都已经有了先行的探索步伐，并取得了非常不错的成绩，在劳动率的提升方面均有了一个非常显著的成绩。而回归中国，人工智能红利时代的到来，也为这个国家带来了更多的希望，传统劳动力结构也将会在人工智能的格局之下产生变化，并且向更加高效的道路迈进。在人工智能科技当中，以人脸识别算法为基础而衍生出来的各种科技项目，将会进一步的改变传统劳动力结构基础。比如在过去，一部分繁琐的需要人力从事的相关项目，也将会由人工智能机器来替代，进而提高生产的效率，把更加多的劳动力释放到创造力的任务当中。其次，在某些特殊环节中，人力是不可或缺的劳动力，但是人工智能科技也可以作为替代及辅助，协助相关的技术人员完成更高科技的劳动力度更大的项目，从而释放出更大的人力价值。通过上面两个积极方面的形势可以看得出来，人工智能红利时代的到来，的确对于改变中国经济尤其是传统劳动力结构上面可以带来更多的能量，在劳动力提升及经济价值的创造上面都会带来明显的推动作用。未来人工智能对于中国经济的推动作用还将会体现在更多的方面，而随着人脸识别算法的深化，这种高科技的AI技术也将会逐渐的被普及到各个领域当中，并发挥更积极高效的作用。未来中国的人工智能红利时代将会焕发出更巨大的生机，除了人脸识别算法之外，更加令你意想不到的人工智能新技术也将会诞生。
AI推动智慧安防 智慧园区未来继续普及	当AI时代到来的时候，智慧城市建立的口号也开始成为时代的选择。对于整个经济发展社会来说。智慧城市的一个重要标配就是AI，而AI又可以体现在诸多方面，比如城市安防。安防对于人类的生命安全而言是一个十分重要的概念，也是现代智慧城市建立的一个重要的指标，在智慧园区的建立上，以AI作为基础建立的建立的智慧安防系统，现在也开始逐渐的向大场景拓展。在智慧园区的建立当中，以监控系统为前端感应的体系已经被逐步建立，在整个智慧园区落实的方案当中，通过AI数据可以对园区的安防工作进一步的把控，通过摄像头以及感应器及后台的数据分析，来完成一系列的协调工作。其中就包括对于园区内的陌生人来访的监控，以及嫌疑人的追捕，还有对于居民本身的居住安全的其他方面的监控，比如消防等等。AI数据的布局，智慧园区的建立，有了一个更高的可行性方案。这个方案在造福城市住户的同时，也在不断的提高公共安全的效率，让智慧安防得以普及到更多的范畴里去。当然，在智慧安防方案落实的同时，我们也要看到，未来这一个方案和构想还需要获得什么样的完善，它的发展方向在哪里，？随着AI技术的不断提升，在智慧园区的建立当中，又会有一些什么新的元素加入？这些都是我们需要思考的。例如，现代，公安部门对于智慧安防这一方面，尤其是监控视频这一方面，已经不在局限于要求视频监控全要看得清楚就可以，这里面还存在有更多复杂的要求，比如可以通过视频追踪，可以分析更复杂的嫌疑人信息等等，这些都是AI技术日新月异之下的智慧安防布局的方向，只会向越来越精细化，全面化的时代行进。除此之外，在智慧园区建立的时候，如何才可以更好的把控住户，物业，以及治安三者之间的关系，怎样可以更好的协调分工，并且通过终端的AI数据分析来更高效的调配三者之间的关系，这个问题也需要未来智慧园区的建立者思考。当然我们相信，AI技术的不断飞跃，将会继续为解决这些问题提供更强大的技术支持，而在智慧安防部组织下，智慧城市的推行也将继续大步流星！
通过实名认证看未来人工智能市场的发展前景	对于目前中国人工智能市场发展，很多人都抱以非常大的期盼，认为在未来的时间里面，人工智能将会不断改造福人类。时下，包括实名认证系统在内的更多精准的人工智能项目正在为更加多的生活及办公场合提供高效的服务方案，人类几乎已经离不开人工智能。但是依旧有一部分人担忧，人工智能会不会取代人类的地位，从而让某些传统的产业或行为失去原有的价值？又或者下一个人工智能的寒冬会不会到来？对于这个问题，相关的人工智能专家表示，现在，无论是中国还是全球，人工智能市场的发展都已经有一个更坚实的基础。过去人工智能产业之所以会出现一段颓废的时间，主要是因为当时的技术条件还不成熟，而且人们对于人工智能的价值实施并没有优化到合理的布局上，因此出现问题也在所难免。但是现在不一样了，因为人工智能发展到现在，已经有了更强大的基础。例如，如今实名认证覆盖着生活和工作的各个领域，我们在操作或者是办理任何一项服务的时候，几乎都需要使用到这一个人工智能识别技术。例如，在互联网教育上面，人工智能可以改变教育的模式，可以营造一个更智能的场所，而实名认证则可以帮助用户完成身份识别及验证过程，让他们可以更高效的享受到线上互联网教育的各种优质服务，同时也保证了运营品牌的利益。此外，在医疗健康产业里面，更多的场所都需要使用到实名认证，核实每一位患者和就诊人的信息，以储备数据，或者医生可以通过识别及智能分析，对病人的身体信息进行把握，并为他们提供更精准的护理方案。除了这些行业之外，人工智能对于农业的积极改变也是很明显的，例如，农业正在逐渐的向自动化种植的过程转变，这个过程离不开人工智能技术的投放。如此种种，都充分展示出了人工智能，在现代已经拥有更强大的基础，通过千百遍的实践，它已经被证实了可以应用到更多的范畴当中，并且发挥应有的作用。就比如实名认证，已经成为了当代身份验证的标配，便捷，高效，更准确，这就是人们所需要的人工智能技术。而这些技术，也在不断的为用户或者是企业机构创造利润，通过技术的改造给他们以更高效的办公或生活氛围。所以总体来说，人工智能的未来将会是更乐观的，寒冬将远去。
旷视人气王产品点亮乌镇 世界互联网大会展现AI创新之光	作为世界互联网大会的重要组成部分，第五届“互联网之光”博览会也如约而至，当下全球最前沿的互联网新技术、新应用再次齐聚于乌镇。中国移动的5G体验车、阿里巴巴的一站式智能体验馆、高德推出的“一张地图游乌镇”、旷视科技的城市天眼系统、智能零售解决方案等，在工业互联网、智慧城市、电子商务等领域的新技术、新成果，都在乌镇惊艳登场。相对于BAT等传统互联网企业来说，一些在移动互联网时代崛起的创新型公司也十分值得关注。作为国内最早进军人工智能领域的企业之一，旷视科技今年也携自身在安防、手机、车载、零售、物流等领域的最新原创AI技术和产品再度出发，与合作伙伴艾迈斯半导体（ams）登陆本届博览会主展馆做展示。今年，旷视展区依然是互联网之光博览会的高热区，其带来的城市天眼2.0系统、端到端智能安防、智慧零售、移动端AI、物流机器人等产品和解决方案再次受到参会领导、行业媒体、专业观众的广泛关注。据了解，今年是旷视第四次参加互联网之光博览会，纵观四年来旷视在博览会上呈现的AI创新成果，从天眼1.0到天眼2.0，从人脸识别到人体识别、行为识别、手势识别，从安防到手机、零售、物流、车载，从云端到软硬一体的“端到端”，旷视每年都在用实际行动诠释永无止境的创新。2018年，旷视也在博览会上介绍了他们全新的技术、产品和解决方案。旷视安防黑科技集中亮相爆款天眼再受瞩目安防，是旷视最早发力的技术应用和业务垂直领域之一。近年，旷视提出了端到端智能安防解决方案，针对安防业务中的典型场景和“情、指、勤”联动的实战诉求，通过“算法、技术、硬件产品、解决方案、数据”全价值链输出，帮助公安用户构建从前端感知，到云端研判，再到终端应用的新型智能安防闭环体系。据旷视工作人员介绍，如今旷视智能安防的洞鉴人像系统、视频结构化分析系统，以及智能摄像机、便携式人像比对机等硬件产品，已在全国100多城市落地，并也是G20峰会、厦门金砖峰会、海南博鳌论坛、上合组织峰会等国际重大活动的安保技术支撑。据悉，旷视也曾为2015年的世界互联网大会提供人证核验的安保技术支持。值得一提的是，旷视科技在本次博览会上也展示了升级后的城市天眼2.0系统，而这套系统更是成为主展馆最吸睛的展品之一。结合大数据与深度学习算法，旷视城市天眼2.0系统将自研的人脸识别、行人识别、车辆识别、轨迹追踪、视频结构化等领先的AI视觉技术，与城市安防、城市交通、城市治理中的实际场景需求所结合，可提供智能识别公安重点关注人员、交通违章违规行为、城市流动摊贩等功能。现场，旷视这一集合众多先进AI视觉技术的天眼系统也为参观者提供了实时人脸识别、人像比对、视频结构化分析黑科技体验，促使旷视“天眼”下总是人流如潮。▲旷视城市天眼2.0系统发力移动端AI创新构建个人IoT物联网络“刷脸瞬间解锁”、“刷脸安全支付“、“大师级AI美颜“……这些是旷视在本届博览会上对其在移动端AI技术及解决方案介绍的关键词。伴随AI应用浪潮在手机行业中的兴起，旷视也早早进军手机行业并率先推出软硬一体的移动端AI感知全栈解决方案，从算法创新、应用开发、设备制造到解决方案，为行业客户实现AI赋能。从目前市场上的手机AI应用来看，旷视基于核心深度学习和计算机视觉技术推出的人脸支付、人脸识别解锁、人像光效、人像背景虚化、3D Animoji等一系列移动端 AI?产品，已经搭载到众多手机厂商发布的最新机型中，以满足其在人脸解锁、图像增强、相机增强、智能图像和视频处理上的需求。在博览会现场，旷视也展示了为 OPPO Find X 提供的3D人脸解锁支付及3D人像光效技术。▲用户体验旷视人脸稠密关键点检测技术此外，旷视全新研发的车载AI视觉解决方案也在本届博览会上亮相。据介绍，目前旷视科技已在汽车前装和后装市场研发出了多场景智能化产品和解决方案，核心技术包括配合多模态人机交互的手势识别、表情识别、视线跟踪，及配合智能安全驾乘方面的人脸识别、驾驶员状态检测、前车碰撞及车道偏离预警等。车载AI视觉赋能，是旷视在移动端AI创新中又一重要布局。AI打通零售、物流场景助力商业效率升级在零售行业中，旷视今年也带来了全新的AI解决方案。据介绍，针对线下零售场景数据缺失，无法用数据驱动决策的痛点，旷视基于业界领先的计算机视觉算法及物联感知终端体系，自主研发了一套“云服务+智能端”的新零售行业解决方案。通过多维度感知并理解顾客的身份属性、行为信息及与货架、商品触发的各类数据，再对数据进行融合分析和深度挖掘，帮助商家提升店务运营人员的能力边界、优化经营策略与供应链管理，以在门店数据化进程中实现降本增效的目的。▲旷视在安防、零售、物流等场景的应用展示而在零售供应链侧，旷视在2018年也开始了深度探索并逐步付诸行动。在零售供应链侧，物流和仓储的数字化、智能化升级正成为行业刚需。依托于旷视强大的机器人、大数据、人工智能等核心技术研发实力，旷视打造出了物流仓储机器人解决方案，通过AI+机器人的产品形式满足客户仓储分拣、智能搬运等业务需求。据旷视介绍，在物流行业中，旷视已与众多国内知名电商仓储、物流及制造企业达成战略合作伙伴关系，通过构建开放的智能机器人平台，为更多合作伙伴实现降本增效、创造价值。再获重量级大奖旷视科技受组委会认可凭借先进的AI技术可视化展示和良好的互动体验，旷视科技的展台在大会期间受到了各省市、各级单位和各路媒体以及其它参展观众的强势关注。博览会期间，旷视科技展区的人工智能核心成果也受到了媒体的集中采访报道。▲央视一套晚间新闻对旷视科技的黑科技报道值得一提的是，在今年世界互联网大会发布的“世界互联网领先科技成果”榜单中，旷视科技原创移动端深度学习卷积神经网络 ShuffleNet 也成功入围，这也是继2017年产业级人脸识别技术入选后，旷视科技再度入围世界互联网领先科技成果的原创核心技术。从2015年初次参展至今，历届世界互联网大会见证了旷视科技的极速成长。在如今的世界互联网大会展台上，旷视围绕AI+IoT所打造的产品矩阵及开拓的应用场景更是让人惊叹。通过不断对算法升级、产品迭代，以及不计其数的自我突破，旷视科技从稍显稚嫩的新兴独角兽企业成长为了全球机器视觉人工智能行业领跑者和人脸识别产品先导者，越来越多的出现在世界舞台上展示中国科创的文明之光、未来之光和智慧之光！放眼未来，期待旷视能带来更多非凡AI科技创新，为社会创造更多价值。
揭秘“买买买”背后的故事 旷视艾瑞思科技赋能智慧供应链	11月6-9日，一年一度的亚洲国际物流技术与运输系统展览会 (CeMAT ASIA) 在上海国际博览中心隆重举行，作为行业领先的智能机器人解决方案供应商，旷视艾瑞思机器人携旗下多款应用于物流仓储、智能工厂的智能搬运机器人产品和解决方案亮相，并隆重推出业内首款智能机器人开放平台，向业内展示了以 AI+IoT 赋能终端的实践能力和前沿创新技术。提升人效坪效旷视推出智能搬运机器人家族新品此次展会中，旷视艾瑞思展出的一系列更为柔性、灵活的智能机器人产品受到广泛关注。其中包括在“货到人”模式下的智能仓储搬运机器人 iWR500、具备1.3吨超大载重能力且支持多系统无限扩展的 iWR1300、基于激光导航和视觉导航可自主避障的 iSR200 及 iPR2000，能够实现对人的精准识别和定位，兼容人机混合场景。旷视艾瑞思智能搬运机器人系列在旷视艾瑞思展区，旷视的货架搬运机器人可根据订单任务将要拣选的货品货架主动搬运到拣货点，拣货人员在拣货点完成拣货，机器人再将货架搬运到下一个拣货点或搬回库存区，准确率达 99.99% 以上，可提升 2-3 倍的拣货效率，大幅提升仓储管理的人效和坪效。目前旷视艾瑞思已落地实施的机器人数量达 3000 多台。不仅广泛应用在电商、新零售、3PL（第三方仓储）、3C、医疗、食品、日用品、工业及汽车制造等行业，还刷新了单仓机器人集群作业行业记录，在位于天津的“未来一号”仓，旷视艾瑞思联合心怡科技实现了 500 台机器人高效协同作业的智慧仓储场景，它们的主要工作是完成订单的快速、准确拣选，而这些 AGV 机器人则成为天津仓今年双十一期间的主力干将。具仓内工作人员介绍：“天津仓为拥有近 50000 多个 SKU，每天单量大，人工分拣难度大，劳动强度大，运营成本居高不下。引进仓储机器人后，大大降低了用工人数和劳动强度，极大提升仓储效率，实现了降本增效。”开放、易用、智能旷视艾瑞斯推出智能机器人平台众所周知，在新零售和智能制造的时代背景下，企业仓储面临提升效率和降低成本双重挑战，智能机器人自动化解决方案已成为核心竞争力，一方面企业业务复杂多变，很难形成标准化的解决方案；另一方面机器人厂商只提供设备和控制软件，无法针对业务流程提出完整解决方案。对此，旷视艾瑞思希望通过打造出了开放、易用、智能的智能机器人开放平台，以解决用户一系列痛点。其优势在于支持多设备接入、可对接业务系统标准化库区和组件，具备可扩展性、支持混合云部署及二次开发，可实现快速部署，为行业用户降本增效。 基于云端作业流程编排，旷视艾瑞思智能机器人平台能够广泛适用于工厂和仓库等作业流程的智能化、数字化建设。例如在仓储场景的“货到人”中转模式中，旷视智能机器人开放平台可有效解决多个站点区之间产能不匹配的场景：站点区 W1 和 W2 的工作人员从缓存区 B 叫空货架进行装货，装货完毕后，发货至缓存区 B；站点区 W3 的工作人员从缓存区 B 叫满载的货架，卸完货架，还空货架至缓存区 B。在实施成本上，旷视智能机器人开放平台占据很大的优势：一般仓储或工厂中机器人数量随着业务量增加，应用机器人进行智能化做作业的软件成本也随之激增，需要根据不同业务、不同硬件进行相应的软件订制化开发，人力成本和实施周期不可控。而旷视艾瑞思的开放平台可以同时接入多种智能设备，同时对智能化作业进行了高度的模组化和抽象化，并提供友好、简单的接口对接 MES、WMS 等业务系统，不会因设备数量和业务的变化产生太大影响，因此边际成本更低，规模效应明显。时代更迭，产业升级已经成为社会和经济的重中之重，在工业4.0、智能制造以及智能物流跨步发展的前提下，行业亟需新技术及新理念。而作为引领新一轮科技革命和产业变革的战略性技术，人工智能、物联网、柔性制造等技术已成为我国科技跨越发展、产业优化升级、生产力整体跃升的重要战略资源。而机器人行业更是如此，面对巨大的行业升级需求，旷视艾瑞思机器人希望通过软硬一体的“AI+IoT”技术和解决方案，为物流行业和制造行业贡献一己之力，从“无人仓”到“智慧仓”、从“制造”到“智造”，旷视正在和前沿的行业伙伴一同推进技术的变革。
进击的中国AI政策红利	自 2015 年智能制造开启了人工智能发展之路，2016 年互联网+ 的提速，2017 年人工智能被正式列入国家战略，进入 2018 年，国内各地方政府对人工智能的重视度亦随之升温，并相继出台 AI 相关发展规划。据不完全统计，从 2016 年开始，北京、江苏、贵州等地方政府最先出台了 AI 相关的发展规划的政策。进入 2018 年，黑龙江、河北、天津、福建、四川、广东等省市也纷纷跟进国务院去年印发的《新一代人工智能发展规划》，对技术与应用、人才培养、产业规模等各方面的发展和目标给出了大体规划。如广东省政府 8 月正式公布的《广东省新一代人工智能发展规划》指出：到 2025 年广东人工智能产业核心规模突破 1500 亿元，带动相关产业规模达 1.8 万亿元；到 2030 年整个人工智能产业发展要进入全球价值链高端环节。截止到今年 10 月，全国已有 19 余省市推出新一代人工智能发展规划。各地政府在积极响应国家战略的同时，也在结合本地资源优势和发展条件，试图打造人工智能产业相关的差异化发展方向。其中，北京、广东、贵州、江苏、浙江、上海、安徽作为受政策推动最先实现IT信息化的地区，在人工智能的政策颁布方面也相对更为积极。相比起来，湖北、重庆、江西、黑龙江、辽宁、河北、天津、福建、四川、河北等地仍是积极响应之下的发展规划，目前尚未有具体的实施细则。除了出台相关政策外，举办 AI 大会，操持 AI 大赛，争抢企业落户，今年以来各地政府纷纷上演 AI 争霸赛。在政府政策的支持和带动下，各大高校纷纷开设 AI 相关课程、设立 AI 研究院，并联合创新企业成立人工智能联合实验室。甚至在少儿教育方面，编程课等人工智能教育开始在社会上掀起一阵学习热潮。实际上，由各地政府所主导的 AI 政策，核心诉求仍是加强企业孵化创新创业，引进培养高端人才，以带动本地经济实现转型。值得一提的是，各级政府规划AI相关政策的同时，中国香港特区与内地的科技合作方面也有了一系列举措。据了解，香港最新《财政预算案》提及了对人工智能等创新技术发展的问题。目前华为、微信分别在香港科技大学开设创新实验室、人工智能联合实验室，阿里巴巴联合商汤科技、香港科技园成立香港人工智能实验室。中美 AI 政策角力：中国后发优势明显，集中力量办大事我国非常重视人工智能的发展，并且已有人工智能比较全面的顶层设计。2017 年 3 月，人工智能被首次写入《 2017 国务院政府工作报告》，正式进入国家战略。2017 年 7 月，国务院印发了《新一代人工智能发展规划》(简称《规划》)，明确将人工智能作为未来国家重要的发展战略，并确定“三步走”的战略目标：到 2020 年，人工智能总体技术和应用与世界先进水平同步，人工智能产业成为新的重要经济增长点，人工智能技术应用成为改善民生的新途径；到 2025 年，人 工智能基础理论实现重大突破，部分技术与应用达到世界领先水平，人工智能成为带动我国产业升级和经济转型的主要动力，智能社会建设取得积极进展；到 2030 年，人工智能理论、技术与应用总体达到世界领先水平，成为世界主要人工智能创新中心。2018 年 10 月 31 日，中共中央政治局就人工智能发展现状和趋势举行第九次集体学习。中共中央总书记习近平在主持学习时强调，人工智能是新一轮科技革命和产业变革的重要驱动力量，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。战略之下，需要把增强原创能力作为重点，以关键核心技术为主攻方向，夯实新一代人工智能发展的基础。根据中国工业和信息化部历年财政拨款支出情况，科学技术支出一直是教育之外的第二大财政支出，并且在从 2011 年至 2017 年期间一直保持 110 亿元以上的投入规模。2011-2017 工信部历年科学技术财政拨款情况与此同时，中国民间资本在人工智能领域的投入也正迎头赶上。据 CBInsights 公布的《2018 年人工智能发展趋势》报告显示，2017 年中国人工智能初创企业获融资额占全球总体的 48%，相比 2016 年实现了翻倍以上增长。而在国际范围内，美国很早就开始出台一系列 AI 相关政策予以扶持和规范。2016 年 10 月，美国白宫发布的《为人工智能的未来做好准备》和美国国家科学技术委员会发布的《国家人工智能研究与发展战略规划》，正式将人工智能上升到美国国家战略高度，为国家资助的人工智能研究和发展划定策略，并制定了美国在人工智能领域的七项长期战略。细数其历年来人工智能的发展战略，可以发现，美国更强调以经济带动与社会服务为基础，使新技术能够充分落地应用。不过，自新任总统特朗普上任后，美国政府并没有持续执行前任总统期间制定的 AI 战略计划。据悉，特朗普政府在基础科学和研究领域的财政支出有所下滑，从能源部先进科学计算研究计划可以看出，预计 2019 财年预算为 8.11 亿美元，相比 2016 年的 12 亿美元减少了 32.4%。此前 Google 母公司 Alphabet 执行董事长 Eric Schmidt 在去年 11 月公开表示，尽管美国的人工智能在未来 5 年内仍可保持领先优势，但很快就会被中国赶超。2018 年 5 月，美国白宫峰会的举办显露出特朗普政府对人工智能发展的新战略。据了解，今年 10 月，美国麻省理工学院宣布投资 10 亿美元开设一所新的苏世民计算机学院，这笔投资是迄今为止美国学术机构对计算机和人工智能领域的最大一笔投资。相对来讲，美国政府在人工智能发展政策方面已有一些领先动作，但中国政策近年来开始逐渐倾向人工智能、大数据、云计算、物联网等新兴技术产业，后发优势明显。
公共安全领域的人工智能技术应用	技术的不断革新，让人工智能得以在城市生活的诸多领域内发挥出积极的作用，比如城市公共安全领域。现代人工智能技术已经可以达到商业化的水平，在公共安全领域内应用的种类也非常多，其中就包括了图像识别，视频结构技术以及智能大数据分析等等，这些人工智能技术，都在进一步惠及城市生活。以图像识别技术为例子。在理解这一个概念的时候，我们可以把它简单理解成为一种利用计算机对图像进行详细的处理和分析的过程，通过这个过程，用户可以识别出不同模式的不同目标和对象的图像，并达到追踪和识别的目的。随着计算机深度学习技术的提升，现代的图像识别技术已经在传统技术的基础上面有了一个质的飞跃，新技术拥有更高的识别率，在准确率以及抗环境干扰上面也有了一个更好了展示，正是因为技术的提升，促使图像识别技术可以被应用到更多的技术产业中去。如今，基于深度学习出现的人脸识别或图像识别技术，以及全面突破了人工建模的模式，在打破局限方面获得了更强大的技术支持。尤其是在实际作业环境当中，还可以针对海量的数据进行学习与识别，即便被识别的因素及对象产生变化，或者出现复杂的干扰，如今的图像识别技术已经可以驾驭这种变化，即便如此，依旧可以实现出色的精准识别过程。如今，包括交通，生活，视频以及生态各个领域，都以及应用到了图像识别及视频识别技术，人工智能的技术在日常生活的普及中，尤其在技术产业的应用范畴内，以及变得越来越常见，技术的成熟也赋予了人工智能技术可以获得大量的成熟应用。此外，再加上政策的推动以及人工智能技术的普及落地，再加上现代城市公共安全建造的庞大需求，决定了包括图像识别，视频监控分析，数据处理等人工智能技术拥有更广阔的应用前景。未来，基于云端产生的拥有更高端的融合能力的智能视频技术将会成为主流，而人工智能未来的发展方向，也将会不断向视频结构化的进程迈进，而不久的将来，大数据分析以及人工智能技术二者之间，也将会呈现出前所未有的默契度。
北京市委书记蔡奇到旷视科技调研走访	11月12日，北京市委书记蔡奇到北京旷视科技有限公司调研走访，北京市委常委、秘书长崔述强和北京市副市长殷勇一同调研。调研期间，蔡奇察看了旷视天眼系统、“城市大脑”等技术展示，旷视科技联合创始人兼CEO印奇向其汇报了企业推动人工智能技术创新与商业创新实践情况。蔡奇强调，民营企业在北京最具代表性的是中关村企业、民营科技企业，各级党委政府要深入开展服务企业大走访，送上“服务包”，一对一为企业做好服务，为中关村企业营造更好的发展环境。旷视科技是一家创立于北京中关村的人工智能企业，拥有国内国际人工智能在申及授权专利 900 余项（已授权超过440项），所开发的核心人脸识别技术被评为2017年全球十大突破技术。在金融、手机、安防、物流、零售等领域，旷视研发的人脸识别技术、图像识别技术、智能视频云产品、智能传感器产品、智能机器人产品都已取得广泛应用。▲蔡奇听取旷视科技联合创始人兼CEO印奇汇报人工智能技术与商业创新蔡奇指出，创新力是中关村企业的生命所在。只有原创才能引领。旷视科技要加大关键核心技术攻关，不断取得新的突破。要加强技术与需求的对接，将人工智能创新成果应用于智慧城市建设，在公共管理、安全防护等领域提供技术支持，助力提高城市治理水平。要用好本市高精尖产业政策，做精做强做优，努力做全球最聪明的公司。蔡奇在座谈会上强调，各级各部门要坚持走访服务企业制度，持续优化营商环境，兑现各项政策。要支持企业在原始创新方面取得更多突破性成果，着力培育更多的独角兽企业、隐形冠军企业。针对企业发展需求和问题，相关部门要逐一研究解决。▲北京市副市长殷勇送上“服务包”
旷视科技参与共建北京智源人工智能研究院	11月14日，在2018中国(北京)跨国技术转移大会开幕式上，北京智源行动计划正式发布，北京智源人工智能研究院(Beijing Academy of Artificial Intelligence，BAAI)揭牌成立。科技部党组书记、部长王志刚，北京市委副书记、市长陈吉宁出席会议。旷视科技作为北京智源人工智能研究院共建单位之一受邀出席，旷视科技联合创始人兼CEO印奇与北京市科委主任许强、海淀区区长戴彬彬等共同为研究院揭牌。▲《北京新闻》报道北京智源人工智能研究院成立，旷视科技作为共建单位之一，旷视科技联合创始人兼CEO印奇（右五）出席北京智源人工智能研究院揭牌仪式陈吉宁市长在致辞中指出，北京智源人工智能研究院是北京市继脑科学与类脑研究中心、量子信息科学研究院之后，着力建设的又一个重要的新型研发机构。研究院将集合北京大学、清华大学、中国科学院、旷视科技等人工智能领域优势单位，采用新的科研组织形式和人才引进培养模式，推动人工智能发展方向和理论、方法、工具、系统等方面的关键性突破。北京市将把政府、企业和社会数据集合到这一平台上，建设新的开源人工智能工具，并将整合大学和大企业的计算能力，向各类AI研发机构开放，欢迎全球的人工智能研究人员参与使用。北京市科学技术委员会主任许强发布北京智源行动计划。该计划是在科技部和北京市政府的指导和支持下，由政府部门、企业、高校、院所等共同提出，是北京服务人工智能发展的顶层设计，是凝聚各方智慧的行动方案。按照北京智源行动计划的部署，北京市科学技术委员会和海淀区政府推动成立北京智源人工智能研究院。研究院依托北京大学、清华大学、中国科学院、旷视等人工智能领域优势单位，建设开放服务平台，召开人工智能峰会，协调推进联合实验室和人才培养，采用国际接轨、灵活自主的运行机制，实现研究院“轻装上阵”“跑得更快”。作为中国人工智能领域领先科技企业，旷视是中国最早用深度学习方法开展人工智能应用研发的科技企业之一。基于自主原创的AI技术体系，旷视拥有覆盖训练引擎、核心算法、基础平台、智能产品等各个层次的创新研发能力。在产业实践当中，通过 AI+IoT 协同发展战略，旷视已将自研的人脸识别技术、图像识别技术、智能视频云产品、智能传感器产品、智能机器人产品广泛应用于金融、手机、安防、物流、零售等领域，帮助产业和社会实现智能化升级。今后，旷视科技将依托自身在人工智能技术研发、平台建设、数据挖掘、人才整合等方面的优势深度参与北京智源行动计划，与北京市及产业链合作伙伴共建北京智源人工智能研究院。以创新为引领推动算法开源、数据整合，探索智能创新生态体系建设；整合人才和产学研资源，实现人工智能领域重大核心基础理论突破；发挥 AI+IoT 产业赋能实践优势，加速人工智能前沿技术的产业化落地和社会化应用。推动北京成为全球人工智能学术思想、基础理论、顶尖人才、企业创新和发展政策的源头，支撑人工智能产业发展，促进人工智能深度应用，改变人类社会生活，改变世界。
从人工智能落地看智慧安防行业就业趋势 	安防行业是随着现代社会安全需求应运而生的产业。可以说，社会只要还有犯罪和不安定因素存在，安防行业就会存在并发展。目前安防市场设备需求的涨势仍为增长幅度最快的市场之一。与智慧安防结合最紧密的行业随着高清视频、智能分析、云计算和大数据等相关技术的发展，安防正在从传统的被动防御向主动判断、预警发展，行业也从单一的安全领域向多行业应用、提升生产效率、提高生活智能化程度方向发展。人工智能技术的迅猛发展，积极推动着安防领域向着一个更智能化、更人性化的方向前进，主要体现在以下这几个方面：智慧交通、智慧楼宇、智慧社区、智慧警务等。人工智能技术是安防行业的未来人工智能是安防领域的未来，在通往未来的道路上，还有许许多多障碍和困难需要跨越和克服，但总体趋势是乐观的。从算法到需求都有得天独厚优势的安防领域，正在不断的推进安防领域的人工智能全面产业化运用。1、视频结构化(对视频数据的识别和提取)在安防领域中，视频监控无疑是不可缺少的一环。而随着智慧城市和平安城市的建设加速，安防系统每天产生的海量图像和视频信息造成的信息冗余问题也催生了带有人工智能的计算机视觉技术在安防领域的应用。2、生物识别技术(指纹识别、人脸识别等)当前，人脸、指纹、虹膜三种识别是应用较为广泛的生物识别方式。指纹属于接触性识别方式，人脸、虹膜属于非接触性识别方式，三者之间互为补充。3、物体识别系统当前，物体识别系统在安防领域中最主要的应用为车牌识别系统，车牌识别的技术在安防行业的应用由来已久，技术相对成熟，人工智能的应用提高了车牌识别的准确率。只有具备自主、个性化、不断进化完善的人工智能大脑，才能解决安防领域日益增加的需求，成为广大用户的专家和助手，提升整个安防领域的智能化水平，推动安防产业的升级换代。安防行业的就业趋势作为全球最大的安防市场之一，中国将持续引领全球安防市场增长。与发达国家与地区相比，目前在中国安防设备尤其视频监控渗透率还处于较低水平，这也意味着中国安防市场仍有很大的增长空间，市场潜力巨大。换句话说，未来很长一段时间里，中国将持续扮演全球安防增长第一引擎的角色。而放眼全球来看，中国安防制造商不但体量与增速蔚为壮观，在安防技术革新和整体解决方案能力方面也都走在整个行业前列。尤其是在当下安防技术与AI深度融合形势下，中国俨然成为安防技术创新的中心，包括海康威视、大华股份等在内的中国安防领军企业已经成为全球技术创新的先驱者。有数据显示，2017年我国安防行业总产值达到6200亿，行业增速为14.8%，另外，《中国安防行业“十三五”(2016-2020年)发展规划》指出：“十三五”期间，安防行业将向规模化、自动化、智能化转型升级，且到2020年，安防企业总收入达到8000亿元左右，年增长率达到10%以上，实现行业增加值2500亿元。拥抱人工智能《人民日报》报道过关于人工智能的数据：预计到2020年，中国人工智能(AI)产业规模将超过1500亿元，带动相关产业规模超过1万亿元，如此快速的增长和发展必然会产生大量的人才需求。一些业内人士认为，国内人工智能人才的供求比例仅为1：10，供需严重失衡。工信部教育考试中心副主任周明也曾在2016年向媒体透露，中国人工智能方面人才缺口超过500万人，近两年来看，这个缺口将会越来越大。
2018重庆国际手机展 | 旷视科技软硬一体创新引领手机未来	11月15日，由重庆市经济和信息委员会主办、手机报在线承办的第二届重庆・国际手机展在重庆召开，作为目前国内规模最大、产业链最齐全的顶级手机产业盛会，本届展会积聚手机产业上下游近 300 家企业到场展示与交流前沿创新成果。作为国内领先的软硬一体智能终端解决方案提供商，旷视科技也携多项原创手机AI视觉创新产品参展，并收获“2018中国手机行业最具影响力企业”殊荣，全面彰显出旷视在打造新型 AI Phone 上的非凡实力。在2017年的重庆国际手机展上，旷视曾凭借在人脸识别解锁技术上的研发与应用突破，获得“手机行业十大优秀供应商”的奖项。时隔一年，AI赋能手机的锐势不减，更进一步在手机行业中催生出打造 AI Phone 的未来变革方向。尤其在手机AI视觉领域的升级过程中，为给用户带来更加细致、全面的智能化操作体验，各厂商的手机产品开始发力协同软件与硬件的升级以提升AI视觉能力。而旷视在过去一年，基于对手机行业的深刻理解，在研发手机AI视觉应用的实践过程中对业务全新升级，打造出了覆盖算法、应用、解决方案、硬件全领域的软硬一体手机AI视觉解决方案，并成功开发出人脸识别解锁与支付、AI人像光效、AI微整形、智能美颜、3D仿生感测技术等一系列移动端 AI 产品，为包括华为、小米、vivo、oppo 等国内一线手机厂商的超过 1 亿台手机设备，带来人脸解锁、图像增强、相机增强和视频处理等方面的颠覆性AI视觉升级，正是这些走在行业前沿的技术创新和落地成果，才促使旷视成长为“2018中国手机行业最具影响力企业”。在第二届重庆・国际手机展上，旷视也展示了基于深度学习和计算机视觉技术打造出的人脸识别解锁、AI人像光效、智能美颜以及3D仿生感测、车载AI视觉等软硬一体的智能终端AI视觉产品。手机AI应用创新在手机解锁的AI赋能上，旷视研发的人脸识别解锁技术依托原创的深度学习引擎 MegBrain 和移动端卷积神经网络 ShuffleNet，能够适配高中低端手机芯片和单摄、双摄、3D摄像头模组，高效实现RGB人脸解锁，零光感红外人脸解锁、单目／双目结构光及 ToF 的人脸解锁。在性能上，解锁速度小于 100 毫秒，可实现亮屏即解锁的高速流畅性；此外，旷视将解锁误识率降低至百万分之一，在保障便捷性的同时也具备了支付级的安全性。旷视手机AI视觉应用底层技术――人脸稠密关键点在自拍方面，旷视也基于自研的面部关键点检测、面部3D建模、人体分割、3D光效渲染算法等核心技术打造出了AI人像光效和智能美颜应用，让用户仅用手机就可享受影棚级打光效果和明星级的美颜、美型体验。3D仿生感测技术旷视基于双目结构光模组的3D仿生感测技术展示伴随市场对3D-sensing应用的需求提升，旷视团队也正发力打造2.5D、3D视觉感知解决方案，以适配2.5D双通、3D结构光、双目结构光、ToF等模组。在本次展会上旷视也首次亮相了基于双目结构光的3D视觉整体解决方案，该方案包含旷视从光学设计、平台开发到IQ评价和Tuning，以及3D基础算法、3D应用算法的全流程自主研发创新，在旷视团队持续不断的优化调整下，旷视基于双目结构光的3D仿生感测技术在室内的Depth精度从20cm到1.2m距离范围，实测数据超越iPhone X; ?在室外10万 Lux强光下，实拍人脸的深度图效果也不输iPhone X。并且在成本控制上，该方案成本目前可以做到同类双目结构光方案最低，并已具备良好的可生产性和可交付性。车载AI视觉解决方案除了带来手机端的产品展示，旷视此次也将自身在智能终端领域中研发的车载AI视觉解决方案带到本次展会上做展示。针对汽车行业内的AI技术应用升级，旷视打造的车载AI视觉解决方案采用了自研的人脸识别、手势识别、表情识别、视线追踪等AI视觉算法，结合红外摄像模组，可精准识别驾驶员身份（人脸识别解锁车门、人脸识别启动发动机）、检测驾驶状态和行为（打呵欠、闭眼、低头、左右摇头、打电话、吸烟等），保障驾驶过程安全性。不仅如此，旷视车载AI视觉解决方案配合车载智能系统，还可支持20多种静态/动态手势，常用场景如接/挂电话、音量调节、控制媒体播放等；支持四种情绪识别，结合语音助手可以让枯燥无味的漫漫驾途变得生动有趣；其视线跟踪技术，还可应用于车载设备间的智能交互。目前旷视在前装和后装市场提供了多场景的智能化产品和解决方案，并已与蔚来汽车达成了车载AI视觉解决方案的深度合作。如今，AI在行业领域的渗透步伐已进入加速期，而与各领域终端设备的结合更成为AI为行业带来转型升级的必经之路。在移动终端领域，手机作为承载人类数字化生活和工作的重要设备，与AI的结合不仅将为行业焕发出新一轮的市场活力，更将为人们带来前所未有的便捷性、高效性、娱乐性生活与工作体验。目前，旷视已将AI赋能个人IoT，为手机、汽车等移动终端领域提供软硬一体的AI视觉解决方案作为自身重要发展方向之一，未来旷视将继续围绕移动智能终端识别与认证、计算摄影及3D感知等领域，完成更多软硬一体化的技术创新与落地，让AI全面惠及到每个人。人脸识别软件协助抓捕逃犯 人工智能市场迎来发展	前段时间，关于张学友演唱会中的逃犯频繁捉的事件成为了城中热话。众所周和，大明星的演唱会人数自然不会少，基本是浩浩荡荡，仁山人和，但为何警方可以屡次从密集的人群当中揪出正在逃亡的犯人？一切的武器在于人脸识别软件。作为如今识别技术能够的核心，人脸识别软件在诸多领域内产生着重要的作用，并对中国的人工智能产业产生了重大的影响。通过人脸识别软件，公安部门可以在密集的人流当中识别出逃犯的特征，利用面部识别技术，进一步的通过数字图像来侦查出人群中的特定的目标。面部识别有非常多的工作方法，但是都离不开以数据作为基础建立起来的模型。在实际工作过程当中，面部识别包括了很多个不同的工作内容，包括对人的外表的区别，对性别，年龄，还有身份等等。我们可以把这一个人脸识别技术，当作是一个人类的大脑神经网络一样，或数据来逐步的让这个网络变得更加成熟，然后让它具备学习的功能，这样一来，它就可以应对更多复杂的识别场所。而在张学友演唱会上面的那些逃犯，其实也是通过这种技术被捉出来的，面部识别技术，赋予了公安部门更加精确的快速的抓捕条件，让他们能够更快更好的找到正在逃亡的犯人，为维护社会治安提供一个更强大的基础。人脸识别软件目前的应用范畴已经不仅仅应用在抓捕犯人这个环节上面，还可以应用到零售，营销以及金融行业，并且发挥着非常重要的作用。与此同时，人脸识别软件相关的产品所产生的效益也是非常多的，这一点也进一步的彰显出了人工智能市场的商机。人脸识别软件为用户的日常生活带来方便，也为智慧城市的建立提供更大的便利性。据悉，如今，中国的人工智能市场正在面临蓬勃的发展时期，市场份额正在不断的增加，而人脸识别软件的开发工序也正在不断的深入，并普及到更多不同的层面。随着人脸识别技术的发展，未来每个人都可以使用到人工智能，并享受到人工智能技术为他们生活和工作带来的方便。而人脸识别技术在应用范畴上面也将会进一步的扩大，并取得更辉煌的成绩。
人工智能身份验证对未来教育产生的积极影响	教育乃国家大计，在现代，教育和人工智能之间的结合，为现代教育的发展提供了一个全新发展方向和更广阔的发展平台，更多的人工智能技术都可以被应用到教育领域里面，比如身份验证。现在，在智能教育环境的创造上面，人工智能可以为这个大环境的设计提供更强悍的技术支持。在基于物联网的智慧建立起来的校园环境，可以通过更加多比较高端的AI技术来改变传统的操作环节，并且有效的提高智能教育的效率。身份验证就是其中一个非常具有代表性的案例，这一点在校园安全探测与预警这一方面可以具有更高的展示力。比如，在整个校园园区里面，安全是非常重要的，如何才可以确保每一个来的访客的身份，以及进入的陌生人身份，这时候身份验证就会起到重要的作用。通过大数据的运算，前端的监测系统可以监测到每一个访客，或者是来访的用户的身份信息，并且对其进行身份验证，如此一来，就可以为校园安全提供更大的保障。身份验证除了能够在识别访客这一方面有作用之外，在智能教室的建立上也能够产生大的作用，可以对参与智能教室的每一位学生的身份进行记录，并完成考勤的过程。而智能教室所展示出来的诸多优势，也能够进一步的改变学生的教育环境，比如说可以远程协同，也可以做数据互动，更可以人机融合，诸多的优势融合在一起，提高了学生的学习效率。此外，身份验证在智能学习远程支持这一方面也提供了技术支持，为在线上课提供了一个更便利的身份识别系统。除此之外，还可以参与智能教育评价，对于教师的身份视频也可以提供一个更高的识别方案。除了身份验证外，人工智能与教育之间的结合还可以体现在很多不同的方面，比如对于学习负担监测与预警的环节布控，另外还有智能学习机器人的陪伴，针对少儿学习可以提供更加多的便利，为陪伴式的学习提供更好的基础。通过上述种种，我们都可以进一步的了解到人工智能对于未来教育领域发展的影响，这种影响也将会向着更智能化，更高效的步伐迈进。
旷视智慧教育解决方案全场景创新铸造平安	11月17日至19日，由中国教育装备行业协会主办，江西省教育厅、南昌市人民政府共同承办的第75届中国教育装备展示会，在南昌绿地国际博览中心举办。作为以人工智能为核心的物联网解决方案提供商，旷视科技将全新研发的人工智能教育产品及解决方案带到现场，在本次展会中首次亮相。▲旷视亮相第75届中国教育装备展伴随中国教育信息化进程的深入，人工智能、物联网、云计算等新兴技术已开始广泛赋能教育产业各领域，推动教育装备、教学模式、教学环境等方面的深度革新。在此过程中，“AI+教育”更脱颖而出成为未来教育产业的发展趋势。在践行以 AI 赋能商业 IoT 的战略布局当中，旷视科技也开始探索为教育产业融入 AI 的升级思维，将打造业界领先的软硬一体智慧教育解决方案，作为自身业务的重点突破方向。在本届中国教育装备展示会上，旷视首次展示了其覆盖智慧教学、智慧管理和智慧后勤全领域的智慧教育产品及解决方案，吸引众多专业观众驻足体验。▲中国教育技术协会常务副会长张少刚先生莅临旷视展台旷视智慧教育解决方案旷视智慧教育解决方案，是旷视结合校园实际场景需求，基于自研的人脸识别等多项尖端 AI 视觉技术、高效的平台开发以及硬件创新能力打造出的行业解决方案，包含课堂教学评价系统、智能考勤系统、校园安防系统、宿舍管理系统、人证核验系统、门禁通行系统、会议签到系统等软硬一体化的智慧教育产品。通过灵活创新的产品、适应丰富场景的终端以及性能卓越的云平台，旷视科技使精细化、安全化、人性化的校园管理成为可能，为提高教育信息化、智能化水平赋予了新动能。智慧教学为实现 AI 改革教学模式，提升教学效率与质量，旷视打造出全新的课堂智能考勤系统和课堂教学评价系统。▲旷视配备高清巡航摄像机的课堂智能考勤系统旷视课堂智能考勤系统，通过旷视自研的考勤摄像机，无死角巡航拍摄教室并自动变焦拍摄人脸；再配合旷视课堂智能考勤主机盒子MegBox-B2D的智能化分析能力，以人脸识别验证的方式对上课的学生身份进行核实，实现无感知无配合的智能考勤。相较传统的点名考勤和刷卡考勤，旷视课堂智能考勤系统可大大提高考勤工作效率，减轻教师工作负担。▲旷视配备考勤及行为分析摄像机MegEye-C3V-920的课堂教学评价系统在课堂教学评价系统中，旷视将自主研发的人脸识别、行为识别、表情识别等技术，集成在考勤及行为分析摄像机MegEye-C3V-920和行为分析服务器中，通过对课堂视频数据进行实时的结构化分析，反馈学生行为、表情、专注度、前排上座率等多维度课堂数据，辅助教学评估评价。旷视课堂教学评价系统可有效解决传统教学对教学质量评估维度单一、教师无法关注到全部学生、缺少综合高效的闭环反馈等问题，提供课堂教学效果反馈，帮助教师改善教学模式、方法，提高教学质量。智慧管理针对校园安全防护、学籍审核、考生身份核验等管理工作中存在的不足与难题，旷视以人为核心，充分发挥人脸识别在安防、审核等场景下的技术优势，打造出了校园安防系统、人证核验系统，辅助校园安全及信息管理工作。▲旷视人证核验一体机，严把学籍、考场身份核验关旷视校园安防系统，在校园重点场所的卡口位置( 如主要出入口、校门口、宿舍门口、图书馆出入口等)部署人脸抓拍机，可对经过卡口的人员进行高并发人脸检测与抓拍，实现实时陌生人预警、黑名单比对报警和人脸检索等功能，提高校园安全保障能力。旷视人证核验系统，通过旷视研发的人证核验一体机设备，还可对学生学籍身份进行核查，实现对学生学籍照片、身份证照片、学生本人三者验证，对验证异常的学生进行预警；对考生进行身份验证，结合身份证、准考证、报名信息，采用人脸比对的方式对考生身份进行核验，实现有效打击替考、代考等舞弊行为，营造公平公正的可信考场。智慧后勤▲旷视M5智能面板机、人脸识别半球机、人脸识别闸机，创造校园智慧后勤在做好校园教学、安全工作之外，将新技术融合校园生活，改变学校后勤服务方式，也成为教育信息化智能化建设的重要环节。旷视在智慧后勤方面也推出了宿舍管理系统、门禁通行系统、会议签到系统以及刷脸支付系统，为师生营造智慧化的校园生活和工作环境。基于旷视研发的M5智能面板机、人脸识别半球机、人脸识别闸机等先进的智能通行产品，旷视可为校园宿舍、教学楼、会议室等场景提供以人脸识别技术为支撑的快速通行、签到体验；尤其在宿舍场景下，旷视宿舍管理系统还可实时统计分析学生在寝时间、离寝时间、 晚归次数等各种状况，帮助辅导员教师获取全面、详细的学生在就寝信息，提高宿舍管理的效率和安全性。此外，旷视也在推进刷脸支付系统在各大校园内的应用，结合“校园一卡通”系统全面提升校园师生智能化的消费体验升级。教育，决定着人类的今天，也决定着人类的明天。教育，是对中华民族伟大复兴具有决定性意义的事业，教育兴则国家兴，教育强则国家强。在当前科技迅猛发展的时代里，教育事业也必须融合先进科技才能真正实现强兴。在《国家中长期教育改革和发展规划纲要(2010-2020年)》及《教育信息化2.0行动计划》等国家对教育事业的规划与布局中，都明确指出要加快教育信息化进程，推动人工智能在教学、管理等方面的全流程应用。目前，旷视智慧教育已帮助清华、北科大、郑州大学、人大附中等100多所院校实现了智慧校园升级。今后，旷视智慧教育仍将紧紧跟随国家的政策指引，并深入了解校园多样化需求，用软硬一体的 AI 创新和一站式服务能力，创造全向交互的校园教学、全面感知的校园环境、高效协同的校园管理、个性便捷的校园生活，为推动中国教育信息化、智能化，让更多人享受科技赋能的优质教育而努力。
智慧校园：打破“信息孤岛”，培育智慧型社区生态	智慧校园是高校信息化的高级形态， 它综合运用云计算、物联网、移动互联、大数据、人工智能、社交网络、知识管理、虚拟现实等各类新兴信息技术， 全面感知校园物理环境， 智能识别师生群体的学习、工作情景和个体特征。同时， 在网络空间建立校园虚拟映像， 将学校的物理空间和数字空间有机衔接起来，通过在网络空间的计算掌握校园运行规律并反馈、控制物理空间，为师生建立智能开放的教育教学环境和便利舒适的生活环境， 改变师生与学校资源、环境的交互方式，开展以人为本的个性化创新服务， 实现学校智慧运行， 支撑学校开展智慧教育。本研究基于建设智慧校园的方案设计与实施为目的， 通过构建全校范围内统一的大数据中心、统一的业务流程网络和统一的服务门户， 打破业务部门界限和业务系统 “信息孤岛”，实现全校范围内一致的 “信息路网”，从而提高教学、科研、管理等各个业务环节的效率。国内外研究进展20世纪70年代，美国麻省理工学院最早提出 “电子化校园”计划。1990年，美国克莱蒙特大学教授 Kenneth首次提出 “数字校园”概念， 并主持开展了 “数字校园计划” ( Campus Computing Project， 以下简称 CCP) 科研项目。自CCP计划实施以来，美国政府相继于1996年、2000 年、2005 年、2010 年颁布并实施了国家 “教育技术计划”，实现从小学到大学的 “人、机、路、网”成片联结，彻底改变了美国高等教育教与学相结合的方式、手段和过程，使美国教育的信息化始终处在国际领先地位。美国始终遵循 “信息技术促进教育改革和发展” 的战略方针， 经历了一个从重视 “基础设施建设系统应用运行效果结构调 整”的变革过程， 逐步由电子校园向数字校园、智慧校园转变的过程。英国、澳大利亚、新西兰、日本等国也分别制定并实施了一系列的教育信息化推进计划，如英国相继出台了“教育高速公路: 前进计划”“2010―2012 教育发展战略”，澳大利亚推出了“数字教育革命实施路线图”，新西兰制定了 “学校数字化学习行动计划”，日本实施了 “学校联网计划”等。这些行动计划和战略为其他国家实施从数字校园向智慧校园的转型提供了典型案例和经验。受国外影响，我国高校教育信息化也经历了从电子校园向数字校园、智慧校园的发展过程。从 20 世纪 80 年代开始，我国高校教育信息化经历了30多年的发展过程，从早期的电算化、校园网络建设，到中期的网络信息系统建设和数字校园整合集成，近期普遍重视开展业务流程优化和服务整合，信息技术越来越深度地融入高校的教育教学业务之中，高校信息化开始进入智慧校园建设阶段。另一方面，随着云计算、物联网、移动互联、大数据、互联网+、人工智能、社交网络、虚拟现实等新兴信息技术在高校中的广泛应用，信息技术与教育教学业务的融合越来越深入，高校信息化由管理信息化发展为教育教学全面信息化，信息技术与教育教学的关系从组合、整合演化到融合创新，这些都促进了智慧校园概念的提出、发展和建设。智慧校园的建设目标和理念智慧校园从用户角度出发， 打破传统业务系统边界， 建设一个扁平化、易操作、搜索引擎式的统 一开放可扩展的信息和服务平台。平台承载高校各类业务和信息， 实现数据资产的可视化呈现、统计分析和辅助决策，培育高校教学、科研、管理和生活的线上智慧型社区生态。平台包括网上事务中心、大数据中心、网络社区平台、资讯中心、个人工作台、移动门户等方面内容。智慧校园的建设是一个复杂系统的工程， 应遵 循以下四个理念。智能感知。应用智能感知技术随时随地感知、捕获、采集和传递物理校园中教学、科研、管理以及生活相关的各类环境、资源与活动的实时数据，实现对校园各类设施设备的运行状态、师生学习工作生活的活动轨迹、师生与校园环境的互动情况等的全面感知，为智慧校园的全面数据化提供感知支撑。数据为体。数据是支撑智慧校园的根本，是智慧校园的核心资产。智慧校园中人和物的基本状态、各种活动以及环境交互等各类信息要全面数据化，数据要连接化、共享化、要素化、全过程化，数据联接要广泛化，通过连接产生反馈、互动，从而激发 “化学反应式”的创新和融合。流程为相。流程是数据得以产生、流转和使用的载体， 是智慧校园中教学、科研、管理和生活等活动得以实现的方法和途径。智慧校园可以视为由广大师生和各类设备作为 “节点” 组成的大规模 “实时协同分工网络”， 广大师生和各类设备“节点”之间的协同分工通过构建统一的业务流程网络实现。在此过程中， 数据也通过统一的业务流程网络得以产生、流转和使用。服务为用 ( 师生为本)。打破物理校园边界，为广大师生提供个性化、一站式、线上线下相结合的综合服务，解决师生在教学、科研、管理和 生活中的实际需求， 支撑高校开展个性化人才培养、科学研究、智慧型管理决策以及智慧型生活。智慧校园的建设思路智慧校园的建设思路是一项复杂的系统工程，必须采用系统化思维和方法进行方案设计与实施，主要包括如下几个方面。整体规划。进行智慧校园架构的顶层设计，构建模块化、灵活可扩展的技术架构，充分考虑云计算、大数据、移动化、智能化等技术趋势和安全性保障。紧抓两端， 落实中间。前端以统一服务平台为核心， 支持移动端 APP 和微信访问， 提升广大师生和管理人员的用户体验。后端以大数据平台为核心， 实现全校范围的数据融合，实现统一数据标准、统一数据视图、统一数据流转、统一数据治理和统一数据分析，真正将数据作为学校的一种核心资产利用起来。中间以业务流程为核心，通过与各业务部门共同梳理和规范业务流程，将前端用户服务体验和后端统一数据连接起来，构建全校范围的业务流程网络，为广大师生提供一致性的教学、科研、管理、生活、社交等服务，如图1所示。以点带面， 步步推进 ( 迭代) ，注重实效。智慧校园建设是一个长期的过程，不可能一蹴而就，只能够分步实施。在分步实施的过程中，每一步都要找到当前阶段学校教学、科研和管理过程中的关键点，切中广大师生和管理人员当前的迫切需求，以此为切入点，以点带面，步步推进。
工信部联合旷视科技开展“强国对话” 探讨AI+实体经济	为学习贯彻习近平总书记在中共中央政治局第九次集体学习时的重要讲话精神，落实《中央和国家机关工委关于推进中央和国家机关年轻干部深入学习习近平新时代中国特色社会主义思想的意见》相关要求，11月20日，旷视科技联合工业和信息化部科技司，以及工信部直属机关党委、团委，共同组织举办了主题为“学习总书记重要讲话精神，推动人工智能与实体经济深度融合”强国对话活动，工信部及相关单位 600 余位同志参加了活动，旷视科技副总裁任志伟作为人工智能独角兽企业代表，同制造业龙头企业、人工智能领军企业、投资界和学术界代表就人工智能发展的趋势、制约人工智能与实体经济融合的瓶颈、破解措施等关键话题进行了深入交流。曾为中共中央政治局第九次集体学习授课的中国工程院院士、北京大学教授高文也来到现场做主旨发言。他简要地传达了习近平总书记重要讲话精神，介绍了全球人工智能产业发展历程和态势，梳理了我国人工智能发展优势和短板，并针对如何促进人工智能与实体经济融合、发挥数据优势和促进中小企业技术发展提出了宝贵建议。高文教授指出，从国际态势来看，人工智能已经被多个国家列为国家战略，但整体来看其发展特性是由一些尖端企业推动的，企业在人工智能革命中发挥着至关重要的作用。在中华民族伟大复兴的关键时期，具体怎样将人工智能技术与实体经济更好的结合，让我国在这次产业革命抢占先机至关重要。会上，来自制造业龙头企业、人工智能领军企业、人工智能独角兽企业、投资界和学术界的代表们也结合贯彻落实习总书记的重要讲话精神，围绕人工智能和实体经济，特别是与制造业的融合进行了深度对话。旷视科技副总裁任志伟认为要大规模推进人工智能创新应用，需要人工智能结合物联网实现数据驱动、人机协同。以旷视科技为例，在赋能智能制造、智能工厂的过程中，旷视不仅要打造“机器之眼”和“机器大脑”，还要连接机器人的手、脚，让机器具备感知能力，以提升产线的运营效率。强国对话活动的开展不仅为直属机关干部职工，特别是青年干部提供一个政治学习和业务学习相结合的平台，更进一步推动了党建群团工作和业务工作相互促进、相互融合。下一步，工信部直属机关党委、团委和工会将同相关司局密切配合，会同兄弟部委党团组织，邀请政府、企业、学术界、投资机构、权威媒体代表，围绕推进“两个强国”建设相关重大问题进行深入对话，以交流研讨的形式帮助广大党员干部更好地深化对习近平新时代中国特色社会主义思想和党的十九大精神的学习理解认识，更好地以实际行动落实中央重大决策部署，扎实推进两个强国建设。
旷视科技人工智能专利荣获第二十届中国专利优秀奖	2018年11月23日，据国家知识产权局公布的第二十届中国专利奖评审结果显示，由北京旷视科技有限公司提交的“基于神经网络模型的目标跟踪方法及装置”发明专利（专利号ZL201610306250.7）成功通过此次评审，荣获第二十届中国专利优秀奖。图：旷视科技荣获第二十届中国专利优秀奖 来源：国家知识产权局官网资料显示，“中国专利奖”是中国唯一的专门对授予专利权的发明创造给予奖励的政府部门奖，由中国国家知识产权局与世界知识产权组织共同评选并颁奖，是国家最高的专利奖项。中国专利奖面向中国境内的所有企业，每年评选一次，自1989年至今已经举办二十届。评选标准包括专利质量、技术先进性、运用及保护措施和成效、社会效益及发展前景等多个维度，评选程序包括择优推荐、初审受理、专业评审、评审委员会复审等多个环节，竞争相当激烈。旷视能够获评中国专利奖，是评选单位对旷视知识产权实力的认可，也是对旷视的科技创新能力的肯定。旷视勇立AI潮头 握有自主知识产权是关键自成立以来，技术信仰、不断创新就是旷视科技始终不变的信条。至今为止，旷视已经揽获 24 项世界技术评测第一，曾在计算机视觉相关的国际人工智能顶级竞赛中多次击败 Google、Facebook、Microsoft 等巨头；在ECCV 2018的COCO、Mapillary竞赛中，旷视更是独揽4冠，刷新了中国 AI 技术的世界新高度。同时，其自主研发的计算机视觉技术及智能硬件、智能云服务等产品已居世界领先水平。旗下拥有全球最大的人脸识别开放平台Face++和第三方人脸身份验证平台FaceID，并已在各垂直领域推出了包括人脸识别支付、人脸识别解锁、全帧智能抓拍机在内的多个具有开创性意义的AI产品。其中，旷视科技自研的核心人脸识别技术被美国著名科技评论杂志《麻省理工科技评论》评定为2017年全球十大突破技术，旷视科技也入榜了“全球最聪明50家公司”。经过七年累积，旷视科技在专利等知识产权方面已经形成较为科学完善的布局。目前，旷视科技已经在中国、美国、印度、欧洲等国家和地区提交人工智能相关专利申请1000余件，成为人工智能行业内拥有自主知识产权最多的企业之一。同时，专利布局覆盖训练引擎、核心算法、基础平台、智能产品等各个技术层次，并以核心算法为纽带形成了横跨金融安全、智慧城市、手机智能、商业物联、工业机器人等五大行业的专利包。凭借不断深耕的自研技术和扎实的知识产权工作，自2015年以来，旷视科技先后被中关村知识产权促进局、北京市知识产权局和中国国家知识产权局评选为中关村知识产权重点示范企业、北京市专利示范单位和国家知识产权优势企业，并多次获得业界评选的“人工智能领域知识产权领先企业”、“年度十大IPR影响力机构”等荣誉称号。在科技部火炬中心评选的中国独角兽企业中，旷视科技也连续两年被评为中国人工智能领域的头部独角兽企业。同时，在2018年4月，旷视科技联合创始人兼CEO印奇还入选2017知识产权领域最具影响力人物；8月，旷视科技获评国家知识产权示范企业。价值务实做有用的创新 旷视助力科技强国旷视科技此次获评中国专利优秀奖的“基于神经网络模型的目标跟踪方法及装置”专利，属于基于人工智能技术进行目标对象准确跟踪的基础性专利，能够针对视频更好地完成目标的检测和跟踪，提高目标跟踪的速度和准确性，解决现有目标跟踪方法存在重复计算，从而导致计算时间增加，影响运算速度，以及待处理视频的目标检测结果不能相互优化，影响检测跟踪准确性的问题。在电视直播、公共安防、智能交通等实际应用中有着非常重要的意义。本发明专利已经作为核心专利技术广泛应用于旷视安防视频结构化产品中，服务于全国100余座城市的公共安全管理，并累计服务保障了博鳌论坛、G20峰会等数十场国际国内大型会议，在维护社会公共安全中发挥了重大作用。2018年是改革开放40周年，也是国家知识产权战略纲要实施十周年。在当下，人工智能已经成为我国创新增长的新引擎，集中体现了中国整体的科技创新实力，在行业变革、创新升级中起到举足轻重的作用。作为中国第一批踏足人工智能革命浪潮的企业，旷视科技始终将技术创新作为自驱力。目前，旷视已经在北京、上海、南京、成都和美国西雅图分别设立了独立研究院，并与西安交通大学、香港科技大学、上海科技大学等高等学府纷纷成立人工智能联合实验室。2017年11月，旷视科技正式成立学术委员会，由图灵奖唯一华人得主姚期智院士担任首席顾问，通过人才聚集和产学研结合协同促进底层技术创新。同时，在人工智能基础研究和产业融合实践中，旷视还建立了自有的技术生产、工程能力体系，并围绕核心的计算机视觉能力搭建了完善的技术矩阵。未来，在国家对知识产权的重视与扶持下，旷视科技将进一步坚定技术信仰，不断创新，提升自身专利申请和布局质量，用更多高价值的人工智能专利助力企业发展，助力“科技强国”战略。
旷视科技唐文斌：深入场景打磨产品 实现人工智能的价值创造	11月27日，36氪WISE 2018 “新经济之王”峰会在北京正式拉开帷幕。作为中国人工智能领域的领军企业，旷视科技联合创始人唐文斌也受邀出席本次峰会，并就“AI如何为产业和社会创造价值”发表演讲。▲旷视科技联合创始人唐文斌出席36氪?WISE 2018 “新经济之王”峰会并发表演讲在当前新经济浪潮全面颠覆产业发展之时，WISE 2018 “新经济之王”峰会聚焦“新经济、新领袖、新亚洲、新未来”的年度主题，汇聚这个时代最具影响力、创新力的“新经济之王”，共同探索和推进新商业文明的未来。改变世界的不是技术是技术衍生的产品所创造的价值当前的新经济以信息革命为背景，其核心是推动由大数据、云计算、人工智能等新一代信息技术驱动的数字经济的蓬勃发展。当前，各产业以及各企业都在全面拥抱数字化转型，挖掘并建立新一阶段的商业价值。然而许多公司却沉迷AI 等技术给自己带来的光环，对最终承载技术的产品欠缺思考，分不清手段和目的的区别，没有切实为企业降低成本，没有创造自己的价值，最终成为泡沫的一部分。对此，唐文斌给出自己的看法：“企业数字化，任何的数据在线化都是手段，并不带来实际价值，但是最后形成的是企业运营、管理的创新，这才是目的。其实我们看人工智能企业，或者我们自己在做的各项人工智能产品，我们会发现做的所有技术本质上都是手段，而 AI技术是为了做产品的一个手段，而你做的产品其实是实现场景价值的手段。”这正与旷视一直以来对自身的定位相同，旷视在内部一直强调：旷视不是一家 AI公司，而是一家以 AI技术为核心的产品公司。旷视最终的关注点是有价值的产品，而不是技术本身。价值是什么？降低成本、提升效率、优化体验旷视成立至今已深扎人工智能领域7年，而从成立伊始旷视就始终坚持并贯彻“技术信仰”和“价值务实”，希望用人工智能为人类创造美好。在今年，旷视在赋能产业的途中更加清晰了自身使命――以非凡科技，为客户和社会持续创造最大价值。但具体来说，旷视要创造的价值是什么？唐文斌在峰会上就对此给出了答案：“降低成本、提升效率、优化体验――正是旷视对行业客户不断输出的价值。”唐文斌举例：“例如，原来我们在办理银行贷款业务的时候，必须要本人携带身份证去银行网点才能办理，但是在2015年旷视推出了 FaceID 在线身份验证的产品，我们通过人脸识别的方式能够让大家在手机上做实名身份认证，我们希望这件事情不再需要你去到网点就可以在线上直接办理，这本质上是在降低成本。”现在，通过 FaceID 在线人脸身份验证平台，旷视已为 4 亿人提供了 “足不出户”或者“只需跑一趟”的智能化金融服务体验，为众多金融企业和用户带来成本控制上的改善。在“提升效率”和“优化体验”，唐文斌也从旷视在安防和楼宇的智能化升级上来体现。在过去的安防作业模式中，从监控视频中搜寻破案线索寻找嫌疑犯是一项繁琐冗长的工作，也正因如此，这项工作需要投入大量人力以及耗费足够的时间让工作人员去一遍遍地翻看监控录像；如今，旷视一系列端到端智能安防产品的落地应用，则大幅缩减了警务流程与时间，极大程度地提高了警方的破案效率。此外，唐文斌也介绍，旷视研发的人脸识别门禁产品则帮助许多企业和楼宇替代了过去指纹或刷卡的通行方式，“在你走过去时门就是开的”的无感知、快速通行刷脸通行体验，正越来越成为各大公司及写字楼优化通行体验的首选。目前，旷视正沿着自身 AI+IoT 的战略布局，为涉及公共IoT、商业IoT和个人IoT领域的众多产业，持续带来“降低成本、提升效率、优化体验”的价值输出。旷视价值创造逻辑在场景中践行“感知、决策、执行”作为一家 CV公司，同时又处于人工智能这一新兴产业，旷视是通过何种“手段”去实现自身的价值创造？对此，唐文斌也给出了答案：“我们的手段最早是做计算机视觉感知，但在实际应用中，我们发现只做计算机视觉并不能呈现出最终的价值，这价值是需要靠后面的决策和行动来呈现。比方说我们刚刚在讲安防业务场景，在一次案件侦查中，我们确定了某个人时一个逃犯，得有行动也就是你得出警把他抓了，才能算作案件的破获与完结。再比方说我们知道很多新零售的场景中，我们知道一位顾客进店之后拿起一瓶矿泉水看了看，但他最后却拿走了旁边的汽水，仅仅有这样的场景数据，是不足以帮助店家去提升坪效的，我们需要帮他制定决策体系辅助他做提升。”所以，旷视在以技术为基础实现价值创造上，是在遵循着“由感知到决策再到执行”的逻辑。而这套逻辑需要企业去接触真实场景，从场景倒推，才能明确逻辑应用方式。唐文斌以旷视进军机器人领域为例：“旷视现在将物流机器人做为自身核心业务之一。我们发现，在物流行业的仓库中，拣货员有时需要在零下10度的环境里每天走 30-40 公里，大部分人不太愿意去干这么辛苦的活，随之带来人力成本和人员流失率的居高不下。针对这种场景，我们选择做机器人，我们希望在赋能机器之眼之外，用机器的‘腿’解决行动的问题，用机器的‘手’去解决抓取的问题，我们通过一系列的产品组合对这类场景实现降本增效和体验优化。”沿着这套逻辑，旷视开始进行自身的物流机器人业务实践。而目前，旷视已打造出全亚洲最大的机器人智能仓，实际投入 500 台 AGV机器人，更加入了机器臂以及其他一系列智能化设备。在今年的双十一中，这个仓库在当天出了 8万多的订单，整体的人效提升了 44%。机器人也好、算法也好其实本质上都是手段，手段注定是要为具体场景服务的。旷视是做感知技术出身，感知之后需要做的是控制，当能够控制很多机器的时候，则需要让机器联动起来去完成场景的运转，最终才能实现人工智能产品的价值创造。面对未来，唐文斌也筹划了旷视科技的路：“我们希望通过以上这样的一些手段回到场景的价值，回到我怎么样帮助场景去降低成本、去提升效率，我们希望能够提供一个叫做机器人网络的大脑，这就是我们接下来想做的事情。”
旷视承包CCPC中国大学生程序设计竞赛 5 年赛事总赞助	AI 科技评论按：经过 2018 年 11 月 24 ― 25 日两日紧张的比赛，第四届中国大学生程序设计竞赛（ CCPC ）总决赛于 25 日落下帷幕，「清华大学_中二之力」从 114 支参赛队伍中脱颖而出，以绝对解题优势拿下冠军。中国大学生程序设计竞赛（ China Collegiate Programming Contest / CCPC ）是由中国大学生程序设计竞赛组委会组织的年度性赛事，旨在通过竞赛来提高并展示中国大学生程序设计创新与解决实际问题的能力，发现优秀的计算机人才，引领并促进中国高校程序设计教学改革与人才培养。CCPC 竞赛举办至今已是第四届，今年的活动总赞助为旷视科技。根据 CCPC 2018 最终榜单数据显示，「清华大学_中二之力」成功解出10题，一举夺下冠军。亚军队伍是来自南京大学的「南京大学_咖啡鸡」团队，「复旦大学_祈求者」团队则拿下季军。其余获得金牌的队伍来自多所高校，包括复旦大学、香港大学、华东师范大学、上海交通大学、浙江大学、北京大学、广东工业大学、中山大学。（企业参赛队伍不计）CCPC 2018 总决赛最终榜单CCPC 竞赛组委会主席俞勇教授在赛后接受采访时表示，CCPC 赛事的最大特点是扎根中国本土，在出题思路上强调融入中国背景，从中培养具有解决中国业界现实问题能力的选手，而不是单纯通过题海战术养成解题「套路」。对此，清华大学 ACM 教练邬晓钧教授表示认可，他认为今年的命题水平较高，设置的题目难度适宜，在题目设计和题意描述方面不存在陷阱，队员因而能够专注在算法分析、设计与实现上，充分发挥队伍的实力。据了解，清华大学为了充分准备本次比赛，从年初开始便安排「以老带少」的模式进行训练，让大四学长向年轻成员传授参赛经验。旷视科技联合创始人唐文斌（右二）为 CCPC 2018 竞赛总冠军颁奖作为 CCPC 总决赛的承办方，哈尔滨工业大学（深圳）计算机学院院长王轩向记者表示，当初答应承办赛事的原因主要有两点，其一是看中了赛事的正规性，无论是从活动规模、宣传效果、赞助力度、出题思路而言，相信能对本校的计算机专业学生有所启发。其二，他也希望通过赛事让更多学生了解哈尔滨工业大学（深圳）校区。同时，对于唐文斌这类竞赛出身的青年创业者身体力行支持 CCPC 的举动，王轩院长也十分赞叹。?旷视科技包揽未来 5 年 CCPC 赛事总赞助旷视科技联合创始人兼 CTO 唐文斌是 CCPC 2018 组委会成员之一，亲自参与了赛事的组织与策划，值得一提的是，在他的大力倡导下，旷视科技也是今年 CCPC 竞赛的总赞助。在竞赛环境和赛题设置上，唐文斌对雷锋网 AI 科技评论表示，CCPC 竞赛是国内做得最好的程序设计竞赛之一，既能保证公平性，又具有专业度与区分度。旷视科技联合创始人兼 CTO?唐文斌身为曾经的信息学奥林匹克竞赛金牌、 ACM/ICPC 国际大学生程序设计竞赛世界总决赛第六名、中国 TopCoder Target 第五名的获得者，唐文斌认为过去的参赛经历对自身的成长帮助极大，其中的收获包括：其一是解决的问题能力，竞赛可以培养模型化问题的能力，从中养成解决问题的思维方式；其二是求胜心，竞赛过程中求赢的心理将可以极大地激发个人潜力；其三是团队协作能力，由于赛事要求三人组团合力答题，非常考验团队之间的协作默契，过程中还会涉及到团队的协调问题，在无形中培养了协调者的领导能力。因此，唐文斌希望大学生们可以在不影响学业的情况下多参加竞赛，而他也会通过身体力行的方式回馈赛事――旷视在未来 5 年将继续成为 CCPC 竞赛的总赞助，让组委会能在无后顾之忧的情况下继续扩大赛事影响力，使更多的学生受惠。?竞赛选手要「站在技术的角度看场景，站在场景的角度看技术」唐文斌表示旷视科技非常欢迎竞赛出身的选手加入到公司团队中来。他十分认可竞赛出身的同学强大的技术实力，同时也强调工程体系方面锻炼的匮乏是不可忽视的问题。因此，他建议同学们平时可以多进行工程上的实践，同时加强人文方面的素养，使自己能够站到用户的角度综合思考问题。「站在技术的角度看场景，站在场景的角度看技术」，唐文斌认为这种人才可遇不可求，也是旷视科技内部「牛逼、成长、可依赖」的人才观所不可或缺的。据 AI 科技评论了解，旷视科技目前的业务重心聚焦在个人 IOT（手机）、公共 IOT（安防、教育）和商业 IOT（智能机器人）三大领域，加入旷视团队将有机会亲自上手接触这些领域的业务。谈及旷视科技对人才的吸引力，唐文斌表示会有以下三点：其一，旷视科技的业务是能够具体产生社会价值的，在具体参与业务的过程中会无形培养个人的使命感；其二，旷视科技的业务具有一定门槛，并非所有人都有能力完成，对于喜欢挑战的同学来说将能够从中获得极大的成就感；其三，旷视里的员工基本上都是综合素质能力较强的人，与强者共事可以互相学习到很多东西。面对当今的 AI 热潮，许多计算机专业的同学们都想投身 AI 行业，如何在高速发展期的 AI 行业不被淘汰，他也有一些建议给到同学们。「一是必须保持敏锐，对自己有自信，二是始终坚持自我学习。旷视科技内部会提供非常丰富的学习课程，甚至会定期邀请不同领域的领航人物来做内部分享，希望通过这些课程让每一位旷视人持续成长，上到更高的台阶，保持自身的行业竞争力。当然，自我驱动力是关键。」
